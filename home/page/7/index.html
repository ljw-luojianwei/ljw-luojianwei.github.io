<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;luojianwei.top&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;}}</script><script src="/js/config.js"></script>
<meta property="og:type" content="website">
<meta property="og:title" content="罗建伟的个人主页">
<meta property="og:url" content="https://luojianwei.top/home/page/7/index.html">
<meta property="og:site_name" content="罗建伟的个人主页">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="罗建伟的个人博客">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://luojianwei.top/home/page/7/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;home&#x2F;page&#x2F;7&#x2F;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>罗建伟的个人主页</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">罗建伟的个人主页</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">明确自己的内心所求，才能更好地解决问题</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/home/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">罗建伟的个人博客</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">68</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">Android Camera 体系结构之八 相机驱动层–V4L2框架解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:00:52 / 修改时间：15:02:16" itemprop="dateCreated datePublished" datetime="2021-06-11T15:00:52+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">相机驱动层位于HAL Moudle与硬件层之间，借助linux内核驱动框架，以文件节点的方式暴露接口给用户空间，让HAL Module通过标准的文件访问接口，从而能够将请求顺利地下发到内核中，而在内核中，为了更好的支持视频流的操作，早先提出了v4l视频处理框架，但是由于操作复杂，并且代码无法进行较好的重构，难以维护等原因，之后便衍生出了v4l2框架。</p>

<p style="text-indent:2em">V4L2英文是Video for Linux 2，该框架是诞生于Linux系统，用于提供一个标准的视频控制框架，其中一般默认会嵌入media controller框架中进行统一管理，v4l2提供给用户空间操作节点，media controller拥有对于每一个设备的枚举控制能力，与此同时，由于v4l2包含了一定数量的子设备，而这一系列的子设备都是处于平级关系，但是在实际的图像采集过程中，子设备之间往往还存在着包含与被包含的关系，所以为了维护并管理这种关系，media controller针对多个子设备建立了的一个拓扑图，数据流也就按照这个拓扑图进行流转。按照v4l2标准，它将一个数据流设备抽象成一个videoX节点，从属的子设备都对应着各自的v4l2_subdev实现，并且通过media controller进行统一管理，整个流程复杂但高效，同时代码的扩展性也较高。</p>

<p><img src="/.top//v4l2%E9%A9%B1%E5%8A%A8%E6%9E%B6%E6%9E%84.jpg" alt="img"></p>
<p style="text-indent:2em">而对高通平台而言，高通整个内核相机驱动是建立在v4l2框架上的，并且对其进行了相应的扩展，创建了一个整体相机控制者的CRM，它以节点video0暴露给用户空间，主要用于管理内核中的Session、Request以及与子设备，同时各个子模块都实现了各自的v4l2_subdev设备，并且以v4l2_subdev节点暴露给用户空间，与此同时，高通还创建了另一个video1设备Camera SYNC，该设备主要用于同步数据流，保证用户空间和内核空间的buffer能够高效得进行传递。</p>

<p style="text-indent:2em">再往下与相机驱动交互的便是整个相机框架的最底层Camera Hardware了，驱动部分控制着其上下电逻辑以及寄存器读取时序并按照I2C协议进行与硬件的通信，和根据MIPI CSI协议传递数据，从而达到控制各个硬件设备，并且获取图像数据的目的。</p>

<h3 id="流程简介"><a href="#流程简介" class="headerlink" title="流程简介"></a>流程简介</h3><p style="text-indent:2em">整个对于v4l2的操作主要包含了如下几个主要流程：</p>

<p><img src="/.top//use_v4l2.jpg" alt="img"></p>
<h4 id="打开video设备"><a href="#打开video设备" class="headerlink" title="打开video设备"></a>打开video设备</h4><p style="text-indent:2em">在需要进行视频数据流的操作之前，首先要通过标准的字符设备操作接口open方法来打开一个video设备，并且将返回的字符句柄存在本地，之后的一系列操作都是基于该句柄，而在打开的过程中，会去给每一个子设备的上电，并完成各自的一系列初始化操作。</p>

<h4 id="查看并设置设备"><a href="#查看并设置设备" class="headerlink" title="查看并设置设备"></a>查看并设置设备</h4><p style="text-indent:2em">在打开设备获取其文件句柄之后，就需要查询设备的属性，该动作主要通过ioctl传入VIDIOC_QUERYCAP参数来完成，其中该系列属性通过v4l2_capability结构体来表达，除此之外，还可以通过传入VIDIOC_ENUM_FMT来枚举支持的数据格式，通过传入VIDIOC_G_FMT/VIDIOC_S_FMT来分别获取和获取当前的数据格式，通过传入VIDIOC_G_PARM/VIDIOC_S_PARM来分别获取和设置参数。</p>

<h4 id="申请帧缓冲区"><a href="#申请帧缓冲区" class="headerlink" title="申请帧缓冲区"></a>申请帧缓冲区</h4><p style="text-indent:2em">完成设备的配置之后，便可以开始向设备申请多个用于盛装图像数据的帧缓冲区，该动作通过调用ioctl并且传入VIDIOC_REQBUFS命令来完成，最后将缓冲区通过mmap方式映射到用户空间。</p>

<h4 id="将帧缓冲区入队"><a href="#将帧缓冲区入队" class="headerlink" title="将帧缓冲区入队"></a>将帧缓冲区入队</h4><p style="text-indent:2em">申请好帧缓冲区之后，通过调用ioctl方法传入VIDIOC_QBUF命令来将帧缓冲区加入到v4l2 框架中的缓冲区队列中，静等硬件模块将图像数据填充到缓冲区中。</p>

<h4 id="开启数据流"><a href="#开启数据流" class="headerlink" title="开启数据流"></a>开启数据流</h4><p style="text-indent:2em">将所有的缓冲区都加入队列中之后便可以调用ioctl并且传入VIDIOC_STREAMON命令，来通知整个框架开始进行数据传输，其中大致包括了通知各个子设备开始进行工作，最终将数据填充到V4L2框架中的缓冲区队列中。</p>

<h4 id="将帧缓冲区出队"><a href="#将帧缓冲区出队" class="headerlink" title="将帧缓冲区出队"></a>将帧缓冲区出队</h4><p style="text-indent:2em">一旦数据流开始进行流转了，我们就可以通过调用ioctl下发VIDIOC_DQBUF命令来获取帧缓冲区，并且将缓冲区的图像数据取出，进行预览、拍照或者录像的处理，处理完成之后，需要将此次缓冲区再次放入V4L2框架中的队列中等待下次的图像数据的填充。</p><br>

<p style="text-indent:2em">整个采集图像数据的流程现在看来还是比较简单的，接口的控制逻辑很清晰，主要原因是为了提供给用户的接口简单而且抽象，这样方便用户进行集成开发，其中的大部分复杂的业务处理都被V4L2很好的封装了，接下来我们来详细了解下V4L2框架内部是如何表达以及如何运转的。</p>

<h3 id="关键结构体"><a href="#关键结构体" class="headerlink" title="关键结构体"></a>关键结构体</h3><p><img src="/.top//%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%84%E4%BD%93.jpg" alt="img"></p>
<p style="text-indent:2em">从上图不难看出，v4l2_device作为顶层管理者，一方面通过嵌入到一个video_device中，暴露video设备节点给用户空间进行控制，另一方面，video_device内部会创建一个media_entity作为在media controller中的抽象体，被加入到media_device中的entitie链表中，此外，为了保持对所从属子设备的控制，内部还维护了一个挂载了所有子设备的subdevs链表。</p>

<p style="text-indent:2em">而对于其中每一个子设备而言，统一采用了v4l2_subdev结构体来进行描述，一方面通过嵌入到video_device，暴露v4l2_subdev子设备节点给用户空间进行控制，另一方面其内部也维护着在media controller中的对应的一个media_entity抽象体，而该抽象体也会链入到media_device中的entities链表中。</p>

<p style="text-indent:2em">通过加入entities链表的方式，media_device保持了对所有的设备信息的查询和控制的能力，而该能力会通过media controller框架在用户空间创建meida设备节点，将这种能力暴露给用户进行控制。</p>

<p style="text-indent:2em">由此可见，V4L2框架都是围绕着以上几个主要结构体来进行的，接下来我们依次简单介绍下：</p>

<details><summary>v4l2_device 源码如下：</summary>
<pre><code>struct v4l2_device &#123;
    struct device *dev;
#if defined(CONFIG_MEDIA_CONTROLLER)
    struct media_device *mdev;
#endif
    struct list_head subdevs;
    spinlock_t lock;
    char name[V4L2_DEVICE_NAME_SIZE];
    void (*notify)(struct v4l2_subdev *sd,
        unsigned int notification, void *arg);
    struct v4l2_ctrl_handler *ctrl_handler;
    struct v4l2_prio_state prio;
    struct kref ref;
    void (*release)(struct v4l2_device *v4l2_dev);
&#125;;</code></pre>
</details>


<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_device</span> *<span class="title">mdev</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">subdevs</span>;</span></span><br><span class="line">    <span class="keyword">spinlock_t</span> lock;</span><br><span class="line">    <span class="keyword">char</span> name[V4L2_DEVICE_NAME_SIZE];</span><br><span class="line">    <span class="keyword">void</span> (*notify)(struct v4l2_subdev *sd,</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> notification, <span class="keyword">void</span> *arg);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_prio_state</span> <span class="title">prio</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kref</span> <span class="title">ref</span>;</span></span><br><span class="line">    <span class="keyword">void</span> (*release)(struct v4l2_device *v4l2_dev);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了一个整个V4L2设备，作为整个V4L2的顶层管理者，内部通过一个链表管理着整个从属的所有的子设备，并且如果将整个框架放入media conntroller进行管理，便在初始化的时候需要将创建成功的media_device赋值给内部变量 mdev，这样便建立了于与media_device的联系，驱动通过调用v4l2_device_register方法和v4l2_device_unregister方法分别向系统注册和释放一个v4l2_device。</p>

<p>v4l2_subdev源码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev</span> &#123;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_entity</span> <span class="title">entity</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">module</span> *<span class="title">owner</span>;</span></span><br><span class="line">    <span class="keyword">bool</span> owner_v4l2_dev;</span><br><span class="line">    u32 flags;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> *<span class="title">v4l2_dev</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_ops</span> *<span class="title">ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_internal_ops</span> *<span class="title">internal_ops</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line">    <span class="keyword">char</span> name[V4L2_SUBDEV_NAME_SIZE];</span><br><span class="line">    u32 grp_id;</span><br><span class="line">    <span class="keyword">void</span> *dev_priv;</span><br><span class="line">    <span class="keyword">void</span> *host_priv;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">video_device</span> *<span class="title">devnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">fwnode_handle</span> *<span class="title">fwnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">async_list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_async_subdev</span> *<span class="title">asd</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_async_notifier</span> *<span class="title">notifier</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_platform_data</span> *<span class="title">pdata</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了一个子设备，每一个子设备都需要在初始化的时候挂载到一个总的v4l2_device上，并且将该v4l2设备赋值给内部的v4l2_dev变量，之后将自身加入到v4l2_device中的子设备链表中进行统一管理，这种方式提高了遍历访问所有子设备的效率，同时为了表达不同硬件模块的特殊操作行为，v4l2_subdev定义了一个v4l2_subdev_ops 结构体来进行定义，其实现交由不同的硬件模块来具体完成。其中如果使能了CONFIG_MEDIA_CONTROLLER宏，便会在media_controller中生成一个对应的media_entity，来代表该子设备，而该entity便会存入子设备结构体中的entity变量中，最后，如果需要创建一个设备节点的话，通过video_device调用标准API接口进行实现，而相应的video_device便会存入其内部devnode变量中。</p>

<p style="text-indent:2em">video_device源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">video_device</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_entity</span> <span class="title">entity</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_intf_devnode</span> *<span class="title">intf_devnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_pipeline</span> <span class="title">pipe</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_file_operations</span> *<span class="title">fops</span>;</span></span><br><span class="line"> </span><br><span class="line">    u32 device_caps;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* sysfs */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> <span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">cdev</span> *<span class="title">cdev</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> *<span class="title">v4l2_dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev_parent</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span> *<span class="title">queue</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_prio_state</span> *<span class="title">prio</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* device info */</span></span><br><span class="line">    <span class="keyword">char</span> name[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">int</span> vfl_type;</span><br><span class="line">    <span class="keyword">int</span> vfl_dir;</span><br><span class="line">    <span class="keyword">int</span> minor;</span><br><span class="line">    u16 num;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* V4L2 file handles */</span></span><br><span class="line">    <span class="keyword">spinlock_t</span>      fh_lock;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">fh_list</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span> dev_debug;</span><br><span class="line"> </span><br><span class="line">    v4l2_std_id tvnorms;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* callbacks */</span></span><br><span class="line">    <span class="keyword">void</span> (*release)(struct video_device *vdev);</span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ioctl_ops</span> *<span class="title">ioctl_ops</span>;</span></span><br><span class="line">    DECLARE_BITMAP(valid_ioctls, BASE_VIDIOC_PRIVATE);</span><br><span class="line"> </span><br><span class="line">    DECLARE_BITMAP(disable_locking, BASE_VIDIOC_PRIVATE);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span> *<span class="title">lock</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">如果需要给v4l2_device或者v4l2_subdev在系统中创建节点的话，便需要实现该结构体，并且通过video_register_device方法进行创建，而其中的fops便是video_device所对应的操作方法集，在v4l2框架内部，会将video_device嵌入到一个具有特定主设备号的字符设备中，而其方法集会在操作节点时被调用到。除了这些标准的操作集外，还定义了一系列的ioctl操作集，通过内部ioctl_ops来描述。</p>

<p style="text-indent:2em">media_device源码如下:</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">media_device</span> &#123;</span></span><br><span class="line">    <span class="comment">/* dev-&gt;driver_data points to this struct. */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_devnode</span> *<span class="title">devnode</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">char</span> model[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">char</span> driver_name[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">char</span> serial[<span class="number">40</span>];</span><br><span class="line">    <span class="keyword">char</span> bus_info[<span class="number">32</span>];</span><br><span class="line">    u32 hw_revision;</span><br><span class="line"> </span><br><span class="line">    u64 topology_version;</span><br><span class="line"> </span><br><span class="line">    u32 id;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ida</span> <span class="title">entity_internal_idx</span>;</span></span><br><span class="line">    <span class="keyword">int</span> entity_internal_idx_max;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">entities</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">interfaces</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">pads</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">links</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* notify callback list invoked when a new entity is registered */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">entity_notify</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Serializes graph operations. */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span> <span class="title">graph_mutex</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_graph</span> <span class="title">pm_count_walk</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">void</span> *source_priv;</span><br><span class="line">    <span class="keyword">int</span> (*enable_source)(struct media_entity *entity,</span><br><span class="line">                 struct media_pipeline *pipe);</span><br><span class="line">    <span class="keyword">void</span> (*disable_source)(struct media_entity *entity);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">media_device_ops</span> *<span class="title">ops</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">如果使能了CONFIG_MEDIA_CONTROLLER宏，则当v4l2_device初始化的过程中便会去创建一个media_device，而这个media_device便是整个media controller的抽象管理者，每一个v4l2设备以及从属的子设备都会对应的各自的entity，并且将其存入media_device中进行统一管理，与其它抽象设备一样，media_device也具有自身的行为，比如用户可以通过访问media节点，枚举出所有的从属于同一个v4l2_device的子设备，另外，在开启数据流的时候，media_device通过将各个media_entity按照一定的顺序连接起来，实现了数据流向的整体控制。</p>

<p style="text-indent:2em">vb2_queue源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            type;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            io_modes;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span>           *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span>           dma_attrs;</span><br><span class="line">    <span class="keyword">unsigned</span>            bidirectional:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            fileio_read_once:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            fileio_write_immediately:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            allow_zero_bytesused:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>           quirk_poll_must_check_waiting_for_buffers:<span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span>            *<span class="title">lock</span>;</span></span><br><span class="line">    <span class="keyword">void</span>                *owner;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_ops</span>        *<span class="title">ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_mem_ops</span>    *<span class="title">mem_ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_buf_ops</span>    *<span class="title">buf_ops</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">void</span>                *drv_priv;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            buf_struct_size;</span><br><span class="line">    u32             timestamp_flags;</span><br><span class="line">    <span class="keyword">gfp_t</span>               gfp_flags;</span><br><span class="line">    u32             min_buffers_needed;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* private: internal use only */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span>            <span class="title">mmap_lock</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            memory;</span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">dma_data_direction</span>     <span class="title">dma_dir</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_buffer</span>       *<span class="title">bufs</span>[<span class="title">VB2_MAX_FRAME</span>];</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            num_buffers;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>        <span class="title">queued_list</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            queued_count;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">atomic_t</span>            owned_by_drv_count;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>        <span class="title">done_list</span>;</span></span><br><span class="line">    <span class="keyword">spinlock_t</span>          done_lock;</span><br><span class="line">    <span class="keyword">wait_queue_head_t</span>       done_wq;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span>           *<span class="title">alloc_devs</span>[<span class="title">VB2_MAX_PLANES</span>];</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            streaming:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            start_streaming_called:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            error:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            waiting_for_buffers:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            is_multiplanar:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            is_output:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            copy_timestamp:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            last_buffer_dequeued:<span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_fileio_data</span>      *<span class="title">fileio</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_threadio_data</span>    *<span class="title">threadio</span>;</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_VIDEO_ADV_DEBUG</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Counters for how often these queue-related ops are</span></span><br><span class="line"><span class="comment">     * called. Used to check for unbalanced ops.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    u32             cnt_queue_setup;</span><br><span class="line">    u32             cnt_wait_prepare;</span><br><span class="line">    u32             cnt_wait_finish;</span><br><span class="line">    u32             cnt_start_streaming;</span><br><span class="line">    u32             cnt_stop_streaming;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">在整个V4L2框架运转过程中，最为核心的是图像数据缓冲区的管理，而这个管理工作便是由vb2_queue来完成的，vb2_queue通常在打开设备的时候被创建，其结构体中的vb2_ops可以由驱动自己进行实现，而vb2_mem_ops代表了内存分配的方法集，另外，还有一个用于将管理用户空间和内核空间的相互传递的方法集buf_ops，而该方法集一般都定义为v4l2_buf_ops这一标准方法集。除了这些方法集外，vb2_queue还通过一个vb2_buffer的数组来管理申请的所有数据缓冲区，并且通过queued_list来管理入队状态的所有buffer，通过done_list来管理被填充了数据等待消费的所有buffer。</p>

<p style="text-indent:2em">vb2_buffer源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vb2_buffer</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span>    *<span class="title">vb2_queue</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        index;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        type;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        memory;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        num_planes;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_plane</span>    <span class="title">planes</span>[<span class="title">VB2_MAX_PLANES</span>];</span></span><br><span class="line">    u64         timestamp;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* private: internal use only</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * state:       current buffer state; do not change</span></span><br><span class="line"><span class="comment">     * queued_entry:    entry on the queued buffers list, which holds</span></span><br><span class="line"><span class="comment">     *          all buffers queued from userspace</span></span><br><span class="line"><span class="comment">     * done_entry:      entry on the list that stores all buffers ready</span></span><br><span class="line"><span class="comment">     *          to be dequeued to userspace</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">vb2_buffer_state</span>   <span class="title">state</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">queued_entry</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">done_entry</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了V4L2框架中的图像缓冲区，当处于入队状态时内部queued_entry会被链接到vb2_queue中的queued_list中，当处于等待消费的状态时其内部done_entry会被链接到vb2_queue 中的done_list中，而其中的vb2_queue便是该缓冲区的管理者。</p>

<p style="text-indent:2em">以上便是V4L2框架的几个核心结构体，从上面的简单分析不难看出，v4l2_device作为一个相机内核体系的顶层管理者，内部使用一个链表控制着所有从属子设备v4l2_subdev，使用vb2_queue来申请并管理所有数据缓冲区，并且通过video_device向用户空间暴露设备节点以及控制接口，接收来自用户空间的控制指令，通过将自身嵌入media controller中来实现枚举、连接子设备同时控制数据流走向的目的。</p>

<h3 id="模块初始化"><a href="#模块初始化" class="headerlink" title="模块初始化"></a>模块初始化</h3><p style="text-indent:2em">整个v4l2框架是在linux内核中实现的，所以按照内核驱动的运行机制，会在系统启动的过程中，通过标准的module_init方式进行初始化操作，而其初始化主要包含两个方面，一个是v4l2_device的初始化，一个是子设备的初始化，首先我们来看下v4l2_device的初始化动作的基本流程。</p>

<p style="text-indent:2em">由于驱动的实现都交由各个平台厂商进行实现，所有内部逻辑都各不相同，这里我们抽离出主要方法来进行梳理：</p>

<p style="text-indent:2em">首先对于v4l2_device的初始化而言，在系统启动的过程中，linux内核会找到module_init声明的驱动，调用其probe方法进行探测相应设备，一旦探测成功，便表示初始化工作完成。</p>

<p style="text-indent:2em">而在probe方法内部，主要做了以下操作：</p>

<ul>
<li>获取dts硬件信息，初始化部分硬件设备。</li>
<li>创建v4l2_device结构体，填充信息，通过v4l2_device_register方法向系统注册并且创建video设备节点。</li>
<li>创建media_device结构体，填充信息，通过media_device_register向系统注册，并创建media设备节点，并将其赋值给v4l2_device中的mdev。</li>
<li>创建v4l2_device的media_entity,并将其添加到media controller进行管理。</li>
</ul>
<p style="text-indent:2em">类似于v4l2_device的初始化工作，子设备的流程如下：</p>

<ul>
<li>获取dts硬件信息，初始化子设备硬件模块</li>
<li>创建v4l2_subdev结构体，填充信息，通过v4l2_device_register_subdev向系统注册，并将其挂载到v4l2_device设备中</li>
<li>创建对应的media_entity，并通过media_device_register_entity方法其添加到media controller中进行统一管理。</li>
<li>最后调用v4l2_device_register_subdev_nodes方法，为所有的设置了V4L2_SUBDEV_FL_HAS_DEVNODE属性的子设备创建设备节点。</li>
</ul>
<h3 id="处理用户空间请求"><a href="#处理用户空间请求" class="headerlink" title="处理用户空间请求"></a>处理用户空间请求</h3><p style="text-indent:2em">系统启动之后，初始化工作便已经完成，现在一旦用户想要使用图像采集功能，便会触发整个视频采集流程，会通过操作相应的video节点来获取图像数据，一般来讲，标准的V4L2框架只需要通过操作video节点即可，但是由于现在的硬件功能越来越复杂，常规的v4l2_controller已经满足不了采集需求，所以现在的平台厂商通常会暴露子设备的设备节点，在用户空间直接通过标准的字符设备控制接口来控制各个设备，而现在我们的目的是梳理V4L2框架，所以暂时默认不创建子设备节点，简单介绍下整个流程。</p>

<p style="text-indent:2em">在操作之前，还有一个准备工作需要做，那就是需要找到哪些是我们所需要的设备，而它的设备节点是什么，此时便可以通过打开media设备节点，并且通过ioctl注入MEDIA_IOC_ENUM_ENTITIES参数来获取v4l2_device下的video设备节点，该操作会调用到内核中的media_device_ioctl方法，而之后根据传入的命令，进而调用到media_device_enum_entities方法来枚举所有的设备。</p>

<p style="text-indent:2em">整个采集流程，主要使用三个标准字符设备接口来完成，分别是用于打开设备的open方法、用于控制设备的ioctl方法以及关闭设备的close方法。</p>

<ol>
<li><h4 id="打开设备-open"><a href="#打开设备-open" class="headerlink" title="打开设备(open)"></a>打开设备(open)</h4></li>
</ol>
<p style="text-indent:2em">一旦确认了我们需要操作的video节点是哪一个，便可以通过调用字符设备标准接口open方法来打开设备，而这个方法会首先陷入内核空间，然后调用file_operations中的open方法，再到v4l2_file_operations中的open方法，而该方法由驱动自己进行实现，其中主要包括了给各个硬件模块上电，并且调用vb2_queue_init方法创建并初始化一个vb2_queue用于数据缓冲区的管理。</p>

<ol start="2">
<li><h4 id="控制设备-ioctl"><a href="#控制设备-ioctl" class="headerlink" title="控制设备(ioctl)"></a>控制设备(ioctl)</h4></li>
</ol>
<p style="text-indent:2em">在打开设备之后，接下来的大部分操作都是通过ioctl方法来完成的，而在该方法中，会首先陷入到内核空间，之后调用字符设备的v4l2_fops中的v4l2_ioctl方法，而在该方法中又会去调用video_device的video_ioctl2方法，video_ioctl2方法定义了一系列video标准的方法，通过不同的命令在v4l2_ioctls中找到相应的标准方法实现，同时为了满足用户自定义命令的实现，在video_ioctl2方法中会去调用到之前注册video_device时赋予的ioctl_ops中的vidioc_default方法，在该方法中加入用户自己的控制逻辑。</p>

<p style="text-indent:2em">在整个控制流程中，首先通过命令VIDIOC_QUERYCAP来获取设备所具有的属性，通过VIDIOC_G_PARM/VIDIOC_S_PARM来分别获取和设置设备参数，在这一系列操作配置完成之后，便需要向内核申请用于数据流转的缓冲区(Buffer)，该操作通过命令VIDIOC_REQBUFS来完成，在内核部分主要调用了标准方法vb2_reqbufs，进而调用__vb2_queue_alloc来向内核申请已知个数的Buffer，并且将其存入之前创建的vb2_queue中进行管理。</p>

<p style="text-indent:2em">申请好了Buffer之后，便可以通过传入VIDIOC_QBUF命令将申请的Buffer入队，具体操作最终会调用vb2_qbuf方法，而在该方法中会从vb2_queue的bufs数组中取出Buffer，将其加入queued_list链表中，并且更新Buffer状态，等待数据的填充或者来自用户空间的出队操作。</p>

<p style="text-indent:2em">在完成上面的操作后，整个数据流并没有开始流转起来，所以需要下发VIDIOC_STREAMON命令来通知整个框架开始出数据，在驱动中主要会去调用vb2_streamon方法，进而调用vb2_start_streaming方法，其中该方法会去将队列中的的Buffer放入到相应的驱动中，等待被填充，紧接着会去调用vb2_queue.ops.start_streaming方法来通知设备开始出图，而该方法一般由驱动自己实现，最后会调用v4l2_subdev_call(subdev, video, s_stream, mode)方法通知各个子设备开始出图。</p>

<p style="text-indent:2em">当有图像产生时，会填充到之前传入的buffer中，并且调用vb2_buffer_done方法通知vb2_queue将buffer加入到done_list链表中，并更新状态为VB2_BUF_STATE_DONE。</p>

<p style="text-indent:2em">在整个数据流开启之后，并不会自动的将图像传入用户空间，必须通过VIDIOC_DQBUF命令来从设备中读取一个帧图像数据，具体操作是通过层层调用会调用到vb2_dqbuf方法，而在该方法中会调用__vb2_get_done_vb方法去从done_list中获取Buffer，如果当前链表为空则会等待最终数据准备好，如果有准备好的buffer便直接从done_list取出，并且将其从queued_list中去掉，最后通过__vb2_dqbuf方法将Buffer返回用户空间。</p>

<p style="text-indent:2em">获取到图像数据之后，便可以进行后期的图像处理流程了，在处理完成之后，需要下发VIDIOC_QBUF将此次buffer重新加入queued_list中，等待下一次的数据的填充和出队操作。</p>

<p style="text-indent:2em">但不需要进行图像的采集时，可以通过下发VIDIOC_STREAMOFF命令来停止整个流程，具体流程首先会调用v4l2_subdev_call(subdev, video, s_stream, 0)通知所有子设备停止出图操作，其次调用vb2_buffer_done唤醒可能的等待Buffer的线程，同时更新Buffer状态为VB2_BUF_STATE_ERROR，然后调用vb2_streamoff取消所有的数据流并更新vb2_queue.streaming的为disable状态。</p>

<ol start="3">
<li><h4 id="关闭设备-close"><a href="#关闭设备-close" class="headerlink" title="关闭设备(close)"></a>关闭设备(close)</h4></li>
</ol>
<p style="text-indent:2em">当确认不使用当前设备进行图像采集操作之后，便可以调用标准方法close来关闭设备。其中主要包括了调用vb2_queue_release方法释放了vb2_queue以及设备下电操作和相关资源的释放。</p><br>

<p style="text-indent:2em">通过上面的介绍，我相信我们已经对整个V4L2框架有了一个比较深入的认识， 然而对于一个优秀的软件架构而言，仅仅是支持现有的功能是远远不够的，随着功能的不断完善，势必会出现需要进行扩展的地方，而v4l2在设计之初便很好的考虑到了这一点，所以提供了用于扩展的方法集，开发者可以通过加入自定的命令来扩充整个框架，高通在这一点上做的非常好，在v4l2框架基础上，设计出了一个独特的KMD框架，提供给UMD CSL进行访问的接口。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">Android Camera 体系结构之七 相机硬件抽象层实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-11 14:57:09" itemprop="dateCreated datePublished" datetime="2021-06-11T14:57:09+08:00">2021-06-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-25 14:52:38" itemprop="dateModified" datetime="2021-06-25T14:52:38+08:00">2021-06-25</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">回顾高通平台Camera HAL历史，之前高通采用的是QCamera & MM-Camera架构，但是为了更精细化控制底层硬件(Sensor/ISP等关键硬件)，同时方便手机厂商自定义一些功能，现在提出了CamX-CHI架构，由于在CamX-CHI中完全看不到之前老架构的影子，所以它完全是一个全新的架构，它将一些高度统一的功能性接口抽离出来放到CamX中，将可定制化的部分放在CHI中供不同厂商进行修改，实现各自独有的特色功能，这样设计的好处显而易见，那便是即便开发者对于CamX并不是很了解，但是依然可以很方便的加入自定义的功能，从而降低了开发者在高通平台的开发门槛。</p>

<p style="text-indent:2em">接下来我们以最直观的目录结构入手对该架构做一个简单的认识，以下便是CamX-CHI基本目录结构：</p>

<p><img src="/.top//camx-chi.jpg" alt="img"></p>
<p style="text-indent:2em">该部分代码主要位于 vendor/qcom/proprietary/ 目录下，其中camx代表了通用功能性接口的代码实现集合(CamX)，chi-cdk代表了可定制化需求的代码实现集合(CHI)，从图中可以看出CamX部分对上作为HAL3接口的实现，对下通过v4l2框架与Kernel保持通讯，中间通过互相dlopen so库并获取对方操作接口的方式保持着与CHI的交互。</p>

<h4 id="camx-中有如下几个主要目录："><a href="#camx-中有如下几个主要目录：" class="headerlink" title="camx/中有如下几个主要目录："></a>camx/中有如下几个主要目录：</h4><ul>
<li>core/ ：用于存放camx的核心实现模块，如Session、Manager、Pipeline等结构的实现。其中还包含了主要用于实现HAL3接口的hal/目录，以及负责与CHI进行交互的chi/目录</li>
<li>csl/：用于存放主要负责camx与camera driver的通讯模块，为camx提供了统一的Camera driver控制接口</li>
<li>hwl/：硬件流程和用于存放自身具有独立运算能力的硬件node的实现，包括bps、ipe、ife、jpeg等，该部分node受csl管理。</li>
<li>swl/：软件流程和用于存放自身并不具有独立运算能力必须依靠CPU才能实现的node的实现。包括stats、jpeg、sensor等。</li>
</ul>
<h4 id="chi-cdk-vendor-中有如下几个主要目录："><a href="#chi-cdk-vendor-中有如下几个主要目录：" class="headerlink" title="chi-cdk/vendor/中有如下几个主要目录："></a>chi-cdk/vendor/中有如下几个主要目录：</h4><ul>
<li>chioverride/: 用于存放CHI实现的核心模块，负责与camx进行交互并且实现了CHI的总体框架以及具体的业务处理逻辑。</li>
<li>bin/: 用于存放平台相关的配置项</li>
<li>topology/: 拓扑图xml，用于存放用户自定义的usecase.xml配置文件</li>
<li>node/: 各个node的实现，用于存放用户自定义功能的node</li>
<li>module/: 模组驱动配置，用于存放不同sensor的配置文件，该部分在初始化sensor的时候需要用到</li>
<li>tuning/: 效果调试参数，用于存放不同场景下的效果参数的配置文件</li>
<li>sensor/: sensor驱动配置，用于存放不同sensor的私有信息以及寄存器配置参数</li>
<li>actuator/: VCM驱动配置，用于存放不同对焦模块的配置信息</li>
<li>ois/：ois驱动配置，用于存放防抖模块的配置信息</li>
<li>flash/：闪光灯驱动配置，存放着闪光灯模块的配置信息</li>
<li>eeprom/: eeprom驱动配置，存放着eeprom外部存储模块的配置信息</li>
<li>fd/: 人脸参数配置，存放了人脸识别模块的配置信息</li>
</ul>
<h3 id="基本组件概念"><a href="#基本组件概念" class="headerlink" title="基本组件概念"></a>基本组件概念</h3><h4 id="Usecase"><a href="#Usecase" class="headerlink" title="Usecase"></a>Usecase</h4><p style="text-indent:2em">作为CamX-CHI中最大的抽象概念，其中包含了多条实现特定功能的Pipeline，具体实现是在CHI中通过Usecase类完成的，该类主要负责了其中的业务处理以及资源的管理。Usecase类，提供了一系列通用接口，作为现有的所有Usecase的基类。其中AdvancedCameraUsecase又继承于CameraUsecaseBase，相机中绝大部分场景会通过实例化AdvancedCameraUsecase来完成，它包括了几个主要接口：</p>

<ul>
<li>Create(): 该方法是静态方法，用于创建一个AdvancedCameraUsecase实例，在其初始化方法中会调用SelectUsecaseConfig方法去获取XML中的相应的Usecase配置信息。</li>
<li>ExecuteCaptureRequest(): 该方法用于下发一次Request请求。</li>
<li>ProcessResultCb(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session数据处理完成的时候便会调用该方法将结果发送到AdvancedCameraUsecase中。</li>
<li>ProcessDriverPartialCaptureResult(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session中产生了partial metadata的时候，便会调用该方法将其发送至AdvancedCameraUsecase中。</li>
<li>ProcessMessageCb(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session产生任何事件，便会调用该方法通知到AdvancedCameraUsecase中。</li>
<li>ExecuteFlush(): 该方法用于刷新AdvancedCameraUsecase。</li>
<li>Destroy(): 该方法用于安全销毁AdvancedCameraUsecase。</li>
</ul>
<p style="text-indent:2em">Usecase的可定制化部分被抽象出来放在了(TARGET_PRODUCT)_usecase.xml中。这里简单介绍其中的几个主要的标签含义：</p>

<ul>
<li>UsecaseName: 代表了该Usecase的名字，后期根据这个名字找到这个Usecase的定义。</li>
<li>Targets: 用于表示用于输出的数据流的集合，其中包括了数据流的格式，输出Size的范围等。</li>
<li>Pipeline: 用于定义该Usecase可以使用的所有Pipeline，这里必须至少定义一条Pipeline。</li>
</ul>
<p style="text-indent:2em">根据chioverride/default/build/android/Android.mk文件规则，编译时会根据此xml的配置生成对应chioverride/default/g_pipelines.h。</p>

<h4 id="Feature"><a href="#Feature" class="headerlink" title="Feature"></a>Feature</h4><p style="text-indent:2em">代表了一个特定的功能，该功能需要多条Pipeline组合起来实现，受Usecase统一管理，在CHI中通过Feature类进行实现，在XML中没有对应的定义，具体的Feature选取工作是在Usecase中完成的，通过在创建Feature的时候，传入Usecase的实例的方式，来和Usecase进行相互访问各自的资源。以下是现有的Feature，其中Feature作为基类存在，定义了一系列通用方法。</p>

<p><img src="/.top//feature.jpg" alt="img"></p>
<p style="text-indent:2em">几个常用的Feature:</p>

<ul>
<li>FeatureHDR: 用于实现HDR功能，它负责管理内部的一条或者几条pipeline的资源以及它们的流转，最终输出具有HDR效果的图像。</li>
<li>FeatureMFNR: 用于实现MFNR功能，内部分为几个大的流程，分别包括Prefiltering、Blending、Postfilter以及最终的OfflineNoiseReproces(这一个是可选择使能的)，每一个小功能中包含了各自的pipeline。</li>
<li>FeatureASD: 用于AI功能的实现，在预览的时候，接收每一帧数据，并且进行分析当前场景的AI识别输出结果，并其通过诸如到metadata方式给到上层，进行后续的处理。</li>
</ul>
<h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><p style="text-indent:2em">
用于管理pipeline的抽象控制单元，一个Session中至少拥有一个pipeine，并且控制着所有的硬件资源，管控着每一个内部pipeline的request的流转以及数据的输入输出，它没有可定制化的部分，所以在CHI中的XML文件中并没有将Session作为一个独立的单元进行定义。Session的实现主要通过CamX中的Session类，其主要接口如下：</p>


<ul>
<li>Initialize(): 根据传入的参数SessionCreateData进行Session的初始化工作。</li>
<li>NotifyResult(): 内部的Pipeline通过该接口将结果发送到Session中。</li>
<li>ProcessCaptureRequest(): 该方法用于用户决定发送一个Request到Session中的时候调用。</li>
<li>StreamOn(): 通过传入的Pipeline句柄，开始硬件的数据传输。</li>
<li>StreamOff(): 通过传入的Pipeline句柄，停止硬件的数据传输。</li>
</ul>
<h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p style="text-indent:2em">作为提供单一特定功能的所有资源的集合，维护着所有硬件资源以及数据的流转，每一个Pipeline包括了其中的Node/Link，在CamX中通过Pipeline类进行实现，负责整条Pipeline的软硬件资源的维护以及业务逻辑的处理，接下来我们简单看下该类的几个主要接口：</p>

<ul>
<li>Create(): 该方法是一个静态方法，根据传入的PipelineCreateInputData信息来实例化一个Pipeline对象。</li>
<li>StreamOn(): 通知Pipeline开始硬件的数据传输</li>
<li>StreamOff(): 通知Pipeline停止硬件的数据传输</li>
<li>FinalizePipeline(): 用于完成Pipeline的设置工作</li>
<li>OpenRequest(): open一个CSL用于流转的Request</li>
<li>ProcessRequest(): 开始下发Request</li>
<li>NotifyNodeMetadataDone(): 该方法是Pipeline提供给Node，当Node内部生成了metadata，便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessMetadataRequestIdDone通知Session。</li>
<li>NotifyNodePartialMetadataDone(): 该方法是Pipeline提供给Node，当Node内部生成了partial metadata，便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessPartialMetadataRequestIdDone通知Session。</li>
<li>SinkPortFenceSignaled(): 用来通知Session 某个sink port的fence处于被触发的状态。</li>
<li>NonSinkPortFenceSignaled(): 用来通知Session 某个non sink port的fence处于被触发的状态。</li>
</ul>
<p style="text-indent:2em">Pipeline中的Node以及连接方式都在XML中被定义，其主要包含了以下几个标签定义：</p>

<ul>
<li>PipelineName: 用来定义该条Pipeline的名称</li>
<li>NodeList: 该标签中定义了该条Pipeline的所有的Node</li>
<li>PortLinkages: 该标签定义了Node上不同端口之间的连接关系</li>
</ul>
<h4 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h4><p style="text-indent:2em">作为单个具有独立处理功能的抽象模块，可以是硬件单元也可以是软件单元，关于Node的具体实现是CamX中的Node类来完成的，其中CamX-CHI中主要分为两个大类，一个是高通自己实现的Node包括硬件Node，一个是CHI中提供给用户进行实现的Node，其主要方法如下：</p>

<ul>
<li>Create(): 该方法是静态方法，用于实例化一个Node对象。</li>
<li>ExecuteProcessRequest(): 该方法用于针对hwl node下发request的操作。</li>
<li>ProcessRequestIdDone(): 一旦该Node当前request已经处理完成，便会通过调用该方法通知Pipeline。</li>
<li>ProcessMetadataDone(): 一旦该Node的当前request的metadata已经生成，便会通过调用该方法通知到Pipeline。</li>
<li>ProcessPartialMetadataDone(): 一旦该Node的当前request的partial metadata已经生成，便会通过调用该方法通知到Pipeline。</li>
<li>CreateImageBufferManager(): 创建ImageBufferManager</li>
</ul>
<p style="text-indent:2em">其可定制化的部分作为标签在XML中进行定义：</p>

<ul>
<li>NodeName： 用来定义该Node的名称</li>
<li>NodeId: 用来指定该Node的ID，其中IPE NodeId为65538，IFE NodeId为65536，用户自定义的NodeId为255。</li>
<li>NodeInstance: 用于定义该Node的当前实例的名称。</li>
<li>NodeInstanceId: 用于指定该Node实例的Id。</li>
</ul>
<h4 id="Link"><a href="#Link" class="headerlink" title="Link"></a>Link</h4><p style="text-indent:2em">用于定义不同Port的连接，一个Port可以根据需要建立多条与其它从属于不同Node的Port的连接，它通过标签来进行定义，其中包括了作为输入端口，作为输出端口。一个Link中包含了一个SrcPort和一个DstPort，分别代表了输入端口和输出端口，然后BufferProperties用于表示两个端口之间的buffer配置。</p>

<h4 id="Port"><a href="#Port" class="headerlink" title="Port"></a>Port</h4><p style="text-indent:2em">作为Node的输入输出的端口，在XML文件中，标签用来定义一个输入端口，标签用来定义输出端口，每一个Node都可以根据需要使用一个或者多个输入输出端口，使用OutputPort以及InputPort结构体来进行在代码中定义。</p>

<ul>
<li>PortName: 该端口的名称</li>
<li>PortId: 该端口的Id</li>
<li>NodeName: 该端口从属的Node名称</li>
<li>NodeId: 该端口从属的Node的Id</li>
<li>NodeInstance: 该端口从属的Node的实例名称</li>
<li>NodeInstanceId: 该端口从属的Node的实例的Id</li>
</ul>
<h3 id="组件结构关系"><a href="#组件结构关系" class="headerlink" title="组件结构关系"></a>组件结构关系</h3><p style="text-indent:2em">通过之前的介绍，我们对于几个基本组件有了一个比较清晰地认识，但是任何一个框架体系并不是仅靠组件胡乱堆砌而成的，相反，它们都必须基于各自的定位，按照各自所独有的行为模式，同时按照约定俗成的一系列规则组合起来，共同完成整个框架某一特定的功能。所以这里不得不产生一个疑问，在该框架中它们到底是如何组织起来的呢？它们之间的关系又是如何的呢？ 接下来我们以下图入手开始进行分析：</p>

<p><img src="/.top//relationship_between_components.jpg" alt="img"></p>
<p style="text-indent:2em">由上图可以看到，几者是通过包含关系组合起来的，Usecase 包含Feature，而Feature包含了Session，Session又维护了内部的Pipeline的流转，而每一条pipeline中又通过Link将所有Node都连接了起来，接下我们就这几种关系详细讲解下：</p>

<p style="text-indent:2em">首先，一个Usecase代表了某个特定的图像采集场景，比如人像场景，后置拍照场景等等，在初始化的时候通过根据上层传入的一些具体信息来进行创建，这个过程中，一方面实例化了特定的Usecase，这个实例是用来管理整个场景的所有资源，同时也负责其中的业务处理逻辑，另一方面，获取了定义在XML中的特定Usecase，获取了用于实现某些特定功能的pipeline。</p>

<p style="text-indent:2em">其次，在Usecase中，Feature是一个可选项，如果当前用户选择了HDR模式或者需要在Zoom下进行拍照等特殊功能的话，在Usecase创建过程中，便会根据需要创建一个或者多个Feature，一般一个Feature对应着一个特定的功能，如果场景中并不需要任何特定的功能，则也完全可以不使用也不创建任何Feature。</p>

<p style="text-indent:2em">然后，每一个Usecase或者Feature都可以包含一个或者多个Session，每一个Session都是直接管理并负责了内部的Pipeline的数据流转，其中每一次的Request都是Usecase或者Feature通过Session下发到内部的Pipeline进行处理，数据处理完成之后也是通过Session的方法将结果给到CHI中，之后是直接给到上层还是将数据封装下再次下发到另一个Session中进行后处理，这都交由CHI来决定。其中，Session和Pipeline是一对多的关系，通常一个Session只包含了一条Pipeline，用于某个特定图像处理功能的实现，但是也不绝对，比如FeatureMFNR中包含的Session就包括了三条pipeline，又比如后置人像预览，也是用一个Session包含了两条分别用于主副双摄预览的Pipeline，主要是要看当前功能需要的pipeline数量以及它们之间是否存在一定关联。</p>

<p style="text-indent:2em">同时，根据上面关于Pipeline的定义，它内部包含了一定数量的Node，并且实现的功能越复杂，所包含的Node也就越多，同时Node之间的连接也就越错综复杂，比如后置人像预览虚化效果的实现就是将拿到的主副双摄的图像通过RTBOfflinePreview这一条Pipeline将两帧图像合成一帧具有虚化效果的图像，从而完成了虚化功能。</p>

<p style="text-indent:2em">最后Pipeline中的Node的连接方式是通过XML文件中的Link来进行描述的，每一个Link定义了一个输入端和输出端分别对应着不同Node上面的输入输出端口，通过这种方式就将其中的一个Node的输出端与另外一个Node的输入端，一个一个串联起来，等到图像数据从Pipeline的起始端开始输入的时候，便可以按照这种定义好的轨迹在一个一个Node之间进行流转，而在流转的过程中每经过一个Node都会在内部对数据进行处理，这样等到数据从起始端一直流转到最后一个Node的输出端的时候，数据就经过了很多次处理，这些处理效果最后叠加在一起便是该Pipeline所要实现的功能，比如降噪、虚化等等。</p>

<h3 id="关键流程详解"><a href="#关键流程详解" class="headerlink" title="关键流程详解"></a>关键流程详解</h3><h4 id="Camera-Provider-启动初始化"><a href="#Camera-Provider-启动初始化" class="headerlink" title="Camera Provider 启动初始化"></a>Camera Provider 启动初始化</h4><p style="text-indent:2em">当系统启动的时候，Camera Provider主程序会被运行，在整个程序初始化的过程中会通过获取到的camera_module_t调用其get_number_of_camera接口获取底层支持的camera数量，由于是第一次获取，所以在CamX-CHI中会伴随着很多初始化动作，具体操作见下图：</p>

<p><img src="/.top//camera_provider_%E5%90%AF%E5%8A%A8%E5%88%9D%E5%A7%8B%E5%8C%96.jpg" alt="img"></p>
<p style="text-indent:2em">主要流程如下：</p>

<ol>
<li>通过HAL3Module::GetInstance()静态方法实例化了HAL3Module对象，在其构造方法里面通过HwEnvironment::GetInstance()静态方法又实例化了HwEnvironment对象，在其构造方法中，实例化了SettingsManager对象，然后又在它构造方法中通过OverrideSettingsFile对象获取了位于/vendor/etc/camera/camxoverridesettings.txt文件中的平台相关的配置信息（通过这种Override机制方便平台厂商加入自定义配置），该配置文件中，可以加入平台特定的配置项，比如可以通过设置multiCameraEnable的值来表示当前平台是否支持多摄，或者通过设置overrideLogLevels设置项来配置CamX-CHI部分的Log输出等级等等。</li>
<li>同时在HwEnvironment构造方法中会调用其Initialize方法，在该方法中实例化了CSLModeManager对象，并通过CSLModeManager提供的接口，获取了所有底层支持的硬件设备信息，其中包括了Camera Request Manager、CAPS模块(该驱动模块主要用于CSL获取Camera平台驱动信息，以及IPE/BPS模块的电源控制)以及Sensor/IPE/Flash等硬件模块，并且通过调用CSLHwInternalProbeSensorHW方法获取了当前设备安装的Sensor模组信息，并且将获取的信息暂存起来，等待后续阶段使用，总得来说在HwEnvironment初始化的过程中,通过探测方法获取了所有底层的硬件驱动模块，并将其信息存储下来供后续阶段使用。</li>
<li>之后通过调用HwEnvironment对象中的ProbeChiCompoents方法在/vendor/lib64/camera/components路径下找寻各个Node生成的So库，并获取Node提供的标准对外接口，这些Node不但包括CHI部分用户自定义的模块，还包括了CamX部分实现的硬件模块，并最后都将其都存入ExternalComponentInfo对象中，等待后续阶段使用。</li>
</ol>
<p style="text-indent:2em">另外在初始化阶段还有一个比较重要的操作就是CamX 与CHI是通过互相dlopen对方的So库，获取了对方的入口方法，最后通过彼此的入口方法获取了对方操作方法集合，之后再通过这些操作方法与对方进行通讯，其主要流程见下图：</p>

<p><img src="/.top//camx-chi-1620873829302.jpg" alt="img"></p>
<p style="text-indent:2em">从上图不难看出，在HAL3Module构造方法中会去通过dlopen方法加载com.qti.chi.override.so库，并通过dlsym映射出CHI部分的入口方法chi_hal_override_entry，并调用该方法将HAL3Module对像中的成员变量m_ChiAppCallbacks(CHIAppCallbacks)传入CHI中，其中包含了很多函数指针，这些函数指针分别对应着CHI部分的操作方法集中的方法，一旦进入到CHI中，就会将CHI本地的操作方法集合中的函数地址依次赋值给m_ChiAppCallbacks，这样CamX后续就可以通过这个成员变量调用到CHI中方法，从而保持了与CHI的通讯。</p>

<p style="text-indent:2em">同样地，CHI中的ExtensionModule在初始化的时候，其构造方法中也会通过调用dlopen方法加载camera.qcom.so库，并将其入口方法ChiEntry通过dlsym映射出来，之后调用该方法，将g_chiContextOps(ChiContextOps，该结构体中定义了很多指针函数)作为参数传入CamX中，一旦进入CamX中，便会将本地的操作方法地址依次赋值给g_chiContextOps中的每一个函数指针，这样CHI之后就可以通过g_chiContextOps访问到CamX方法。</p>

<h4 id="打开相机设备-初始化相机设备"><a href="#打开相机设备-初始化相机设备" class="headerlink" title="打开相机设备/初始化相机设备"></a>打开相机设备/初始化相机设备</h4><p style="text-indent:2em">一旦用户打开了相机应用，App中便会去调用CameraManager的openCamera方法，该方法之后会最终调用到Camera Service中的CameraService::connectDevice方法，然后通过ICameraDevice::open()这一个HIDL接口通知Provider，然后在Provider内部又通过调用之前获取的camera_module_t中common的methods的open方法来获取一个Camera 设备，对应于HAL中的camera3_device_t结构体，紧接着，在Provider中会继续调用获取到的camera3_device_t的initialize方法进行初始化动作。接下来我们便来详细分析下CamX-CHI对于open以及initialize的具体实现流程：</p>

<h5 id="open"><a href="#open" class="headerlink" title="open"></a>open</h5><p style="text-indent:2em">该方法是camera_module_t的标准方法，主要用来获取camera3_device_t设备结构体的，CamX-CHI对其进行了实现，open方法中完成的工作主要有以下几个：</p>

<ol>
<li>将当前camera id传入CHI中进行remap操作，当然这个remap操作逻辑完全是根据CHI中用户需求来的，用户可以根据自己的需要在CHI中加入自定义remap逻辑。</li>
<li>实例化HALDevice对象，其构造函数中调用Initialize方法，该方法会填充CamX中自定义的Camera3Device结构体。</li>
<li>将m_HALCallbacks.process_capture_result指向了本地方法ProcessCaptureResult以及m_HALCallbacks.notify_result指向了本地方法Notify(之后会在配置数据流的过程中，将m_HALCallbacks注册到CHI中， 一旦当CHI数据处理完成之后，便会通过这两个回调方法将数据或者事件回传给CamX)。</li>
<li>最后将HALDevice 中的Camera3Device成员变量作为返回值给到Provider中的CameraCaptureSession中。</li>
</ol>
<p style="text-indent:2em">Camera3Device 其实重定义了camera3_device_t，其中HwDevice对应于camera3_device_t中的hw_device_t，Camera3DeviceOps对应于camera3_device_ops_t，而在HALDevice的初始化过程中，会将CamX实现的HAL3接口的结构体g_camera3DeviceOps赋值给Camera3DeviceOps中。</p>

<h5 id="initialize"><a href="#initialize" class="headerlink" title="initialize"></a>initialize</h5><p style="text-indent:2em">该方法在调用open后紧接着被调用，主要用于将上层的回调接口传入HAL中，一旦有数据或者事件产生，CamX便会通过这些回调接口将数据或者事件上传至调用者，其内部的实现较为简单。</p>

<p style="text-indent:2em">initialize方法中有两个参数，分别是之前通过open方法获取的camera3_device_t结构体和实现了camera3_callback_ops_t的CameraDevice，很显然camera3_device_t结构体并不是重点，所以该方法的主要工作是将camera3_callback_ops_t与CamX关联上，一旦数据准备完成便通过这里camera3_callback_ops_t中回调方法将数据回传到Camera Provider中的CameraDevice中，基本流程可以总结为以下几点：</p>

<ol>
<li>实例化了一个Camera3CbOpsRedirect对象并将其加入了g_HAL3Entry.m_cbOpsList队列中，这样方便之后需要的时候能够顺利拿到该对象。</li>
<li>将本地的process_capture_result以及notify方法地址分别赋值给Camera3CbOpsRedirect.cbOps中的process_capture_result以及notify函数指针。</li>
<li>将上层传入的回调方法结构体指针pCamera3CbOpsAPI赋值给Camera3CbOpsRedirect.pCbOpsAPI，并将Camera3CbOpsRedirect.cbOps赋值给pCamera3CbOpsAPI，通过JumpTableHal3的initialize方法将pCamera3CbOpsAPI传给HALDevice中的m_pCamera3CbOps成员变量，这样HALDevice中的m_pCamera3CbOps就指向了CamX中本地方法process_capture_result以及notify。</li>
</ol>
<p style="text-indent:2em">经过这样的一番操作之后，一旦CHI有数据传入便会首先进入到本地方法ProcessCaptureResult，然后在该方法中获取到HALDevice的成员变量m_pCamera3CbOps，进而调用m_pCamera3CbOps中的process_capture_result方法，即camxhal3entry.cpp中定义的process_capture_result方法，然后这个方法中会去调用JumpTableHAL3.process_capture_result方法，该方法最终会去调用Camera3CbOpsRedirect.pCbOpsAPI中的process_capture_result方法，这样就调到从Provider传入的回调方法，将数据顺利给到了CameraCaptureSession中。</p>

<h4 id="配置相机设备数据流"><a href="#配置相机设备数据流" class="headerlink" title="配置相机设备数据流"></a>配置相机设备数据流</h4><p style="text-indent:2em">在打开相机应用过程中，App在获取并打开相机设备之后，会调用CameraDevice.createCaptureSession来获取CameraDeviceSession，并且通过Camera api v2标准接口，通知Camera Service，调用其CameraDeviceClient.endConfigure方法，在该方法内部又会去通过HIDL接口ICameraDeviceSession::configureStreams_3_4通知Provider开始处理此次配置需求，在Provider内部，会去通过在调用open流程中获取的camera3_device_t结构体的configure_streams方法来将数据流的配置传入CamX-CHI中，之后由CamX-CHI完成对数据流的配置工作，接下来我们来详细分析下CamX-CHI对于该标准HAL3接口 configure_streams的具体实现：</p>

<p style="text-indent:2em">配置数据流是整个CamX-CHI流程比较重要的一环，其中主要包括两个阶段：</p>

<ol>
<li>选择UsecaseId</li>
<li>根据选择的UsecaseId创建Usecase</li>
</ol>
<p style="text-indent:2em">接下来我们就这两个阶段分别进行详细介绍:</p>

<h5 id="①-选择UsecaseId"><a href="#①-选择UsecaseId" class="headerlink" title="① 选择UsecaseId"></a>① 选择UsecaseId</h5><p style="text-indent:2em">不同的UsecaseId分别对应的不同的应用场景，该阶段是通过调用UsecaseSelector::GetMatchingUsecase()方法来实现的，该函数中通过传入的operation_mode、num_streams配置数据流数量以及当前使用的Sensor个数来选择相应的UsecaseId，比如当numPhysicalCameras值大于1同时配置的数据流数量num_streams大于1时选择的就是UsecaseId::MultiCamera，表示当前采用的是双摄场景。</p>

<h5 id="②-创建Usecase"><a href="#②-创建Usecase" class="headerlink" title="② 创建Usecase"></a>② 创建Usecase</h5><p style="text-indent:2em">根据之前选择的UsecaseId，通过UsecaseFactory来创建相应的Usecase，其中Class Usecase是所有Usecase的基类，定义并实现了一些通用接口，CameraUsecaseBase继承于Usecase，并扩展了部分功能。AdvancedCameraUsecase又继承于CameraUsecaseBase，作为主要负责大部分场景的Usecase实现类，另外对于多摄场景，现提供了继承于AdvancedCameraUsecase的UsecaseMultiCamera来负责实现。除了双摄场景，其它大部分场景使用的都是AdvancedCameraUsecase类来管理各项资源的，接下来我们重点梳理下AdvancedCameraUsecase::Create()方法。在AdvancedCameraUsecase::Create方法中做了很多初始化操作，其中包括了以下几个阶段：</p>

<ol>
<li>获取XML文件中Usecase配置信息</li>
<li>创建Feature</li>
<li>保存数据流，重建Usecase的配置信息</li>
<li>调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作</li>
</ol>
<p style="text-indent:2em">接下来我们就这几个阶段逐一进行分析：</p>

<h6 id="获取XML文件中Usecase配置信息"><a href="#获取XML文件中Usecase配置信息" class="headerlink" title="获取XML文件中Usecase配置信息"></a>获取XML文件中Usecase配置信息</h6><p style="text-indent:2em">这一部分主要通过调用CameraUsecaseBase::GetXMLUsecaseByName方法进行实现。该方法的主要操作是从PerNumTargetUsecases数组中找到匹配到给定的usecaseName的Usecase，并作为返回值返回给调用者，其中这里我们以"UsecaseZSL“为例进行分析，PerNumTargetUsecases的定义是在g_pipeline.h中，该文件是在编译过程中通过usecaseconverter.pl脚本将定义在个平台目录下的common_usecase.xml中的内容转换生成g_pipeline.h。</p>

<h6 id="创建Feature"><a href="#创建Feature" class="headerlink" title="创建Feature"></a>创建Feature</h6><p>如果当前场景选取了Feature，则调用FeatureSetup来完成创建工作。</p>
<p>该方法主要是通过诸如operation_mode、camera数量以及UsecaseId等信息来决定需要选择哪些Feature,具体逻辑比较清晰，一旦决定需要使用哪一个Feature之后，便调用相应的Feature的Create()方法进行初始化操作。</p>
<h6 id="保存数据流，重建Usecase的配置信息"><a href="#保存数据流，重建Usecase的配置信息" class="headerlink" title="保存数据流，重建Usecase的配置信息"></a>保存数据流，重建Usecase的配置信息</h6><p>从Camera Service 传入的数据流，需要将其存储下来，供后续使用，同时高通针对Usecase也加入了Override机制，根据需要可以选择性地扩展Usecase，这两个步骤的实现主要是通过SelectUsecaseConfig方法来实现。</p>
<p>其中主要是调用以下两个方法来实现的：</p>
<p>ConfigureStream： 该方法将从上层配置的数据流指针存入AdvancedCameraUsecase中，其中包括了用于预览的m_pPreviewStream以及用于拍照的m_pSnapshotStream。</p>
<p>BuildUsecase： 这个方法用来重新在原有的Usecase上面加入了Feature中所需要的pipeline，并创建了一个新的Usecase，并将其存入AdvancedCameraUsecase中的m_pChiUsecase成员变量中，紧接着通过SetPipelineToSessionMapping方法将pipeline与Session进行关联。</p>
<h6 id="调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作"><a href="#调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作" class="headerlink" title="调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作"></a>调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作</h6>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/" class="post-title-link" itemprop="url">Android Camera 体系结构之六 相机硬件抽象层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:55:17 / 修改时间：14:56:37" itemprop="dateCreated datePublished" datetime="2021-06-11T14:55:17+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">始于谷歌的Treble开源项目，基于接口与实现分离的设计原则，谷歌加入了Camera Provider这一抽象层，该层作为一个独立进程存在于整个系统中，并且通过HIDL这一自定义语言成功地将Camera Hal Module从Camera Service中解耦出来，承担起了对Camera HAL的封装工作，纵观整个Android Camera系统，对于Camera Provider而言，对上是通过HIDL接口负责与Camera Service的跨进程通信，对下通过标准的HAL3接口下发针对Camera的实际操作，这俨然是一个中央枢纽般的调配中心的角色，而事实上正是如此，由此看来，对Camera Provider的梳理变得尤为重要，接下来就以我个人理解出发来简单介绍下Camera Provider。</p>

<p style="text-indent:2em">Camera Provider通过提供标准的HIDL接口给Camera Service进行调用，保持与Service的正常通信，其中谷歌将HIDL接口的定义直接暴露给平台厂商进行自定义实现，其中为了极大地减轻并降低开发者的工作量和开发难度，谷歌很好地封装了其跨进程实现细节，同样地，Camera Provider通过标准的HAL3接口，向下控制着具体的Camera HAL Module，而这个接口依然交由平台厂商负责去实现，而进程内部则通过简单的函数调用，将HIDL接口与HAL3接口完美的衔接起来，由此构成了Provider整体架构。</p>

<p><img src="/.top//provider.jpg" alt="img"></p>
<p style="text-indent:2em">由图中可以看出Camera Provider进程由两部分组成，一是运行在系统中的主程序通过提供了标准的HIDL接口保持了与Camera Service的跨进程通讯，二是为了进一步扩展其功能，通过dlopen方式加载了一系列so库，而其中就包括了实现了Camera HAL3接口的so库，而HAL3接口主要定义了用于实现图像控制的功能，其实现主要交由平台厂商或者开发者来完成，所以Camera HAL3 so库的实现各式各样，这里在高通平台上的实现就是我们本文重点需要分析的CamX-CHI框架。在开始梳理CamX-CHI之前，不防先从上到下，以接口为主线简单梳理下Camera Provider的各个部分:</p>

<h3 id="Camera-HIDL-接口"><a href="#Camera-HIDL-接口" class="headerlink" title="Camera HIDL 接口"></a>Camera HIDL 接口</h3><p style="text-indent:2em">首先需要明确一个概念，就是HIDL是一种自定义语言，其核心是接口的定义，而谷歌为了使开发者将注意力落在接口的定义上而不是机制的实现上，主动封装了HIDL机制的实现细节，开发者只需要通过*.hal文件定义接口，填充接口内部实际的实现即可，接下来来看下具体定义的几个主要接口：</p>

<p><img src="/.top//hidl.jpg" alt="img"></p>
<p style="text-indent:2em">因为HIDL机制本身是跨进程通讯的，所以Camera Service本身通过HIDL接口获取的对象都会有Bn端和Bp端，分别代表了Binder两端，接下来为了方便理解，我们都省略掉Bn/Bp说法,直接用具体接口类代表，忽略跨进程两端的区别。</p>

<p style="text-indent:2em">ICameraProvider.hal文件中定义了ICameraProvider接口类，由CameraProvider继承并实现，在Camera Provider启动的时候被实例化，主要接口如下：</p>

<ul>
<li>getCameraDeviceInterface_V3_x: 该方法主要用于Camera Service获取ICameraDevice，通过该对象可以控制Camera 设备的诸如配置数据流、下发request等具体行为。</li>
<li>setCallback： 将CameraService 实现的ICameraProviderCallback传入CameraProvider，一旦Provider有事件产生时便可以通过该对象通知Camera Service。</li>
</ul>
<p style="text-indent:2em">ICameraProviderCallback.hal文件中定义了ICameraProviderCallback回调接口类，该接口由Camera Service中的CameraProviderManager::ProviderInfo继承并实现，在Camera Service启动的时候被实例化，通过调用ICameraProvider::setCallback接口注册到Camera Provider中，其主要接口如下：</p>

<ul>
<li>cameraDeviceStatusChange： 将Camera 设备状态上传至Camera Service，状态由CameraDeviceStatus定义</li>
</ul>
<p style="text-indent:2em">ICameraDevice.hal文件中定义了ICameraDevice接口类，由CameraDevice::TrampolineDeviceInterface_3_2实现，其主要接口如下:</p>

<ul>
<li>open： 用于创建一个Camera设备，并且将Camera Service中继承ICameraDeviceCallback并实现了相应接口的Camera3Device作为参数传入Provider中，供Provider上传事件或者图像数据。</li>
<li>getCameraCharacteristics：用于获取Camera设备的属性。</li>
</ul>
<p style="text-indent:2em">ICameraDeviceCallback.hal文件中定义了ICameraDeviceCallback接口类，由Camera Service中的Camera3Device继承并实现，通过调用ICameraDevice::open方法注册到Provider中，其主要接口如下：</p>

<ul>
<li>processCaptureResult_3_4: 一旦有图像数据产生会通过调用该方法将数据以及metadata上传至Camera Service。</li>
<li>notify: 通过该方法上传事件至Camera Service中，比如shutter事件等。</li>
</ul>
<p style="text-indent:2em">ICameraDeviceSession.hal文件中定义了ICameraDeviceSession接口类，由CameraDeviceSession::TrampolineSessionInterface_3_2继承并实现，其主要接口如下：</p>

<ul>
<li>constructDefaultRequestSettings：用于创建默认的Request配置项。</li>
<li>configureStreams_3_5：用于配置数据流，其中包括了output buffer/Surface/图像格式大小等属性。</li>
<li>processCaptureRequest_3_4：下发request到Provider中，一个request对应着一次图像需求。</li>
<li>close: 关闭当前会话</li>
</ul>
<h3 id="Camera-Provider-主程序"><a href="#Camera-Provider-主程序" class="headerlink" title="Camera Provider 主程序"></a>Camera Provider 主程序</h3><p style="text-indent:2em">接下来进入到Provider内部去看看，整个进程是如何运转的，以下图为例进行分析:</p>

<p><img src="/.top//provider-process-flow.jpg" alt="img"></p>
<p style="text-indent:2em">在系统初始化的时候，系统会去运行android.hardware.camera.provider@2.4-service_64程序启动Provider进程，并加入HW Service Manager中接受统一管理，在该过程中实例化了一个LegacyCameraProviderImpl_2_4对象，并在其构造函数中通过hw_get_module标准方法获取HAL的camera_module_t结构体,并将其存入CameraModule对象中，之后通过调用该camera_modult_t结构体的init方法初始化HAL Module，紧接着调用其get_number_of_camera方法获取当前HAL支持的Camera数量，最后通过调用其set_callbacks方法将LegcyCameraProviderImpl_2_4(LegcyCameraProviderImpl_2_4继承了camera_modult_callback_t)作为参数传入CamX-CHI中，接受来自CamX-CHI中的数据以及事件，当这一系列动作完成了之后，Camera Provider进程便一直便存在于系统中，监听着来自Camera Service的调用。</p>

<p><img src="/.top//provider-process-flow1.jpg" alt="img"></p>
<p style="text-indent:2em">接下来以上图为例简单介绍下Provider中几个重要流程：</p>

<ul>
<li><p>Camera Service通过调用ICameraProvider的getCameraDeviceInterface_v3_x接口获取ICameraDevice，在此过程中，Provider会去实例化一个CameraDevice对象，并且将之前存有camera_modult_t结构体的CameraModule对象传入CameraDevice中，这样就可以在CameraDevice内部通过CameraModule访问到camera_module_t的相关资源，然后将CameraDevice内部类TrampolineDeviceInterface_3_2(该类继承并实现了ICameraDevice接口)返回给Camera Service。</p>
</li>
<li><p>Camera Service通过之前获取的ICameraDevice，调用其open方法来打开Camera设备，接着在Provider中会去调用CameraDevice对象的open方法，在该方法内部会去调用camera_module_t结构体的open方法，从而获取到HAL部分的camera3_device_t结构体，紧接着Provider会实例化一个CameraDeviceSession对象，并且将刚才获取到的camera3_device_t结构体以参数的方式传入CameraDeviceSession中，在CameraDeviceSession的构造方法中又会调用CameraDeviceSession的initialize方法，在该方法内部又会去调用camera3_device_t结构体的ops内的initialize方法开始HAL部分的初始化工作，最后CameraDeviceSession对象被作为camera3_callback_ops的实现传入HAL，接收来自HAL的数据或者具体事件，当一切动作都完成后，Provider会将CameraDeviceSession::TrampolineSessionInterface_3_2(该类继承并实现了ICameraDeviceSession接口)对象通过HIDL回调的方法返回给Camera Service中。</p>
</li>
<li><p>Camera Service通过调用ICameraDevcieSession的configureStreams_3_5接口进行数据流的配置，在Provider中，最终会通过调用之前获取的camera3_device_t结构体内ops的configure_streams方法下发到HAL中进行处理。</p>
</li>
<li><p>Camera Service通过调用ICameraDevcieSession的processCaptureRequest_3_4接口下发request请求到Provider中，在Provider中，最终依然会通过调用获取的camera3_device_t结构体内ops中的process_capture_request方法将此次请求下发到HAL中进行处理。</p>
</li>
</ul>
<p style="text-indent:2em">从整个流程不难看出，这几个接口最终对应的是HAL3的接口，并且Provider并没有经过太多复杂的额外的处理。</p>

<h3 id="Camera-HAL3-接口"><a href="#Camera-HAL3-接口" class="headerlink" title="Camera HAL3 接口"></a>Camera HAL3 接口</h3><p style="text-indent:2em">HAL(Hardware Abstraction Layer,硬件抽象层)，是谷歌开发的用于屏蔽底层硬件抽象出来的一个软件层， 每一个平台厂商可以将不开源的代码封装在这一层，仅仅提供二进制文件。该层定义了自己的一套通用标准接口，平台厂商务必按照以下规则定义自己的Module:</p>

<ul>
<li>每一个硬件模块都通过hw_module_t来描述，具有固定的名字HMI</li>
<li>每一个硬件模块都必须实现hw_module_t里面的open方法，用于打开硬件设备，并返回对应的操作接口集合</li>
<li>硬件的操作接口集合使用hw_device_t 来描述，并可以通过自定义一个更大的包含hw_device_t的结构体来拓展硬件操作集合</li>
</ul>
<p style="text-indent:2em">其中代表硬件模块的是hw_module_t，对应的设备是通过hw_device_t来描述，从这两者的定义可以看出，主要是通过hw_module_t 代表了模块，通过其open方法用来打开一个设备，而该设备是用hw_device_t来表示，其中除了用来关闭设备的close方法外，并无其它方法，由此可见谷歌定义的HAL接口，并不能满足绝大部分HAL模块的需要，所以谷歌想出了一个比较好的解决方式，那便是将这两个基本结构嵌入到更大的结构体内部，同时在更大的结构内部定义了各自模块特有的方法，用于实现模块的功能，这样，一来对上保持了HAL的统一规范，二来也扩展了模块的功能。</p>

<p style="text-indent:2em">基于上面的方式，谷歌便针对Camera 提出了HAL3接口，其中主要包括了用于代表一系列操作主体的结构体以及具体操作函数，接下来我们分别进行详细介绍：</p>

<h4 id="核心结构体解析"><a href="#核心结构体解析" class="headerlink" title="核心结构体解析"></a>核心结构体解析</h4><p style="text-indent:2em">HAL3中主要定义了
camera_module_t/camera3_device_t/camera3_stream_configuration/camera3_stream以及camera3_stream_buffer几个主要结构体。</p>


<p style="text-indent:2em">由其中camera_module_t以及camera3_device_t代码定义不难发现，camera_module_t包含了hw_module_t，主要用于表示Camera模块，其中定义了诸如get_number_of_cameras以及set_callbacks等扩展方法，而camera3_device_t包含了hw_device_t，主要用来表示Camera设备，其中定义了camera3_device_ops操作方法集合，用来实现正常获取图像数据以及控制Camera的功能。</p>

<p style="text-indent:2em">结构体camera3_stream_configuration主要用来代表配置的数据流列表，内部装有上层需要进行配置的数据流的指针，内部的定义简单介绍下：</p>

<ul>
<li>num_streams: 代表了来自上层的数据流的数量，其中包括了output以及input stream。</li>
<li>streams: 是streams的指针数组，包括了至少一条output stream以及至多一条input stream。</li>
<li>operation_mode: 当前数据流的操作模式，该模式在camera3_stream_configuration_mode_t中被定义，HAL通过这个参数可以针对streams做不同的设置。</li>
<li>session_parameters: 该参数可以作为缺省参数，直接设置为NULL即可，CAMERA_DEVICE_API_VERSION_3_5以上的版本才支持。</li>
</ul>
<p style="text-indent:2em">camera3_stream_t结构体主要用来代表具体的数据流实体，在整个的配置过程中，需要在上层进行填充，当下发到HAL中后，HAL会针对其中的各项属性进行配置，这里便简单介绍下其内部的各个元素的意义：</p>

<ul>
<li>stream_type: 表示数据流的类型，类型在camera3_stream_type_t中被定义。</li>
<li>width： 表示当前数据流中的buffer的宽度。</li>
<li>height: 表示当前数据流中buffer的高度。</li>
<li>format: 表示当前数据流中buffer的格式，该格式是在system/graphics.h中被定义。</li>
<li>usage： 表示当前数据流的gralloc用法，其用法定义在gralloc.h中。</li>
<li>max_buffers： 指定了当前数据流中可能支持的最大数据buffer数量。</li>
<li>data_space: 指定了当前数据流buffer中存储的图像数据的颜色空间。</li>
<li>rotation：指定了当前数据流的输出buffer的旋转角度，其角度的定义在camera3_stream_rotation_t中，该参数由Camera Service进行设置，必须在HAL中进行设置，该参数对于input stream并没有效果。</li>
<li>physical_camera_id： 指定了当前数据流从属的物理camera Id。</li>
</ul>
<p style="text-indent:2em">结构体camera3_stream_buffer_t主要用来代表具体的buffer对象，其中重要元素如下：</p>

<ul>
<li>stream: 代表了从属的数据流</li>
<li>buffer：buffer句柄</li>
</ul>
<h4 id="核心接口函数解析"><a href="#核心接口函数解析" class="headerlink" title="核心接口函数解析"></a>核心接口函数解析</h4><p style="text-indent:2em">HAL3的核心接口都是在camera3_device_ops中被定义,该结构体定义了一系列的函数指针，用来指向平台厂商实际的实现方法，接下来就其中几个方法简单介绍下：</p>

<h5 id="a-initialize"><a href="#a-initialize" class="headerlink" title="a) initialize"></a>a) initialize</h5><p style="text-indent:2em">该方法必须在camera_module_t中的open方法之后，其它camera3_device_ops中方法之前被调用，主要用来将上层实现的回调方法注册到HAL中，并且根据需要在该方法中加入自定义的一些初始化操作，另外，谷歌针对该方法在性能方面也有严格的限制，该方法需要在5ms内返回，最长不能超过10ms。


</p><h5 id="b-configure-streams"><a href="#b-configure-streams" class="headerlink" title="b) configure_streams"></a>b) configure_streams</h5><p style="text-indent:2em">该方法在完成initialize方法之后，在调用process_capture_request方法之前被调用，主要用于重设当前正在运行的Pipeline以及设置新的输入输出流，其中它会将stream_list中的新的数据流替换之前配置的数据流。在调用该方法之前必须确保没有新的request下发并且当前request的动作已经完成，否则会引起无法预测的错误。一旦HAL调用了该方法，则必须在内部配置好满足当前数据流配置的帧率，确保这个流程的运行的顺畅性。其中包含了两个参数，分别是camera3_device以及stream_list(camera3_stream_configuration_t ),其中第二个参数是上层传入的数据流配置列表，该列表中必须包含至少一个output stream，同时至多包含一个input stream。另外，谷歌针对该方法有着严格的性能要求，平台厂商在实现该方法的时候，需要在500ms内返回，最长不能超过1000ms。</p>

<h5 id="c-construct-default-request-settings"><a href="#c-construct-default-request-settings" class="headerlink" title="c) construct_default_request_settings"></a>c) construct_default_request_settings</h5><p style="text-indent:2em">该方法主要用于构建一系列默认的Camera Usecase的capture设置项，通过camera_metadata_t来进行描述，其中返回值是一个camera_metadata_t指针，其指向的内存地址是由HAL来进行维护的，同样地，该方法需要在1ms内返回，最长不能超过5ms。</p>

<h5 id="d-process-capture-request"><a href="#d-process-capture-request" class="headerlink" title="d) process_capture_request"></a>d) process_capture_request</h5><p style="text-indent:2em">该方法用于下发单次新的capture request到HAL中， 上层必须保证该方法的调用都是在一个线程中完成，而且该方法是异步的，同时其结果并不是通过返回值给到上层，而是通过HAL调用另一个接口process_capture_result()来将结果返回给上层的，在使用的过程中，通过in-flight机制，保证短时间内下发足够多的request，从而满足帧率要求。</p>

<p style="text-indent:2em">该方法的性能依然受到谷歌的严格要求，规定其需要在一帧图像处理完的时长内返回，最长不超过4帧图像处理完成的时长，比如当前预览帧率是30帧，则该方法的操作耗时最长不能超过120ms，否则便会引起明显的帧抖动，从而影响用户体验。</p>

<h5 id="e-dump"><a href="#e-dump" class="headerlink" title="e) dump"></a>e) dump</h5><p style="text-indent:2em">该方法用于打印当前Camera设备的状态，一般是由上层通过dumpsys工具输出debug dump信息或者主动抓取bugreport的时候被调用，该方法必须是非阻塞实现，同时需要保证在1ms内返回，最长不能超过10ms。</p>

<h5 id="f-flush"><a href="#f-flush" class="headerlink" title="f) flush"></a>f) flush</h5><p style="text-indent:2em">当上层需要执行新的configure_streams的时候，需要调用该方法去尽可能快地清除掉当前已经在处理中的或者即将处理的任务，为配置数据流提供一个相对稳定的环境，其具体工作如下：</p>

<ul>
<li>所有的还在流转的request会尽可能快的返回</li>
<li>并未开始进行流转的request会直接返回，并携带错误信息</li>
<li>任何可以打断的硬件操作会立即被停止</li>
<li>任何无法进行打断的硬件操作会在当前状态下进行休眠</li>
</ul>
<p style="text-indent:2em">flush会在所有的buffer都得以释放，所有request都成功返回后才真正返回，该方法需要在100ms内返回，最长不能超过1000ms。</p>

<p style="text-indent:2em">上面的一系列方法是上层直接对下控制Camera Hal，而一旦Camera Hal产生了数据或者事件的时候，可以通过camera3_callback_ops中定义的回调方法将数据或者事件返回至上层，该结构体中常用的回调方法主要有两个：用于返回数据的process_capture_result以及用于返回事件的notify，接下来分别介绍下：</p>

<ul>
<li>process_capture_result</li>
</ul>
<p style="text-indent:2em">该方法用于返回HAL部分产生的metadata和image buffers，它与request是多对一的关系，同一个request，可能会对应到多个result，比如可以通过调用一次该方法用于返回metadata以及低分辨率的图像数据，再调用一次该方法用于返回jpeg格式的拍照数据，而这两次调用时对应于同一个process_capture_request动作。同一个Request的Metadata以及Image Buffers的先后顺序无关紧要，但是同一个数据流的不同Request之间的Result必须严格按照Request的下发先后顺序进行依次返回的，如若不然，会导致图像数据显示出现顺序错乱的情况。该方法是非阻塞的，而且并且必须要在5ms内返回。</p>

<ul>
<li>notify</li>
</ul>
<p style="text-indent:2em">该方法用于异步返回HAL事件到上层，必须非阻塞实现，而且要在5ms内返回。</p>



<p style="text-indent:2em">谷歌为了将系统框架和平台厂商的自定义部分相分离，在Android上推出了Treble项目，该项目直接将平台厂商的实现部分放入vendor分区中进行管理，进而与system分区保持隔离，这样便可以在相互独立的空间中进行各自的迭代升级，而互不干扰，而在相机框架体系中，便将Camera HAL Module从Camera Service中解耦出来，放入独立进程Camera Provider中进行管理，而为了更好的进行跨进程访问，谷歌针对Provider提出了HIDL机制用于Camera Service对于Camera Provier的访问，而HIDL接口的实现是在Camera Provider中实现，针对Camera HAL Module的控制又是通过谷歌制定的Camera HAL3接口来完成，所以由此看来，Provider的职责也比较简单，通过HIDL机制保持与Camera Service的通信，通过HAL3接口控制着Camera HAL Module。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%94-%E7%9B%B8%E6%9C%BA%E6%9C%8D%E5%8A%A1%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%94-%E7%9B%B8%E6%9C%BA%E6%9C%8D%E5%8A%A1%E5%B1%82/" class="post-title-link" itemprop="url">Android Camera 体系结构之五 相机服务层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:54:02 / 修改时间：14:54:34" itemprop="dateCreated datePublished" datetime="2021-06-11T14:54:02+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p style="text-indent:2em">Camera Service被设计成一个独立进程，作为一个服务端，处理来自Camera Framework 客户端的跨进程请求，并在内部进行一定的操作，随后作为客户端将请求再一次发送至作为服务端的Camera Provider，整个流程涉及到了两个跨进程操作，前者通过aidl机制实现，后者通过HIDL机制实现，由于在于Camera Provider通信的过程中，Service是作为客户端存在的，所以此处我们重点关注aidl以及Camera Service 主程序的实现。</p>

<p><img src="/.top//cameraserver.jpg" alt="img"></p>
<h3 id="Camera-AIDL-接口"><a href="#Camera-AIDL-接口" class="headerlink" title="Camera AIDL 接口"></a>Camera AIDL 接口</h3><p style="text-indent:2em">在介绍Camera AIDL之前，不妨来简单了解下何为AIDL，谷歌为什么要实现这么一套机制？</p>

<p style="text-indent:2em">在Android系统中，两个进程通常无法相互访问对方的内存，为了解决该问题，谷歌提出了Messager、广播以及后来的Binder，来解决这个问题，但是如果某个进程需要对另一个进程中进行多线程的并发访问，Messager和广播效果往往不是很好，所以Binder会作为主要实现方式，但是Binder的接口使用起来比较复杂，对开发者特别是初学者并不是很友好，所以为了降低跨进程开发门槛，谷歌开创性地提出了AIDL(自定义语言)机制，主动封装了Binder的实现细节，提供给开发者较为简单的使用接口，极大地提升了广大开发者的开发效率。</p>

<p style="text-indent:2em">按照谷歌的针对AIDL机制的要求，需要服务端创建一系列*.aidl文件，并在其中定义需要提供给客户端的公共接口，并且予以实现，接下来我们来看下几个主要的aidl文件。</p>

<p><img src="/.top//camera-aidl.jpg" alt="img"></p>
<p style="text-indent:2em">ICameraService.aidl定义了ICameraService 接口，实现主要通过CameraService类来实现，主要接口如下：</p>

<ul>
<li>getNumberOfCameras： 获取系统中支持的Camera 个数</li>
<li>connectDevice：打开一个Camera 设备</li>
<li>addListener: 添加针对Camera 设备以及闪光灯的监听对象</li>
</ul>
<p style="text-indent:2em">ICameraServiceListener.aidl定义了ICameraServiceListener接口，由Framework中的CameraManagerGlobal类实现，主要接口如下：</p>

<ul>
<li>onStatusChanged： 用于告知当前Camera 设备的状态的变更</li>
<li>onTorchStatusChanged:</li>
</ul>
<p style="text-indent:2em">ICameraDeviceUser.aidl定义了ICameraDeviceUser接口，由CameraDeviceClient最终实现，主要接口如下：</p>

<ul>
<li>disconnect： 关闭Camera 设备</li>
<li>submitRequestList：发送request</li>
<li>beginConfigure： 开始配置Camera 设备，需要在所有关于数据流的操作之前</li>
<li>endConfigure： 结束关于Camera 设备的配置，该接口需要在所有Request下发之前被调用</li>
<li>createDefaultRequest： 创建一个具有默认配置的Request</li>
</ul>
<p style="text-indent:2em">ICameraDeviceCallbacks.aidl文件中定义了ICameraDeviceCallbacks接口，其实现主要由Framework中的CameraDeviceCallbacks类进行实现，主要接口如下：</p>

<ul>
<li>onResultReceived： 一旦Service收到结果数据，便会调用该接口发送至Framework</li>
<li>onCaptureStarted： 一旦开始进行图像的采集，便调用该接口将部分信息以及时间戳上传至Framework</li>
<li>onDeviceError: 一旦发生了错误，通过调用该接口通知Framework</li>
</ul>
<h3 id="Camera-Service-主程序"><a href="#Camera-Service-主程序" class="headerlink" title="Camera Service 主程序"></a>Camera Service 主程序</h3><p style="text-indent:2em">Camera Service 主程序，是随着系统启动而运行，主要目的是向外暴露aidl接口给Framework进行调用，同时通过调用Camera Provider的HIDL接口，建立与Provider的通信，并且在内部维护从Framework以及Provider获取到的资源，并且按照一定的框架结构保持整个Service在稳定高效的状态下运行，所以接下来我们主要通过几个关键类、初始化过程以及处理来自App的请求三个部分来详细介绍下。</p>

<h4 id="1-关键类解析"><a href="#1-关键类解析" class="headerlink" title="1. 关键类解析"></a>1. 关键类解析</h4><p style="text-indent:2em">首先我们来看下几个关键类，Camera Service中主要包含了以下几个类，用于提供aidi接口，并负责内部一系列逻辑的控制，并且通过HIDL接口保持与Provider的通信。</p>

<p><img src="/.top//cameraservice.jpg" alt="img"></p>
<p style="text-indent:2em">首先我们看下CameraService的这个类，它主要实现了aidl中ICameraService 接口，并且暴露给Camera Framework进行调用，这个类在初始化的时候会去实例化一个CameraProviderManager对象，而在实例化的过程中，该对象会去获取系统中所有的Camera Provider，并且在其内部实例化了对应Provider个数的ProviderInfo对象，并且随着每一个ProviderInfo的实例化，将每一个Camera Provider作为参数存入ProviderInfo中，并且最终将所有的ProviderInfo存入一个vector容器中进行统一管理，就这样，CameraProviderManager便达到了管理所有的Camera Provider的目的。</p>

<p style="text-indent:2em">而对于单个ProviderInfo而言，内部会维护一个Camera Provider代理，而在系统运行初期，ProviderInfo会去向Camera Provider获取当前这设备所支持的Camera 设备，拿到Camera Provider中的ICameraDevice代理，并且依次存入提前实例化好的DeviceInfo3对象中，最后会将所有的DeviceInfo3存入一个内部容器，进行统一管理，而DeviceInfo3维护着Camera Provider中的ICameraDevice代理，保持了对Camera Provider的控制。</p>

<p style="text-indent:2em">另外，Camera Service 中还包含了CameraDeviceClient类，该类在打开设备的时候被实例化，一次打开设备的操作对应一个该类对象，它实现了ICameraDeviceUser接口，以aidl方式暴露接口给Camera Framework进行调用，于此同时，该类在打开设备的过程中，获取了来自Camera Framework对于ICameraDeviceCallback接口的实现代理，通过该代理可以将结果上传至Camera Framework中，其中还包含了一个Camera3Device以及FrameProcessorBase，Camera3Device主要实现了对Camera Provider 的ICameraDeviceCallbacks回调接口，通过该接口接收来自Provider的结果上传，进而传给CameraDeviceClient以及FrameProcessBase，其中，Camera3Device会将事件通过notify方法给到CameraDeviceClient，而metadata以及imagedata 会给到FrameProcessBase，进而给到CameraDeviceClient，所以FrameProcessBase主要用于metadata以及imagedata的中转处理。而Camera3Device中RequestThread主要用于处理Request的接收与下发工作。</p>

<p style="text-indent:2em">对于CameraService而言，主要包括了两个阶段，一个是系统刚启动的时候，会通过运行其主程序将其CameraService 服务运行起来，等待Camera Framework的下发图像需求，另一个阶段就是当用户打开相机应用的时候，会去获取相机设备，进而开始图像采集过程，接下来我们就主要以这两个阶段分别来详细介绍下内部运行逻辑。</p>

<h4 id="2-启动初始化"><a href="#2-启动初始化" class="headerlink" title="2. 启动初始化"></a>2. 启动初始化</h4><p style="text-indent:2em">当系统启动的时候，会首先运行Camera Service的主程序，将整个进程运行起来，这里我们首先来看下Camera Service 是怎样运行起来的。</p>

<p><img src="/.top//flow.jpg" alt="img"></p>
<p style="text-indent:2em">当系统启动的时候会首先运行main_cameraserver程序，紧接着调用了CameraService的instantiate方法，该方法最终会调用到CameraService的onFirstRef方法，在这个方法里面便开始了整个CameraService的初始化工作。而在onFirstRef方法内又调用了enumerateProviders方法，该方法中主要做了两个工作：</p>

<ul>
<li>一个是实例化一个CameraProviderManager对象，该对象管理着有关Camera Provider的一些资源。</li>
<li>一个是调用CameraProviderManager的initialize方法对其进行初始化工作。</li>
</ul>
<p style="text-indent:2em">而在CameraProviderManager初始化的过程中，主要做了三件事：</p>

<ul>
<li>首先通过getService方法获取<strong>ICameraProvider</strong>代理。</li>
<li>随后实例化了一个ProviderInfo对象，之后调用其initialize方法进行初始化。</li>
<li>最后将ProviderInfo加入到一个内部容器中进行管理。</li>
</ul>
<p style="text-indent:2em">而在调用ProviderInfo的initialize方法进行初始化过程中存在如下几个动作：</p>

<ul>
<li>首先接收了来自CameraProviderManager获取的ICameraProvider代理并将其存入内部成员变量中。</li>
<li>其次由于<strong>ProviderInfo</strong>实现了ICameraProviderCallback接口，所以紧接着调用了ICameraProvider的setCallback将自身注册到Camera Provider中，接收来自Provider的事件回调。</li>
<li>再然后，通过调用ICameraProvider代理的<strong>getCameraDeviceInterface_V3_X</strong>接口，获取Provider端的<strong>ICameraDevice</strong>代理，并且将这个代理作为参数加入到DeviceInfo3对象实例化方法中，而在实例化<strong>DeviceInfo3</strong>对象的过程中会通过ICameraDevice代理的<strong>getCameraCharacteristics</strong>方法获取该设备对应的属性配置，并且保存在内部成员变量中。</li>
<li>最后ProviderInfo会将每一个DeviceInfo3存入内部的一个容器中进行统一管理，至此整个初始化的工作已经完成。</li>
</ul>
<p style="text-indent:2em">通过以上的系列动作，Camera Service进程便运行起来了，获取了Camera Provider的代理，同时也将自身关于Camera Provider的回调注册到了Provider中，这就建立了与Provider的通讯，另一边，通过服务的形式将aidl接口也暴露给了Framework，静静等待来自Framework的请求。</p>

<h4 id="3-处理App请求"><a href="#3-处理App请求" class="headerlink" title="3. 处理App请求"></a>3. 处理App请求</h4><p style="text-indent:2em">一旦用户打开了相机应用，便会去调用CameraManager的openCamera方法进而走到Framework层处理，Framework通过内部处理，最终将请求下发到Camera Service中，而在Camera Service主要做了获取相机设备属性、打开相机设备，然后App通过返回的相机设备，再次下发创建Session以及下发Request的操作，接下来我们来简单梳理下这一系列请求在Camera Service中是怎么进行处理的。</p>

<h5 id="a-获取属性"><a href="#a-获取属性" class="headerlink" title="a) 获取属性"></a>a) 获取属性</h5><p style="text-indent:2em">对于获取相机设备属性动作，逻辑比较简单，由于在Camera Service启动初始化的时候已经获取了相应相机设备的属性配置，并存储在DeviceInfo3中，所以该方法就是从对应的DeviceInfo3中取出属性返回即可。</p>

<h5 id="b-打开相机设备"><a href="#b-打开相机设备" class="headerlink" title="b) 打开相机设备"></a>b) 打开相机设备</h5><p style="text-indent:2em">对于打开相机设备动作，主要由connectDevice来实现，内部实现比较复杂，接下来我们详细梳理下。</p>

<p style="text-indent:2em">当CameraFramework通过调用ICameraService的connectDevice接口的时候，主要做了两件事情：</p>

<ul>
<li>一个是创建CameraDeviceClient。</li>
<li>一个是对CameraDeviceClient进行初始化，并将其给到Framework。</li>
</ul>
<p style="text-indent:2em">而其中创建CameraDevcieClient的工作是通过makeClient方法来实现的，在该方法中首先实例化一个CameraDeviceClient，并且将来自Framework针对ICameraDeviceCallbacks的实现类CameraDeviceImpl.CameraDeviceCallbacks存入CameraDeviceClient中，这样一旦有结果产生便可以将结果通过这个回调回传给Framework，其次还实例化了一个Camera3Device对象。</p>

<p style="text-indent:2em">其中的CameraDeviceClient的初始化工作是通过调用其initialize方法来完成的，在该方法中：</p>

<ul>
<li>首先调用父类Camera2ClientBase的initialize方法进行初始化。</li>
<li>其次实例化FrameProcessorBase对象并且将内部的Camera3Device对象传入其中，这样就建立了FrameProcessorBase和Camera3Device的联系，之后将内部线程运行起来，等待来自Camera3Device的结果。</li>
<li>最后将CameraDeviceClient注册到FrameProcessorBase内部，这样就建立了与CameraDeviceClient的联系。</li>
</ul>
<p style="text-indent:2em">而在Camera2ClientBase的intialize方法中会调用Camera3Device的intialize方法对其进行初始化工作，并且通过调用Camera3Device的setNotifyCallback方法将自身注册到Camera3Device内部，这样一旦Camera3Device有结果产生就可以发送到CameraDeviceClient中。</p>

<p style="text-indent:2em">而在Camera3Device的初始化过程中，首先通过调用CameraProviderManager的openSession方法打开并获取一个Provider中的ICameraDeviceSession代理，其次实例化一个HalInterface对象，将之前获取的ICameraDeviceSession代理存入其中，最后将RequestThread线程运行起来，等待Request的下发。而对于CameraProviderManager的openSession方法，它会通过内部的DeviceInfo保存的ICameraDevice代理，调用其open方法从Camera Provider中打开并获取一个ICameraDeviceSession远程代理，并且由于Camera3Device实现了Provider中ICameraDeviceCallback方法，会通过该open方法传入到Provider中，接收来自Provider的结果回传。</p>

<p style="text-indent:2em">至此，整个connectDevice方法已经运行完毕，此时App已经获取了一个Camera设备，紧接着，由于需要采集图像，所以需要再次调用CameraDevice的createCaptureSession操作，到达Framework，再通过ICameraDeviceUser代理进行了一系列操作，分别包含了cancelRequest/beginConfigure/deleteStream/createStream以及endConfigure方法来进行数据流的配置。</p>

<h5 id="c-配置数据流"><a href="#c-配置数据流" class="headerlink" title="c) 配置数据流"></a>c) 配置数据流</h5><p style="text-indent:2em">其中cancelRequest逻辑比较简单，对应的方法是CameraDeviceClient的cancelRequest方法，在该方法中会去通知Camera3Device将RequestThread中的Request队列清空，停止Request的继续下发。</p>

<p style="text-indent:2em">beginConfigure方法是空实现，这里不进行阐述。</p>

<p style="text-indent:2em">deleteStream/createStream 分别是用于删除之前的数据流以及为新的操作创建数据流。</p>

<p style="text-indent:2em">紧接着调用位于整个调用流程的末尾–endConfigure方法，该方法对应着CameraDeviceClient的endConfigure方法，其逻辑比较简单，在该方法中会调用Camera3Device的configureStreams的方法，而该方法又会去通过ICameraDeviceSession的configureStreams_3_4的方法最终将需求传递给Provider。</p>

<p style="text-indent:2em">到这里整个数据流已经配置完成，并且App也获取了Framework中的CameraCaptureSession对象，之后便可进行图像需求的下发了，在下发之前需要先创建一个Request，而App通过调用CameraDeviceImpl中的createCaptureRequest来实现，该方法在Framework中实现，内部会再去调用Camera Service中的aidl接口createDefaultRequest，该接口的实现是CameraDeviceClient，在其内部又会去调用Camera3Device的createDefaultRequest方法，最后通过ICameraDeviceSession代理的constructDefaultRequestSettings方法将需求下发到Provider端去创建一个默认的Request配置，一旦操作完成，Provider会将配置上传至Service，进而给到App中。</p>

<h5 id="d-处理图像需求"><a href="#d-处理图像需求" class="headerlink" title="d) 处理图像需求"></a>d) 处理图像需求</h5><p style="text-indent:2em">在创建Request成功之后，便可下发图像采集需求了，这里大致分为两个流程，一个是预览，一个拍照，两者差异主要体现在Camera Service中针对Request获取优先级上，一般拍照的Request优先级高于预览，具体表现是当预览Request在不断下发的时候，来了一次拍照需求，在Camera3Device 的RequestThread线程中，会优先下发此次拍照的Request。这里我们主要梳理下下发拍照request的大体流程：</p>

<p style="text-indent:2em">下发拍照Request到Camera Service，其操作主要是由CameraDevcieClient的submitRequestList方法来实现，在该方法中，会调用Camera3Device的setStreamingRequestList方法，将需求发送到Camera3Device中，而Camera3Device将需求又加入到RequestThread中的RequestQueue中，并唤醒RequestThread，在该线程被唤醒后，会从RequestQueue中取出Request，通过之前获取的ICameraDeviceSession代理的processCaptureRequest_3_4方法将需求发送至Provider中，由于谷歌对于processCaptureRequest_3_4的限制，使其必须是非阻塞实现，所以一旦发送成功，便立即返回，在App端便等待这结果的回传。</p>

<h5 id="e-接收图像结果"><a href="#e-接收图像结果" class="headerlink" title="e) 接收图像结果"></a>e) 接收图像结果</h5><p style="text-indent:2em">针对结果的获取是通过异步实现，主要分别两个部分，一个是事件的回传，一个是数据的回传，而数据中又根据流程的差异主要分为metadata和imagedata两个部分，接下来我们详细介绍下：</p>

<p style="text-indent:2em">在下发Request之后，首先从Provider端传来的是Shutter Notify，因为之前已经将Camera3Device作为ICameraDeviceCallback的实现传入Provider中，所以此时会调用Camera3Device的notify方法将事件传入Camera Service中，紧接着通过层层调用，将事件通过CameraDeviceClient的notifyShutter方法发送到CameraDeviceClient中，之后又通过打开相机设备时传入的Framework的CameraDeviceCallbacks接口的onCaptureStarted方法将事件最终传入Framework，进而给到App端。</p>

<p style="text-indent:2em">在Shutter事件上报完成之后，当一旦有metadata生成，Camera Provider便会通过ICameraDeviceCallback的processCaptureResult_3_4方法将数据给到Camera Service，而该接口的实现对应的是Camera3Device的processCaptureResult_3_4方法，在该方法会通过层层调用，调用sendCaptureResult方法将Result放入一个mResultQueue中，并且通知FrameProcessorBase的线程去取出Result，并且将其发送至CameraDeviceClient中，之后通过内部的CameraDeviceCallbacks远程代理的onResultReceived方法将结果上传至Framework层，进而给到App中进行处理。</p>

<p style="text-indent:2em">随后ImageData前期也会按照类似的流程走到Camera3Device中，但是会通过调用returnOutputBuffers方法将数据给到Camera3OutputStream中，而该Stream中会通过BufferQueue这一生产者消费者模式中的生产者的queue方法通知消费者对该buffer进行消费，而消费者正是App端的诸如ImageReader等拥有Surface的类，最后App便可以将图像数据取出进行后期处理了。</p>

<p style="text-indent:2em">初代Android相机框架中，Camera Service层就已经存在了，主要用于向上与Camera Framework保持低耦合关联，承接其图像请求，内部封装了Camera Hal Module模块，通过HAL接口对其进行控制，所以该层从一开始就是谷歌按照分层思想，将硬件抽象层抽离出来放入Service中进行管理，这样的好处显而易见，将平台厂商实现的硬件抽象层与系统层解耦，独立进行控制。之后随着谷歌将平台厂商的实现放入vendor分区中，彻底将系统与平台厂商在系统分区上保持了隔离，此时，谷歌便顺势将Camera HAL Moudle从Camera Service中解耦出来放到了vendor分区下的独立进程Camera Provider中，所以之后，Camera Service 的职责便是承接来自Camera Framework的请求，之后将请求转发至Camera Provider中，作为一个中转站的角色存在在系统中。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%9B%9B-%E7%9B%B8%E6%9C%BA%E5%BA%94%E7%94%A8%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%9B%9B-%E7%9B%B8%E6%9C%BA%E5%BA%94%E7%94%A8%E5%B1%82/" class="post-title-link" itemprop="url">Android Camera 体系结构之四 相机应用层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:51:55 / 修改时间：14:53:16" itemprop="dateCreated datePublished" datetime="2021-06-11T14:51:55+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">相机应用处于整个框架的上层，在现实生活中，为了满足各式各样的应用场景，会加入很多业务处理逻辑，但是一旦当我们拨开繁杂的业务逻辑，便会发现其核心部分依然是通过调用谷歌制订的一系列Camera Api接口来完成的，而所有的相机行为都包含在该接口中。</p>

<p style="text-indent:2em">起初，相机系统采用的是Camera Api v1接口，它通过一个Camera 类以及该类中的几个标准方法来实现整个相机系统的预览、拍照以及录像功能，控制逻辑比较简单，同时也比较容易理解，但也正是这种简单，导致了它无法逐帧控制底层硬件，无法通过元数据进行修改进而增强帧的表达能力，再加之应用场景的多样化趋势，该接口在新功能的实现上显得些许力不从心。面对该接口难以进一步扩展相机功能这一局面，谷歌在Andorid 5.0(API Level 21)便重新对Camera进行了设计，摒弃了Camera Api v1的设计逻辑，提出了一个全新的API-camera2，引入了Session以及Request概念，将控制逻辑统一成一个视图，因此在使用上更加复杂，同时也支持了更多特性，比如逐帧控制曝光、感光度以及支持Raw格式的输出等。并且由于对控制逻辑的高度抽象化，使得该接口具有很高的灵活性，可以通过简单的操作实现30fps的全高清连拍的功能，总的来说，该接口极大地提高了对于相机框架的控制能力，同时也进一步大幅度提升了其整体性能。</p>

<p style="text-indent:2em">谷歌提出Camera Api v2接口的同时，将其具体实现放入了Camera Framework中来完成，Framework内部负责解析来自App的请求，并且通过AIDL跨进程接口下发到Camera Service中进行处理，并且等待结果的回传。接下来我们首先以Camera Api v2接口为主简单讲解下其逻辑含义，然后详细梳理下Camera Framework对于它的实现，最后以一个简单App Demo为例，来介绍下如何使用该接口来控制整个相机体系。</p>

<p><img src="/.top//camera.jpg" alt="img"></p>
<h4 id="Camera-Api-v2"><a href="#Camera-Api-v2" class="headerlink" title="Camera Api v2"></a>Camera Api v2</h4><p style="text-indent:2em">在介绍Camera Api v2之前，首先我们来回顾下Api v1接口的基本逻辑，该接口主要通过一个Camera.java类来定义了所有的控制行为，通过定义诸如open、startPreview、takePicture、AutoFocus等标准的接口来实现打开设备、预览、拍照以及对焦操作的功能，同时通过定义Camera.Parameters来实现了参数的读取与设置，其中包括了帧率、图片格式的控制，另外，通过定义了Camera.CameraInfo来实现了图像元数据的获取。而为了更加细致化地控制相机系统的Camera Api v2接口，相对于Api v1接口而言，复杂了许多，通过不同的接口类以及接口方法定义了复杂的相机系统行为，接下来我们来逐一进行介绍：</p>

<h5 id="CameraManager"><a href="#CameraManager" class="headerlink" title="CameraManager"></a>CameraManager</h5><p style="text-indent:2em">谷歌将CameraManager定义为一个系统服务，通过Context.getSystemService来获取，主要用于检测以及打开系统相机，其中打开操作通过openCamera方法来完成。除此之外，还定义了getCameraCharacteristics方法来获取当前Camera设备支持的属性信息，而该属性信息通过CameraCharacteristics来表示，其中包括了图像数据的大小以及帧率等信息。</p>

<h5 id="CameraDevice"><a href="#CameraDevice" class="headerlink" title="CameraDevice"></a>CameraDevice</h5><p style="text-indent:2em">代表了一个被打开的系统相机，类似于Camera Api v1中的Camera类，用于创建CameraCaptureSession以及对于最后相机资源的释放。</p>

<h5 id="CameraDevice-StateCallback"><a href="#CameraDevice-StateCallback" class="headerlink" title="CameraDevice.StateCallback"></a>CameraDevice.StateCallback</h5><p style="text-indent:2em">该类定义了一系列的回调方法，其实现交由App来完成，主要用于返回创建Camera设备的结果，一旦创建成功相机框架会通过回调其onOpened方法将CameraDevice实例给到App，如果失败，则调用onError返回错误信息。</p>

<h5 id="CameraCaptureSession"><a href="#CameraCaptureSession" class="headerlink" title="CameraCaptureSession"></a>CameraCaptureSession</h5><p style="text-indent:2em">该类代表了一个具体的相机会话，建立了与Camera设备的通道，而之后对于Camera 设备的控制都是通过该通道来完成的。当需要进行预览或者拍照时，首先通过该类创建一个Session，并且调用其setRepeatingRequest方法开启预览流程，或者调用capture方法开始一次拍照动作。</p>

<h5 id="CameraCaptureSession-StateCallback"><a href="#CameraCaptureSession-StateCallback" class="headerlink" title="CameraCaptureSession.StateCallback"></a>CameraCaptureSession.StateCallback</h5><p style="text-indent:2em">该接口类定义了一系列回调方法，其实现交由App完成，主要用于返回创建CameraCaptureSession的结果，成功则通过onConfigured方法返回一个CameraCaptureSession实例，如果失败则通过onConfigureFailed返回错误信息。</p>

<h5 id="CameraCaptureSession-CaptureCallback"><a href="#CameraCaptureSession-CaptureCallback" class="headerlink" title="CameraCaptureSession.CaptureCallback"></a>CameraCaptureSession.CaptureCallback</h5><p style="text-indent:2em">该接口类定义了一系列回调方法，用于返回来自Camera Framework的数据和事件，其中onCaptureStarted方法在下发图像需求之后立即被调用，告知App此次图像需求已经收到，onCaptureProgressed方法在产生partial metadata的时候回调，onCaptureCompleted方法在图像采集完成，上传metadata数据时被调用。</p>

<h5 id="CaptureRequest"><a href="#CaptureRequest" class="headerlink" title="CaptureRequest"></a>CaptureRequest</h5><p style="text-indent:2em">该类用于表示一次图像请求，在需要进行预览或者拍照时，都需要创建一个CaptureRequest，并且将针对图片的一系列诸如曝光/对焦设置参数都加入到该Request中，通过CameraCaptureSession下发到相机系统中。</p>

<h5 id="TotalCaptureResult"><a href="#TotalCaptureResult" class="headerlink" title="TotalCaptureResult"></a>TotalCaptureResult</h5><p style="text-indent:2em">每当通过CameraDevice完成了一次CaptureRequest之后会生成一个TotalCaptureResult对象，该对象包含了此次抓取动作所产生的所有信息，其中包括关于硬件模块(包括Sensor/lens/flash)的配置信息以及相机设备的状态信息等。</p>

<h5 id="CaptureResult"><a href="#CaptureResult" class="headerlink" title="CaptureResult"></a>CaptureResult</h5><p style="text-indent:2em">该类代表了某次抓取动作最终生成的图像信息，其中包括了此次关于硬件软件的配置信息以及输出的图像数据，以及显示了当前Camera设备的状态的元数据(meta data)，该类并不保证拥有所有的图像信息。</p>

<h3 id="Camera-Framework"><a href="#Camera-Framework" class="headerlink" title="Camera Framework"></a>Camera Framework</h3><p style="text-indent:2em">基于接口与实现相分离的基本设计原则，谷歌通过Camera Api 接口的定义，搭建起了App与相机系统的桥梁，而具体实现便是由Camera Framework来负责完成的。在采用Camera Api v1接口的时期，该部分是通过JNI层来进行java到C++的转换，进而到达native层，而在native层会通过实现CameraClient建立与Camera Service的通讯 ，整个过程比较繁琐，使得整体框架略显繁杂，而随着Camera Api v2的提出，在该层便大量使用AIDL机制，直接在Java层建立与Camera Service的通信，进一步简化了整体框架。接下来我们以几个主要接口为主线，简单梳理下其具体实现。</p>

<p><img src="/.top//app-framework01.jpg" alt="img"></p>
<h5 id="CameraManager-1"><a href="#CameraManager-1" class="headerlink" title="CameraManager"></a>CameraManager</h5><p style="text-indent:2em">实现主要在CameraManager.java中，通过CameraManager查询、获取以及打开一个Camera 设备。在该类中还实现了内部类CameraManagerGlobal，该类继承于ICameraServiceListener.Stub，在内部会获取到ICameraService远程代理，并且调用ICameraService的addListener方法将自己注册到Camera Service中，一旦Camera Service状态有所变更便会通过其实现的回调方法通知到Camera Manager服务，另外，该类在打开相机设备的时候，还通过调用ICameraService.connectDevice()方法获取到Camera Service中的CameraDevice远程代理ICameraDeviceUser对象，并且将该代理传入CameraDeviceImpl中，进而与Camera Service建立了连接。</p>

<h5 id="CameraDeviceImpl"><a href="#CameraDeviceImpl" class="headerlink" title="CameraDeviceImpl"></a>CameraDeviceImpl</h5><p style="text-indent:2em">该类定义在CameraDeviceImpl.java文件中，继承并实现了CameraDevice接口，代表了一个相机设备，可以完成CameraCaptureSession的创建以及CaptureRequest创建等工作，内部定义了CameraDeviceCallbacks类(该类继承于ICameraDeviceCallbacks.Stub，对应于ICameraDeviceCallbacks接口)，用于接收来自Camera Service中的Camera Device的状态回调，并且内部维护着一个Camera Service 的远程ICameraDevice代理，进而可以下发图像请求到Camera Service中。</p>

<h5 id="CameraCaptureSessionImpl"><a href="#CameraCaptureSessionImpl" class="headerlink" title="CameraCaptureSessionImpl"></a>CameraCaptureSessionImpl</h5><p style="text-indent:2em">该类定义在CameraCaptureSessionImpl.java文件中，继承并实现了CameraCaptureSession接口，每一个相机设备在一个时间段中，只能创建并存在一个CameraCaptureSession，该类维护着来自实例化时传入的Surface列表，这些Surface正是包含了每一个图像请求的数据缓冲区。


</p><p style="text-indent:2em">其中该类包含了两种Session，一种是普通的，适用于一般情况下的会话操作，另一种是用于Reprocess流程的会话操作，该流程主要用于对于现有的图像数据进行再处理的操作。</p>

<p>除了以上这几个接口，还有几个接口是需要App部分进行实现的，用于返回App所需要的对象或者数据：</p>
<h5 id="CameraDevice-StateCallback-1"><a href="#CameraDevice-StateCallback-1" class="headerlink" title="CameraDevice.StateCallback"></a>CameraDevice.StateCallback</h5><p style="text-indent:2em">被App端进行继承并实现，用于在调用CameraManager的openCamera方法时，通过参数的形式传入Framework，在Framework中，一旦CameraDeviceImpl创建成功便通过其中的onOpened方法将其返回给App，如果失败，便会通过其他方法返回给App错误信息。</p>

<h5 id="CameraCaptureSession-StateCallback-1"><a href="#CameraCaptureSession-StateCallback-1" class="headerlink" title="CameraCaptureSession.StateCallback"></a>CameraCaptureSession.StateCallback</h5><p style="text-indent:2em">被App端进行继承并实现，用于在调用CameraDevice的createCaptureSession方法时作为参数传入Framework中，一旦创建成功，Framework便会通过调用该类的onConfigured接口返回一个CameraCaptureSessionImpl的对象，如果失败，Framework会调用其onConfigureFailed方法将错误信息返回至App。</p>

<h5 id="CameraCaptureSession-CaptureCallback-1"><a href="#CameraCaptureSession-CaptureCallback-1" class="headerlink" title="CameraCaptureSession.CaptureCallback"></a>CameraCaptureSession.CaptureCallback</h5><p style="text-indent:2em">被App端进行继承并实现，App通过调用CameraCaptureSessionImpl的setRepeatingRequest或者capture方法时作为参数传入Framework，一旦Framework接收到来自CameraService的数据时，便会通过调用这个回调类将数据发送至App中。</p>

<p><img src="/.top//app-framwork02.jpg" alt="img"></p>
<p>Camera Framework 中针对几个接口的调用流程如上图，接下来我们依次进行分析：</p>
<h6 id="a-openCamera"><a href="#a-openCamera" class="headerlink" title="a) openCamera"></a>a) openCamera</h6><p style="text-indent:2em">当用户打开相机应用时，会去调用该方法打开一个相机设备，其中该方法最终经过层层调用会调用到Camera Framework中的openCameraDeviceUserAsync方法，在该方法中主要做了三件事：</p>

<ul>
<li>首先是调用其getCameraCharacteristics方法通过获取ICameraService代理来获取当前设备的属性。</li>
<li>其次是实例化了一个CameraDeviceImpl对象，并将来自App的CameraDevice.StateCallback接口存入该对象中，再将CameraDeviceImpl中的内部类CameraDeviceCallbacks对象作为参数通过ICameraService的connectDevice方法传入Camera Service去打开并获取一个ICameraDeviceUser代理，并将该代理存入CameraDeviceImpl中进行管理。</li>
<li>最后通过App传入的回调将CameraDeviceImpl返回给App使用，至此整个流程便完成了。</li>
</ul>
<h6 id="b-createCaptureSession"><a href="#b-createCaptureSession" class="headerlink" title="b) createCaptureSession"></a>b) createCaptureSession</h6><p style="text-indent:2em">在打开相机设备之后便需要去创建一个相机会话，用于传输图像请求，其最终实现是调用该方法来进行实现的，而该方法会去调用到Camera Framework中的createCaptureSessionInternal方法，该方法主要做了两件事：</p>

<ul>
<li>首先调用configureStreamsChecked方法来配置数据流。</li>
<li>其次实例化了一个CameraCaptureImpl对象，并通过传入CameraCaptureSession.StateCallback回调类将该对象发送至至App中。</li>
</ul>
<p style="text-indent:2em">而在configureStreamsChecked方法中会去调用ICameraDeviceUser代理的一系列方法进行数据流配置，其中调用cancelRequest方法停掉当前的的预览流程，调用deleteStream方法删除之前的数据流，调用createStream创建新的数据流，最后调用endConfigure来进行数据流的配置工作，针对性的配置便在最后这个endConfigure方法中。</p>

<h6 id="c-createCaptureRequest"><a href="#c-createCaptureRequest" class="headerlink" title="c) createCaptureRequest"></a>c) createCaptureRequest</h6><p style="text-indent:2em">在创建并获取相机会话之后，便可以开始下发图像请求了，而在此之前，需要通过该方法来创建一个CaptureRequest，一旦调用该方法，最终会调用到Camera Service中ICameraDeviceUser的createDefaultRequest方法来创建一个默认配置的CameraMetadataNative，其次实例化一个CaptureRequest.Builder对象，并将刚才获取的CameraMetadataNative传入其中，之后返回该CaptureRequest.Builder对象，在App中，直接通过调用该Buidler对象的build方法，获取一个CaptureRequest对象。CaptureRequest对象也创建成功了，接下来需要下发图像请求了，一般常用请求分为两种,一个是预览一个是拍照。</p>

<h6 id="d-setRepeatingRequest"><a href="#d-setRepeatingRequest" class="headerlink" title="d) setRepeatingRequest"></a>d) setRepeatingRequest</h6><p style="text-indent:2em">App调用该方法开始预览流程，通过层层调用最终会调用到Framework中的submitCaptureRequest方法，该方法主要做了两件事：</p>

<ul>
<li>首先调用CameraService层ICameraDeviceUser的submitRequestList方法，将此次Request下发到CameraService中。</li>
<li>其次将App通过参数传入的CameraCaptureSession.CaptureCallback对象存到CameraDeviceImpI对象中。</li>
</ul>
<p>接下来看下拍照请求的处理流程：</p>
<h6 id="e-capture"><a href="#e-capture" class="headerlink" title="e) capture"></a>e) capture</h6><p style="text-indent:2em">该方法最终也会调用到Framework中的submitCaptureRequest方法，接下来边和预览流程大致相同，会去调用Camera Service 中的ICameraDeviceUser的submitRequestList方法传入请求，之后将App实现的回调对象存入CameraDeviceImpl对象中。</p>

<h6 id="f-onCaptureProgressed"><a href="#f-onCaptureProgressed" class="headerlink" title="f) onCaptureProgressed"></a>f) onCaptureProgressed</h6><p style="text-indent:2em">一旦Request下发到Camera Service之后，当底层生成了partial metadata数据，Camera Service会调用通过调用在打开相机设备时传入的ICameraDeviceCallbacks代理，通过其onResultReceived方法将数据传回Framework，之后调用App传入的CameraCaptureSession.CaptureCallback中的onCaputreProgressed方法将结果回传至App进行解析以及后处理。</p>

<h6 id="g-onCaptureCompleted"><a href="#g-onCaptureCompleted" class="headerlink" title="g) onCaptureCompleted"></a>g) onCaptureCompleted</h6><p style="text-indent:2em">一旦Request下发到Camera Service之后，当底层生成了metadata数据，Camera Service会调用通过调用在打开相机设备时传入的ICameraDeviceCallbacks代理，通过其onResultReceived方法将数据传回Framework，之后调用App传入的CameraCaptureSession.CaptureCallback中的onCaputreCompleted方法将结果回传至App进行解析以及后处理。</p>

<h6 id="h-onImageAvailable"><a href="#h-onImageAvailable" class="headerlink" title="h) onImageAvailable"></a>h) onImageAvailable</h6><p style="text-indent:2em">之前已经通过两个回调接口onCaptureProgressed以及onCaptureCompleted方法将metadata上传到了App，一般情况下，图像数据会在他们之后上传，而且这个上传过程并不经过Camera Framework，而是通过BufferQueue来进行的，当Camera Service接收到底层传来的图像数据，便会立即调用processCaptureResult_3_4方法，该方法中会去调用BufferQueue中生产者角色的Surface的queueBuffer方法，将数据入队并通知消费者去消费，而此时的消费者正是App端的ImageReader，并经过一层层回调，最终会通过调用ImageReader的onImageAvailable方法，通知ImageReader去将数据取出，并做后期操作。</p>

<p style="text-indent:2em">从上面的梳理不难发现，整个Camera Framework除了是对Camera Api v2的实现外，还承担着与Camera Service跨进程通信的任务，充当了一个位于App与Service之间的中转站的角色。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%89-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%89-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88/" class="post-title-link" itemprop="url">Android Camera 体系结构之三 架构概览</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:46:34 / 修改时间：14:50:19" itemprop="dateCreated datePublished" datetime="2021-06-11T14:46:34+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">Android系统利用分层思想，将各层的接口定义与实现分离开来，以接口作为各层的脉络，连接整体框架，将具体实现的主导权交由各自有具体实现需求的平台厂商或者Android 开发者，这样既做到把控全局，也给予了众多开发者足够大的创作空间，这体现出了一个优秀的开源系统应有的胸怀和远见。其中，谷歌根据职能的不同将Camera框架一共划分成了五层，分别是App(相机应用层)、Service(相机服务层)、Provider(相机硬件抽象层)、Driver(相机驱动层)以及Hardware(硬件层)，下面的Camera的整体架构图很清晰地显示出了其五层架构以及相互的关联接口。</p>

<p><img src="/.top//android_camera_architecture.jpg" alt="img"></p>
<h4 id="Camera-App"><a href="#Camera-App" class="headerlink" title="Camera App"></a>Camera App</h4><p style="text-indent:2em">应用层处于整个框架的顶端，承担着与用户直接进行交互的责任，承接来自用户直接或者间接的比如预览/拍照/录像等一系列具体需求，一旦接收到用户相关UI操作，便会通过Camera Api v2标准接口将需求发送至Camera Framework部分，并且等待Camera Framework回传处理结果，其中包括了图像数据以及整体相机系统状态参数，之后将结果以一定方式反馈给用户，达到记录显示种种美好瞬间的目的。</p>

<center><font size="2">----------------------------------------------------------------------Api v2----------------------------------------------------------------------</font></center>

<h4 id="Camera-Framework"><a href="#Camera-Framework" class="headerlink" title="Camera Framework"></a>Camera Framework</h4><p style="text-indent:2em">该层主要位于Camera App与Camera Service之间，以jar包的形式运行在App进程中，它封装了Camera Api v2接口的实现细节，暴露接口给App进行调用，进而接收来自App的请求，同时维护着请求在内部流转的业务逻辑，最终通过调用Camera AIDL跨进程接口将请求发送至Camera Service中进行处理，紧接着，等待Camera Service结果的回传，进而将最终结果发送至App。</p>

<center><font size="3">==================================aidl=================================</font></center>

<h4 id="Camera-Service"><a href="#Camera-Service" class="headerlink" title="Camera Service"></a>Camera Service</h4><p style="text-indent:2em">该层位于Camera Framework与Camera Provider之间，作为一个独立进程存在于Android系统中，在系统启动初期会运行起来，它封装了Camera AIDL跨进程接口，提供给Framework进行调用，进而接收来自Framework的图像请求，同时内部维护着关于请求在该层的处理逻辑，最终通过调用Camera HIDL跨进程接口将请求再次下发到Camera Provider中，并且等待结果的回传，进而将结果上传至Framework中。</p>

<center><font size="3">=================================HIDL================================</font></center>

<h4 id="Camera-Provider"><a href="#Camera-Provider" class="headerlink" title="Camera Provider"></a>Camera Provider</h4><p style="text-indent:2em">该层位于Camera Service与Camera Driver之间，作为一个独立的进程存在于Android系统中，同时在系统启动初期被运行，提供Camera HIDL跨进程接口供Camera Service进行调用，封装了该接口的实现细节，接收来自Service的图像请求，并且内部加载了Camera HAL Module，该Module由OEM/ODM实现，遵循谷歌制定的标准Camera HAL3接口，进而通过该接口控制Camera HAL部分，最后等待Camera HAL的结果回传，紧接着Provider通过Camera HIDL接口将结果发送至Camera Service。</p>

<center><font size="2">----------------------------------------------------------------------HAL 3----------------------------------------------------------------------</font></center>

<h4 id="CamX-CHI-Camera-HAL"><a href="#CamX-CHI-Camera-HAL" class="headerlink" title="CamX-CHI(Camera HAL)"></a>CamX-CHI(Camera HAL)</h4><p style="text-indent:2em">是高通对谷歌Camera HAL3接口的实现，以so库的形式被加载至Camera Provider中，之前采用的是QCamera & MM-Camera架构，但是为了更好灵活性和可扩展性，而今高通又提出了CamX-CHI架构，该架构提供HAL3接口给Provider进行调用，接收来自Provider的请求，而内部对HAL3接口进行了实现，并且通过V4L2标准框架控制着相机驱动层，将请求下发至驱动部分，并且等待结果回传，进而上报给Camera Provider。</p>

<p style="text-indent:2em">CamX-CHI架构由CamX和CHI两个部分组成，CamX负责一些基础服务代码的实现，不经常改动，CHI负责实现一些可扩展性和定制化的需求，方便OEM/ODM添加自己的扩展功能。CamX主要包括实现HAL3入口的hal模块，实现与V4L2驱动交互的csl模块，实现硬件node的hwl和实现软件node的swl。CHI通过抽象出Usecase、Feature、Session、Pipeline、Node的概念，使厂商可以通过实现Node接口来接入自己的算法，并通过XML文件灵活配置Usecase、Pipeline、Node的结构关系。</p>

<center><font size="2">=========================================V4L2=========================================</font></center>

<h4 id="Camera-Driver"><a href="#Camera-Driver" class="headerlink" title="Camera Driver"></a>Camera Driver</h4><p style="text-indent:2em">Linux为视频采集设备制定了标准的V4L2接口，并在内核中实现了其基础框架V4L2 Core。用户空间进程可以通过V4L2接口调用相关设备功能，而不用考虑其实现细节。V4L2提出了总设备和子设备的概念，并通过media controller机制向用户空间暴露自己的硬件拓扑结构。视频采集设备驱动厂商按照V4L2 Core的要求开发自己的驱动程序，只需要实现相应的结构体和函数接口并调用注册函数注册自己就行。</p>

<center><font size="2">----------------------------------------------------------------------KMD-----------------------------------------------------------------------</font></center>

<p style="text-indent:2em">在高通平台上，高通对相机驱动部分进行了实现，利用了V4L2框架的可扩展特性，设计出了一套独特的KMD框架。在该框架内部主要包含了三个部分，CRM、Camera Sync以及一系列子设备，首先，作为框架顶层管理者，CRM创建了一个V4L2主设备用来管理所有的子设备，并且暴露设备节点video0给用户空间，同时内部维护着整个底层驱动业务逻辑。其次，Camera Sync创建了一个V4L2主设备，同时暴露了设备节点video1给用户空间，主要用于向用户空间反馈图像数据处理状态。最后，子设备模块被抽象成v4l2_subdev设备，同样也暴露设备节点v4l2-subdev给用户空间进行更精细化的控制。另外，在整个框架初始化的过程中，通过media controller机制，保持了在用户空间进行枚举底层硬件设备的能力。</p>

<center><font size="2">=======================================I2C/MIPI CSI======================================</font></center>

<h4 id="Camera-Hardware"><a href="#Camera-Hardware" class="headerlink" title="Camera Hardware"></a>Camera Hardware</h4><p style="text-indent:2em">相机硬件处在整个相机体系的最底层，是相机系统的物理实现部分，该部分包括镜头、感光器、ISP三个最重要的模块，还有对焦马达、闪光灯、滤光片、光圈等辅助模块。镜头的作用是汇聚光线，利用光的折射性把射入的光线汇聚到感光器上。感光器的作用是负责光电转换，通过内部感光元件将接收到的光信号转换为电子信号，进而通过数电转换模块转为数字信号，并最后传给ISP。ISP负责对数字图像进行一些算法处理，如白平衡、降噪、去马赛克等。</p>

<p style="text-indent:2em">通过上面的介绍，我们可以发现，谷歌通过以上五级分层，形成了整个相机框架体系，其中层与层之间通过行业协会、开源社区或者谷歌制订的标准接口进行连接，上层通过调用标准接口下发请求到下层，下层负责对标准接口进行实现，最终将请求再次封装并调用下一层级的对外接口下发到下层。所以总得来说，谷歌使用标准接口作为骨架搭建整体框架，而其具体实现交由各层自己负责，从整体上来看，职责划分明确，界限分明，这样的设计，一来利用标准接口，保持了整个框架业务正常流转，二来极大地降低了各层耦合度，保持了各层的相互独立，最终让整个框架处于一个稳定同时高效的运行状态。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%8C-%E7%9B%B8%E6%9C%BA%E7%AE%80%E5%8F%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%8C-%E7%9B%B8%E6%9C%BA%E7%AE%80%E5%8F%B2/" class="post-title-link" itemprop="url">Android Camera 体系结构之二 相机简史</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:43:49 / 修改时间：14:46:02" itemprop="dateCreated datePublished" datetime="2021-06-11T14:43:49+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">几千年来，人类主要通过文字以及绘画的方式记录着对于客观世界的认知，为了更直观地呈现客观世界的图景，摄影技术应运而生。摄影是一门光与影的艺术，通过透镜将光线导入并依靠其折射特性，将光线最终导向到感光器件中，而感光器件在收到光线刺激之后进行一定的转换，进而形成影像，而这一系列的硬件设备的组合统一被称之为相机系统，同时由于现代计算机科学的迅猛发展，该系统依托其强大的传播力，彻底改变和提升了人类感知客观世界的方式和速度。</p>

<p style="text-indent:2em">与现在相比，早期的相机系统十分简陋，同时成像效果也一直是灰白色调为主，但随着技术的不断革新，具有成像效果好，感光能力强的胶卷一经推出，便彻底提升了相机系统的成像效果。之后又随着CCD感光器件的发明，彻底将相机系统推入了数字成像时代，它直接将光信号转换为电子信号，进而转换为数字信号，最终将数据存储到计算机系统中。之后又在相机系统加入了图像处理模块，依托其强大的运算能力，成功地将成像效果再一次提升了一个维度，因此该时期的相机系统发展迅速，同时也基于技术的不断发展，各大厂商也推陈出新，打造了各式各样的相机系统，比较有代表性的便是单反和傻瓜相机，其中主打成像效果的单反相机，具有成像效果优秀，受到了众多摄像发烧友的追捧，而具有操作简单的傻瓜式相机，更加适合普通人群使用，在普通市场上反响也相当不错。之后随着手机的普及，对于使用手机进行拍照的需求越发强烈，同时随着制造工艺的进一步发展，一种低成本、小体积感光器件CMOS便顺势被推了出来，就这样手机端相机系统便正式登上了历史舞台。</p>

<p style="text-indent:2em">但是由于相机系统在手机端起步较晚，所以初期的手机软件系统并没有对其有很好的支持，无论从开始的WINCE系统、还是塞班系统亦或是而今Android系统，在开始阶段，都只是简单实现了基本相机功能，使其仅仅能够满足简单的预览拍照录像需求，但是手机市场竞争异常激烈，各个厂商也看到了手机相机这块蓝海，便都投入了巨额资金进行研发，以Android系统为例，开始的相机系统功能简单，成像效果一般，并且无法满足用户的诸如高动态范围拍照等需求，但是经过了全球开发者的不懈努力，针对性为相机系统设计出了一套优秀的软件框架，并且借助一系列优秀的图像算法，再依托强大的硬件模块，而今Android相机系统在某些领域完全可以媲美专业相机。</p>

<p style="text-indent:2em">而今的手机相机系统，除了成像效果有着显著的提高外，各大厂商在手机相机的功能性上也做足了功夫，最显著的代表便是单摄到多摄的演化，刚开始的手机系统仅仅采用了一个后置摄像头，但是由于人们对于自拍的需求日益增长，双摄系统便应运而生，一前一后两个相机模组，后者用于日常拍摄，前者用于自拍，之后随着时代的进步，互联网进一步的普及，将更多的专业照片带到了人们面前，由于审美能力的提高，人们对于手机相机系统便有了更高的要求，再加上技术水平的进一步提高，各大厂商便顺势提出了多摄相机系统，针对不同的拍摄场景或者拍摄效果在一部手机终端上集成多个相机模组，极大的满足了用户对于随手一拍便是大片的需求。</p>

<p style="text-indent:2em">纵观整个Android相机系统的发展，从之前的小分辨率，一步步发展到而今的一亿像素，从之前的成像效果差强人意，到而今的完美呈现各种场景光影效果，从之前的单一模组到而今的多摄系统，它克服了一个又一个的技术难题，解决了一个又一个用户痛点问题，而其发展的背后都源于一个简单的目的，那就是让每一个人都能享受到科技带来的乐趣。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%80-%E5%BA%8F%E8%A8%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%80-%E5%BA%8F%E8%A8%80/" class="post-title-link" itemprop="url">Android Camera 体系结构之一 序言</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-11 14:42:37" itemprop="dateCreated datePublished" datetime="2021-06-11T14:42:37+08:00">2021-06-11</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-14 22:03:32" itemprop="dateModified" datetime="2021-06-14T22:03:32+08:00">2021-06-14</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">Android系统自2007年底被Google推出问世以来，已经走过14个春夏秋冬，历经多次的大大小小的迭代重构、架构调整，虽然时代年轮依旧滚滚，虽然每年技术依然在不断地推陈出新，但是到目前为止，依然可以窥见其接口与实现相分离的核心设计理念，所以其架构设计的优越性可见一斑，另外，随着智能手机的快速普及，面对这一庞大终端市场，作为Android系统中最重要的几个组件之一的相机系统也必定会作为主要战场在手机市场中与其它厂商展开竞争。近几年，谷歌针对相机框架体系进行了多次迭代优化，就而今的相机框架而言，整体架构设计十分优秀，作为一个相机系统开发者，个人感觉很有必要针对整个框架进行一次完整的梳理总结，所以便促使我写下该系列文章，以整个框架的梳理为出发点，深入介绍下Android 相机框架。</p>

<h3 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h3><p><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%80-%E5%BA%8F%E8%A8%80">01.序言</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%8C-%E7%9B%B8%E6%9C%BA%E7%AE%80%E5%8F%B2/">02.相机简史</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%89-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88/">03.架构概览</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%9B%9B-%E7%9B%B8%E6%9C%BA%E5%BA%94%E7%94%A8%E5%B1%82">04.应用层</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%94-%E7%9B%B8%E6%9C%BA%E6%9C%8D%E5%8A%A1%E5%B1%82/">05.服务层</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/">06.硬件抽象层</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/">07.硬件抽象层实现</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/">08.驱动层之V4L2框架</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B9%9D-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93%E9%AB%98%E9%80%9AKMD%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/">09.驱动层之高通KMD</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%8D%81-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%B1%82/">10.硬件层</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%B8%80-%E5%AE%89%E5%8D%93%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/">11.总结</a><br><a target="_blank" rel="noopener" href="https://ljw-luojianwei.github.io/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%BA%8C-%E6%89%8B%E6%9C%BA%E7%9B%B8%E6%9C%BA%E7%9A%84%E6%9C%AA%E6%9D%A5%E4%B8%8E%E5%8F%91%E5%B1%95/">12.手机相机的未来与发展</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/home/page/6/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/home/">1</a><span class="space">&hellip;</span><a class="page-number" href="/home/page/6/">6</a><span class="page-number current">7</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">罗建伟的个人博客</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
