<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;luojianwei.top&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;}}</script><script src="/js/config.js"></script>
<meta property="og:type" content="website">
<meta property="og:title" content="罗建伟的个人主页">
<meta property="og:url" content="https://luojianwei.top/home/index.html">
<meta property="og:site_name" content="罗建伟的个人主页">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="罗建伟的个人博客">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://luojianwei.top/home/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;home&#x2F;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>罗建伟的个人主页</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">罗建伟的个人主页</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">明确自己的内心所求，才能更好地解决问题</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/home/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">罗建伟的个人博客</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E9%9B%B6-%E5%BA%8F%E8%A8%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E9%9B%B6-%E5%BA%8F%E8%A8%80/" class="post-title-link" itemprop="url">Android Q 编译原理之零 序言</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-15 17:20:06 / 修改时间：17:38:30" itemprop="dateCreated datePublished" datetime="2021-06-15T17:20:06+08:00">2021-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Compiler/" itemprop="url" rel="index"><span itemprop="name">Compiler</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">Android的版本一直快速的进行迭代着，从我们以前最常见的Android 4.4一直发展到了今天的Android 12.0版本(即Android K到Android S)，Android版本的快速迭代对于消费者来说是一件好事，但是对于开发者来说各种适配各种改造有时候吃翔的心情都有了。而对于Android版本的适配和各种改造的第一步就是从编译Android源码开始，可是不幸的是随着Android版本的迭代连编译Android源码的相关流程都发生了翻天覆地的变化。本系列基于Android 10.0 进行编译系统的体系的一个梳理。</p>

<p>Android各个版本的对应关系如下:</p>
<table>
<thead>
<tr>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>K</td>
<td>L</td>
<td>M</td>
<td>N</td>
<td>O</td>
<td>P</td>
<td>Q</td>
<td>R</td>
<td>S</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/" class="post-title-link" itemprop="url">Android Q 编译原理之一 编译系统入门篇</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-15 17:18:08 / 修改时间：17:26:14" itemprop="dateCreated datePublished" datetime="2021-06-15T17:18:08+08:00">2021-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Compiler/" itemprop="url" rel="index"><span itemprop="name">Compiler</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p style="text-indent:2em">在Android 7.0之前，Android编译系统使用GNU Make描述和shell来构建编译规则，模块定义都使用Android.mk进行定义，Android.mk的本质就是Makefile，但是随着Android的工程越来越大，模块越来越多，Makefile组织的项目编译时间越来越长。这样下去Google工程师觉得不行，得要优化。因此，在Android7.0开始，Google采用<a target="_blank" rel="noopener" href="https://ninja-build.org" style="text-decoration:none">ninja</a>来取而代之前使用的make，由于之前的Android.mk数据实在巨大，因此Google加入了一个kati工具，用于将Android.mk转换成ninja的构建规则文件buildxxx.ninja，再使用ninja来进行构建工作。编译速度快了一些，但是既然要干，那就干个大的，最终目标要把make都取代，于是从Android8.0开始，Google为了进一步淘汰Makefile，因此引入了Android.bp文件来替换之前的Android.mk。Android.bp只是一个纯粹的配置文件，不包括分支、循环语句等控制流程，本质上就是一个json配置文件。Android.bp通过Blueprint+soong转换成ninja的构建规则文件build.ninja，再使用ninja来进行构建工作。Android10.0上，mk和bp编译的列表可以从 \out\.module_paths中的Android.bp.list、Android.mk.list中看到，Android10.0还有400多个mk文件没有被替换完，Google任重道远。


</p><h4 id="Android编译演进过程："><a href="#Android编译演进过程：" class="headerlink" title="Android编译演进过程："></a>Android编译演进过程：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Android7.0 之前使用GNU Make</span><br><span class="line">Android7.0 引入ninja、kati、Android.bp和soong构建系统</span><br><span class="line">Android8.0 默认打开Android.bp</span><br><span class="line">Android9.0 强制使用Android.bp</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">Google在Android 7.0之后，引入了Soong构建系统，旨在取代make，它利用Kati GNU Make克隆工具和Ninja构建系统组件来加速Android的构建。Make构建系统得到了广泛的支持和使用，但在Android层面变得缓慢、容易出错、无法扩展且难以测试。Soong构建系统正好提供了Android Build所需的灵活性。


</p><p><img src="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/Android%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BC%96%E8%AF%91%E5%8E%86%E7%A8%8B.jpg" alt="Android系统的编译历程"></p>
<h3 id="编译流程"><a href="#编译流程" class="headerlink" title="编译流程"></a>编译流程</h3><h4 id="编译构成"><a href="#编译构成" class="headerlink" title="编译构成"></a>编译构成</h4><p style="text-indent:2em">Android的编译目录在/build 中，看一下Android 10源码中的build目录，现在是这个样子：</p>

<p><img src="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/20201014202635594.jpg" alt="img"></p>
<p style="text-indent:2em">这个目录中可以看到core文件夹被link到了make/core，envsetup.sh被link到make/envsetup.sh，这主要是为了对使用者屏蔽切换编译系统的差异。
这里重点看四个文件夹：blueprint、kati、make、soong。</p>


<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">blueprint：用于处理Android.bp，编译生成*.ninja文件，用于做ninja的处理</span><br><span class="line">kati：用于处理Android.mk，编译生成.ninja文件，用于做ninja的处理</span><br><span class="line">make：文件夹还是原始的make那一套流程，比如envsetup.sh</span><br><span class="line">soong：构建系统，核心编译为soong_ui.bash</span><br></pre></td></tr></table></figure>

<p><strong>Soong构建系统家族成员及各自关系如下图所示：</strong></p>
<p><img src="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/Soong%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%AE%B6%E6%97%8F%E6%88%90%E5%91%98.jpg" alt="Soong编译系统家族成员"></p>
<p style="text-indent:2em">在编译过程中，Android.bp会被收集到out/soong/build.ninja.d，blueprint以此为基础，生成out/soong/build.ninja，Android.mk会由kati/ckati生成为out/build-aosp_arm.ninja，两个ninja文件会被整合进入out/combined-aosp_arm.ninja


</p><p><strong>out/combined-aosp_arm.ninja内容如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">builddir = out</span><br><span class="line">include out/build-aosp_arm.ninja</span><br><span class="line">include out/soong/build.ninja</span><br><span class="line">build out/combined-aosp_arm.ninja: phony out/soong/build.ninja</span><br></pre></td></tr></table></figure>

<h4 id="编译步骤"><a href="#编译步骤" class="headerlink" title="编译步骤"></a>编译步骤</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> build/envsetup.sh</span><br><span class="line">lunch aosp_arm-eng        //或者 m PRODUCT-aosp_x86_64-eng，Android10.0不一定需要lunch命令</span><br><span class="line">make -j8                  //编译模块也可以直接用 m libart</span><br></pre></td></tr></table></figure>

<p><strong>Android10.0编译步骤如下图所示:</strong></p>
<p><img src="/2021/06/15/Android-Q-%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E4%B8%80-%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8%E7%AF%87/20201014202755574.jpg" alt="img"></p>
<h3 id="编译说明"><a href="#编译说明" class="headerlink" title="编译说明"></a>编译说明</h3><h4 id="编译环境初始化-envsetup说明"><a href="#编译环境初始化-envsetup说明" class="headerlink" title="编译环境初始化-envsetup说明"></a>编译环境初始化-envsetup说明</h4>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/14/%E9%80%9A%E8%BF%87Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/14/%E9%80%9A%E8%BF%87Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" class="post-title-link" itemprop="url">通过Hexo搭建个人博客</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-14 17:24:45 / 修改时间：17:58:35" itemprop="dateCreated datePublished" datetime="2021-06-14T17:24:45+08:00">2021-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Web/" itemprop="url" rel="index"><span itemprop="name">Web</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p style="text-indent:2em">现在市面上的博客很多，如CSDN，博客园，简书等平台，可以直接在上面发表，用户交互做的好，写的文章百度也能搜索的到。缺点是比较不自由，会受到平台的各种限制和恶心的广告。而自己购买域名和服务器，搭建博客的成本实在是太高了，不光是说这些购买成本，单单是花力气去自己搭这么一个网站，还要定期的维护它，对于我们大多数人来说，实在是没有这样的精力和时间。那么就有第三种选择，通过Hexo直接在github page等平台上托管我们的博客，这样就可以安心的来写作，又不需要定期维护。Hexo是一款基于Node.js的高效简洁的静态博客框架，依赖少易于安装使用，它使用MarkDown语法解析文章，可以方便的生成静态网页，托管在GitHub和Coding等托管平台上，是搭建博客的首选框架。</p>

<h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><ol>
<li><h4 id="安装git、Nodejs、hexo"><a href="#安装git、Nodejs、hexo" class="headerlink" title="安装git、Nodejs、hexo"></a>安装git、Nodejs、hexo</h4></li>
</ol>
<p style="text-indent:2em">Git是目前世界上最先进的分布式版本控制系统，可以高效的处理从很小到非常大的项目版本管理。也就是我们这里用来管理hexo博客文章上传到GitHub的工具。Hexo是基于NodeJS编写的，所以需要安装一下nodeJS和里面的npm工具。命令：sudo apt install git-core; sudo apt install nodejs;sudo apt install npm。git和nodejs安装好后，就可以用命令 npm install -g hexo-cli 全局安装hexo了。安装完后，检查一下有没有安装成功，至此就全部安装完了：


<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git</span></span><br><span class="line">git --version</span><br><span class="line"><span class="comment"># nodejs</span></span><br><span class="line">node -v</span><br><span class="line"><span class="comment"># npm</span></span><br><span class="line">npm -v</span><br><span class="line"><span class="comment"># hexo</span></span><br><span class="line">hexo -v</span><br></pre></td></tr></table></figure>

</p><p style="text-indent:2em">接下来创建并初始化一下博客文件夹和安装Hexo需要的包，这个blog可以自己取什么名字都行。</p>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init blog &amp;&amp; cd blog &amp;&amp; npm install</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">新建完成后，指定文件夹目录下有：</p>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── node_modules           :依赖包文件夹。</span><br><span class="line">├── scaffolds              :模版文件夹。生成文章的一些模板，当您新建文章时，Hexo会根据scaffold来建立文件。</span><br><span class="line">├── source                 :资源文件夹。是存放用户资源的地方，你用来存放博客文章的md文件就放在此处。</span><br><span class="line">|   ├── _drafts            :</span><br><span class="line">|   └── _posts             :</span><br><span class="line">├── themes                 :主题文件夹。Hexo会根据主题来生成静态页面。</span><br><span class="line">├── _config.yml            :博客的配置文件</span><br><span class="line">├── db.json                :</span><br><span class="line">├── package.json           :</span><br><span class="line">└── package-lock.json      :</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">现在一个简单的个人博客已经创建完成，我们可以使用 hexo g(generate) 命令来生成静态网页。然后通过 hexo s(server) 命令启动本地服务器来预览一下hexo为我们提供的最原始博客页面。使用ctrl+c可以把服务关掉。</p>

<ol start="2">
<li><h4 id="GitHub托管"><a href="#GitHub托管" class="headerlink" title="GitHub托管"></a>GitHub托管</h4></li>
</ol>
<p style="text-indent:2em"><b>创建个人仓库：</b>创建一个和用户名相同的仓库，后面加.github.io，只有这样，将来要部署到GitHub page的时候，才会被识别，也就是xxxx.github.io，其中xxx就是注册GitHub的用户名。
</p><p style="text-indent:2em"><b>安装 hexo-deployer-git 部署插件：</b>npm install hexo-deployer-git --save</p>

<p style="text-indent:2em"><b>安装 hexo-asset-image 图片引用插件：</b>npm install hexo-asset-image --save</p>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="工具配置"><a href="#工具配置" class="headerlink" title="工具配置"></a>工具配置</h4><h5 id="npm-配置"><a href="#npm-配置" class="headerlink" title="npm 配置"></a>npm 配置</h5><ol>
<li>设置npm在安装全局模块时的路径和环境变量(Windows)</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建文件夹node_cache、node_global</span></span><br><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">&quot;node_global&quot;</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">&quot;node_cache&quot;</span></span><br><span class="line"><span class="comment">#在系统变量中新建一个变量名为&quot;NODE_PATH&quot;，值为&quot;node_global\node_modules&quot;</span></span><br><span class="line"><span class="comment">#编辑用户变量里的Path，将相应npm的路径改为：&quot;nodejs\node_global&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置镜像源</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">npm config get registry</span><br><span class="line"><span class="comment"># https://registry.npmjs.org/</span></span><br><span class="line">npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org</span><br><span class="line">npm config get registry</span><br><span class="line"><span class="comment"># https://registry.npm.taobao.org</span></span><br></pre></td></tr></table></figure>

<h4 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h4><h5 id="安装hexo主题"><a href="#安装hexo主题" class="headerlink" title="安装hexo主题"></a>安装hexo主题</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-theme-next</span><br><span class="line">cp -rf node_modules/hexo-theme-next themes &amp;&amp; mv themes/hexo-theme-next themes/next</span><br><span class="line">cp themes/next/_config.yml themes/next/_config.yml.bak</span><br></pre></td></tr></table></figure>

<h5 id="配置主题"><a href="#配置主题" class="headerlink" title="配置主题"></a>配置主题</h5><h4 id="博客配置"><a href="#博客配置" class="headerlink" title="博客配置"></a>博客配置</h4><p style="text-indent:2em">在文件根目录下的<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/configuration" style="text-decoration:none">_config.yml</a>，就是整个hexo框架的配置文件了，可以在里面修改大部分的配置。其中theme就是选择什么主题，也就是在theme这个文件夹下，在官网上有很多个主题，默认安装的是lanscape这个主题。当需要更换主题时，在官网上下载，把主题的文件放在theme文件夹下，再修改这个参数就可以了。deploy 就是网站的部署的，repo就是仓库(Repository)的简写，branch选择仓库的哪个分支。
</p>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份原始核心配置文件</span></span><br><span class="line">cp _config.yml _config.yml.bak</span><br></pre></td></tr></table></figure>

<p <p>Front-matter 是文件最上方以 — 分隔的区域，用于指定个别文件的变量</p>
<h3 id="管理-通过git分支进行多终端工作"><a href="#管理-通过git分支进行多终端工作" class="headerlink" title="管理-通过git分支进行多终端工作"></a>管理-通过git分支进行多终端工作</h3><h4 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h4><p style="text-indent:2em">由于`hexo d`上传部署到 github 的其实是 hexo 编译后的文件，是用来生成网页的，不包含源文件。也就是上传的是在本地目录里自动生成的`.deploy_git`里面。其他文件 ，包括我们写在 source 里面的，配置文件，主题文件，都没有上传到 github。所以可以利用 git 的分支管理，将源文件上传到 github 的另一个分支即可。</p>

<h4 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h4><p style="text-indent:2em">主要是通过维护两条 git 分支来实现，第一个分支是 Gihub 上默认的 master 分支，用于存放发布的博文的静态页面；另外再新建一个分支，比如命名为 hexo ，通过此分支存放主题、原始的博客文件等等，这些文件才是不同电脑需要同步的文件；当每次修改主题或者新增博文后，先将修改的主题文件(在themes文件夹下)或者新增博客(在source文件夹下)，同步到远程的 Hexo 分支，然后在通过 hexo g -d 命令发布博文，也就是将新增的博文的静态页面同步到 master 分支。这样通过不同的分支管理不同的文件，实现了多台电脑同步更新博文的功能。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%BA%8C-%E6%89%8B%E6%9C%BA%E7%9B%B8%E6%9C%BA%E7%9A%84%E6%9C%AA%E6%9D%A5%E4%B8%8E%E5%8F%91%E5%B1%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%BA%8C-%E6%89%8B%E6%9C%BA%E7%9B%B8%E6%9C%BA%E7%9A%84%E6%9C%AA%E6%9D%A5%E4%B8%8E%E5%8F%91%E5%B1%95/" class="post-title-link" itemprop="url">Android Camera 体系结构十二 手机相机的未来与发展</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:07:58 / 修改时间：15:08:28" itemprop="dateCreated datePublished" datetime="2021-06-11T15:07:58+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">Android相机发展至今，通过开发者对框架的不断优化，算法人员对图像处理算法的不断提升，硬件工程师对硬件性能地不断调教，换来了在某些领域完全可以媲美专业相机的成像效果，这些成绩是有目共睹的，但是我们不能仅仅着眼于过去，试着将眼光放得长远些，如何将Android相机推向更高的维度，使其成为手机相机的王者，想必这是每一个热衷于技术的开发者都需要反复思考的问题，当然就我个人而言，对于它的未来，有着我自己的思考。</p>

<p style="text-indent:2em">Android相机，首先是基于Android系统，所以对于系统端的优化，我相信Google依然会不断的进行完善，特别地，谷歌一直奉行着接口与实现相分离的设计原则， 这就将很多的实现让渡给各自有实现需求的开发者，所以其实我们有很大的创作空间，比如App部分，通过设计良好的业务框架，让整个相机应用在一个高效且稳定的框架中运行，处理来自用户需求，下发图像需求至相机框架中。又比如对于Camera Hal的实现，其实这部分高通做的已经相当完备，从QCamera&MM-Camera架构到而今的CamX-CHI，都是在为上层提供更好地相机而努力着，但是框架谈不上完美，只能是比较符合当下实际情况，针对CamX-CHI而言，存在着内存占用过大以及CPU负载较高的问题，这些也是我们作为开发者所需要去攻克的难题。</p>

<p style="text-indent:2em">麻雀虽小，五脏俱全，Android相机的小体积中俨然具备着一个完整的相机硬件体系，从光圈到透镜组，再到感光器件最后到后期的图像处理模块，每一个器件都承担着自己特有的使命。对于整套硬件体系而言，对于每一个器件的一个小小的提升都有可能使其在一系列竞争者中脱颖而出，比如某品牌的一亿像素，由于机身厚度的限制，大尺寸的CMOS会给透镜组乃至后期的算法处理带来不小的压力。</p>

<p style="text-indent:2em">一张完美的图像，仅仅依靠前期的成像系统是远远不够的，就像当我们看见一副美景时，心中所呈现的并不是单单眼前的景色而已，我们所独有的人生阅历会在我们心中不经意地给其铺上一层独特的滤镜，赋予其独特的意义，而对于相机系统而言，算法便是其给图像铺上灵魂滤镜的关键因素，不同的算法可以赋予图像不同的属性，但是评价算法的好坏，经常会通过效果与效率两个方面来衡量，所以图像的更多意义，需要更多的算法来实现，而算法的更好更快处理便是其实现的目标，一个好的算法往往能够为平庸无奇的图像带来质的飞跃。</p>

<p style="text-indent:2em">而今的Android相机已经完全不局限于记录身边的美好，而是在创造属于每个人的美好，可以通过它来和相隔万里的亲人朋友进行视频通讯，可以编辑属于自己的独一无二的图像表情，可以让多个自己存在在同一个空间中，以及通过萌拍模式记录下自己的可爱瞬间等，这一切的一切都极大的扩展了Android相机的功能性和可玩性，所以针对新Feature的开发，势必是一个大的趋势，这也印证了一个道理，对于相机的开发，我们有时候不是在满足需求，而是在创造需求。</p>

<p style="text-indent:2em">最后，纵观Android历史，不难发现谷歌自始至终秉承着开源普惠大众的宗旨，从未停止过对Android系统的迭代优化，在整个Android相机系统架构中，不难发现接口与实现相分离的这一简单设计原则在其身上随处可见，这样既保证了整体架构的足够稳定，也实现了系统细节实现的多样性，同时也体现出了强大的灵活性，总的来讲，这样一套优秀的架构体系并且依托如今强大的硬件设备，加之全球开发者们在算法、新feature的不懈努力，我相信Android 相机会在以后的发展中一路高歌猛进，超越苹果成为手机相机领域的王者。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%B8%80-%E5%AE%89%E5%8D%93%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%8D%81%E4%B8%80-%E5%AE%89%E5%8D%93%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">Android Camera 体系结构十一 安卓相机架构总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:06:53 / 修改时间：15:07:28" itemprop="dateCreated datePublished" datetime="2021-06-11T15:06:53+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p style="text-indent:2em">Android 相机体系庞大且复杂，在我刚开始接触到该框架的时候，如盲人摸象一般，一点一点地在代码的世界中探索，在很长的一段时间内，都只能局限于某一个特定的区域，而且在解决问题的过程中，虽然通过对代码的深入梳理，最终都会顺利解决难题，但是到最后依然缺乏一个对于整个框架的理解，正如管中窥豹一般，只见细节而无法把握全貌。但是进入现在的公司之后，通过与相机前辈的沟通，我发现框架思维能力尤为重要，针对整个框架结构需要做到掌控全局，这样在遇到问题的时候便可以迅速定位，此时再进行代码层面的深入研究，发现问题根源，进而达到最终解决问题的目的。</p>

<p style="text-indent:2em">Android相机体系随处可见接口与实现相分离的设计思想，而之前提及的对于体系结构的梳理正是按照其接口的逻辑定义来完成，再结合其接口具体实现，进而完善整个框架体系的代码地图的构建，而在本人六年多的相机开发过程中，经历了多次的Android 相机的框架调整，接口演变，接下来以个人经历为主线，简单为整个相机架构做一个总结。</p>

<p style="text-indent:2em">起初，首先接触到的相机框架部分便是驱动，那时接触的是高通MSM8953平台，该平台还是采用的QCamera & MM-Camera框架，底层驱动并没有负责复杂业务逻辑控制，而是主要用于控制上下电，以及数据流的开启以及停止等，并且依然使用的是vb2进行图像帧缓冲区的管理，但是现如今的7150，其驱动部分俨然发生了翻天覆地的变化，高通为了配合UMD的业务处理，为驱动设计了一套KMD的框架，包含了复杂的业务处理流程，并且数据的管理也摒弃了vb2，采用了新的管理手段，赋予了驱动更多的职能。</p>

<p style="text-indent:2em">之后由于工作需要，进一步将工作重心过渡到Camera HAL层，开发的平台依然是MSM8953平台上，当时采用还是QCamera & MM-Camera框架，在该平台上见证了HAL接口的演变，首先接触最多的便是HAL1接口，该接口使用起来比较简单，通过几个特定接口分别实现预览、拍照以及录像的功能，此时，谷歌已经意识到该接口具有一定的局限，所以自然而然地进行接口的升级，提出了HAL2接口，但是由于接口定义存在问题，所有很快谷歌便摒弃了该接口，迅速推出HAL3接口，并且一直沿用至今。HAL3接口相比于HAL1，优势明显，通过将所有的采集流程高度抽象为一个统一逻辑，所有的场景都可以通过这一统一逻辑进行扩展，使该接口具有很强的灵活性和扩展性，所以通过这几代HAL接口的演变，不难得出一个结论，那便是接口的定义需要高度抽象，而抽象的目的就是为了更好的灵活性和可扩展性，就单单这一点而言，HAL3接口可以说是成功的。</p>

<p style="text-indent:2em">在后续HAL层的开发过程中，也见证了HIDL接口的诞生，在进行Android 8.0系统的升级过程中，发现谷歌将Camera Hal Module从Camera Service 解耦出来，放入一个独立的进程Camera Provider中进行管理，而该进程负责向外暴露HIDL接口，对内完成对其的实现，并且开始针对system分区以及vendor分区进行了严格的权限控制，该目的显而易见，那边是将平台厂商的实现与谷歌Framework相分离，这样便可以进行快速的迭代升级。</p>

<p style="text-indent:2em">进入现在的公司之后，工作内容进一步扩大，涉及到了App部分，而这部分在之前也有所接触，但是并不深入，那个时候还是使用Camera Api v1接口，其定义和HAL1类似，但为了增加其灵活性和扩展性，之后谷歌提出了Camera Api v2接口，现在主要接触的便是该接口，通过简单的几个控制语句便可以实现图像的采集，使用起来比较简单，进一步降低了开发者的门槛，这也从侧面体现出了该接口定义的巧妙。同时，对于Camera Api v2的实现，是通过Camera Framework来完成的，而该层也有着一次不小的演变，刚开始Framework层并不是直接通过AIDL接口与Camera Service进行通信，而是通过一个JNI层来完成从Java到Native的转换，而Native部分作为客户端，保持对Service的通信。这种设计，很显然会比较臃肿，并且代码难以维护，所以之后由于AIDL接口的提出，谷歌直接将其加入到相机框架中，用于保持Framework与Service的通信，进而摈弃了JNI层，进一步减少了不必要的层级结构，保持了整个体系简洁性。</p>

<p style="text-indent:2em">整个相机体系，经历了多次的发展，最终形成了而今的框架结构，一路走来，不难发现都是对于接口的升级，而其升级主要是更新其逻辑定义，完善其具体实现。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%8D%81-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%8D%81-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%B1%82/" class="post-title-link" itemprop="url">Android Camera 体系结构之十 相机硬件层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:05:20 / 修改时间：15:05:44" itemprop="dateCreated datePublished" datetime="2021-06-11T15:05:20+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p style="text-indent:2em">相机的硬件层，作为整个框架的最底层，通过硬件模块接收来自客观世界的真实光影效果，将其转换为计算机所熟知的数字信号，并按照一定的数据格式向上源源不断提供成稳定并成像效果优秀的图像数据，整个部分复杂且高效，可以说是，一个优秀的硬件基础，就好比为整个相机框架的地基，拥有一个好的地基，便使得建造一座摩天大厦成为可能，接下来我们来详细介绍下，这部分各个组件的基本情况。</p>

<h3 id="基本硬件结构"><a href="#基本硬件结构" class="headerlink" title="基本硬件结构"></a>基本硬件结构</h3><p style="text-indent:2em">而今的相机硬件系统纷繁复杂，但是如果仔细深入研究的话，你会发现，其实核心组件无外乎镜头、感光器、图像处理器三大件，其中镜头用来聚光，感光器件用于光电转换，而图像处理器用来加工处理图像数据，接下来我们就以这三个组件开始展开对于相机系统的世界的探索之旅。</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%8D%81-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%B1%82/hardware.jpg" alt="hardware"></p>
<ol>
<li><h4 id="镜头焦距-Lens-Focus"><a href="#镜头焦距-Lens-Focus" class="headerlink" title="镜头焦距(Lens Focus)"></a>镜头焦距(Lens Focus)</h4></li>
</ol>
<p style="text-indent:2em">将时间的转盘向前波动一下，让我们回到各自的小学时代，那时候老师给我们都布置了一个家庭作业，任务是制作一个小孔成像的简单模型，这个简单模型便是我接触的最原始最简单的成像系统，但是那是我一直有一个疑问，成像为什么那么模糊，这个疑问在我接触到真正的相机之后才得以解开，原来一切都是光线惹的祸。</p>

<p style="text-indent:2em">根据小孔成像原理，小孔的一端是光源，另一端是成像平面，光经过小孔，入射到平面上，无数个光线都入射到这个平面上，便形成了光源的像，但是有一个问题，就是光线是按照发散路径向四周蔓延开来，光源某点所发出的某一束光线通过小孔后会到达成像平面的某一点上，但是很显然，该点也会接收来自另一个光源上的点所发出的另一束光线，这样就形成的光的干扰，进而影响了最终的成像效果。所以为了改善这个问题，镜头便被发明出来，而镜头其实就是我们日常生活中接触的凸透镜，其根本目的就是为了解决光线互相干扰的问题，其原理就是通过凸透镜的折射原理，将来自同一点的光线，重新汇聚至一点，从而大幅度提升了成像效果。而这里的重新汇聚的一点便是光源那点在透镜后的像点，而由于随着光源点的不断变换，其像点会相应的变化，所以我们常常将来自无限远处的光线，通过透镜之后汇聚而成的那个点称为该镜头的焦点，而焦点到透镜中心的距离，便称为焦距，一旦透镜制作完成，焦距便被确定下来。</p>

<ol start="2">
<li><h4 id="光圈快门"><a href="#光圈快门" class="headerlink" title="光圈快门"></a>光圈快门</h4></li>
</ol>
<p style="text-indent:2em">对于一个制作完成的镜头，无法随意调整镜头的直径，所以便在其中加入了一个叫做光圈的部件，该部件一般采用正多边形或者圆形的孔状光栅，通过调整光栅开合大小进而控制这个镜头的瞬时进光量，然而针对总的进光亮的控制仅仅依靠光圈也是不够的，需要再用到另一个叫做快门的部件，它主要决定着曝光的时长，最初的快门是通过调整镜头前的盖子的开关来进行实现，随着时代的进步，现在快门衍生出了多个实现方式，其中包括机械快门，它是作为一种只使用弹簧或者其他机械结构，不靠电力来驱动与控制速度的快门结构，电子快门，该快门结构通过马达和磁铁在电力驱动的作用下进行控制。电子断流快门，一种完全没有机械结构的快门结构，具有高快门速率和很快的影响捕捉频率，但是缺点是容易产生高光溢出现象。</p>

<p style="text-indent:2em">光圈控制着瞬时进光量，快门控制着曝光时间，通过两者的共同合作，完成了控制光线进入量的目的，进而进一步真实再现了场景的光影效果，避免了过度曝光的情况发生，极大的提升了整个提成像质量。</p>

<ol start="3">
<li><h4 id="对焦马达"><a href="#对焦马达" class="headerlink" title="对焦马达"></a>对焦马达</h4></li>
</ol>
<p style="text-indent:2em">正如之前所说，入射光线会在通过透镜之后以锥形路径汇聚到一点，该点叫做像点，之后再以锥形发散开去，而所有的相同距离发射的光线，都会汇聚到各自的像点上时，便形成了一个都是像点组成的一个平面，而这个平面一般叫做像平面，又由于这个平面是所有像点所汇聚而成的，所以该平面是成像清晰的，而现如今的对焦的本质便是通过移动透镜，使像平面与感光器件平面重合，从而在感光器件上形成清晰的像。一般来讲，对焦可以通过手动移动透镜完成，但是更一般地，是通过一个叫做对焦马达的器件来完成。除了手动调整镜头进而完成对焦操作外，现在比较主流的方式是通过自动移动透镜进而完成对焦动作，随着技术的不断发展，而今的对焦又发展出了自动对焦策略，其中包括了相位对焦和对比度对焦。其基本原理是前后调整镜头使像平面与感光器感光平面重合，从而形成清晰的成像效果。另外，针对更为复杂的相机系统，为了获得更加优秀的成像质量，一般都会采用多个透镜组合来实现，一来可以消除色差，二来可以通过马达调整透镜间的距离，来动态的修改整个透镜组的焦距，从而满足更加复杂场景下的成像需求。</p>

<ol start="4">
<li><h4 id="感光器-Sensor"><a href="#感光器-Sensor" class="headerlink" title="感光器(Sensor)"></a>感光器(Sensor)</h4></li>
</ol>
<p style="text-indent:2em">正如之前所讲，透镜的作用是为了汇聚光线，从而形成像平面，但是如何将这个所谓的像平面转换成计算机所熟知的图像信息呢？这就需要用到这里的感光器了，感光器并不是现代社会的专有发明，其实早在19世界初期的欧洲便有了这个概念，一位名叫尼埃普斯的法国人通过使用沥青加上薰衣草油，再以铅锡合金板作为片基，拍摄了从他家楼上看到的窗户外的场景，名叫《鸽子窝》的照片，而这里的沥青混以薰衣草油便是一种简单的感光物质，从这开始感光技术开始进入快速发展期，在1888年，美国柯达公司生产出了一种新型感光材料，柔软且可卷绕的胶卷，这是感光材料的一个质的飞跃，之后1969年在贝尔实验室，CCD数字感光器件被发明出来，将整个感光技术推入了数字时代，随后技术的不断革新，便于大规模批量生产的CMOS应运而生，将成像系统往更小更好的方向推进了一大步。随着CMOS的技术不断发展，优势明显的它渐渐取代了CCD，成为相机系统的主流感光器件。</p>

<ol start="5">
<li><h4 id="滤光片-IR-Filter"><a href="#滤光片-IR-Filter" class="headerlink" title="滤光片(IR Filter)"></a>滤光片(IR Filter)</h4></li>
</ol>
<p style="text-indent:2em">由于感光材料的特性所致，它会感受除了可见光波长范围内的光线，比如部分红外光，由于这部分红外光是不可见的，所以对于我们而言没有实际的用处(当然，这也不绝对，有的情况就是需要采集红外光的信息，比如夜视照相机)，并且可能会干扰之后的ISP的处理，所以往往需要使用一个用于过滤红外光，避免红外光线干扰，修正摄入的光线的滤片，一般分为干涉式的IR/AR-CUT(在低通滤波晶片上镀膜，利用干涉相消的原理)和吸收式的玻璃(利用光谱吸收的原理)。</p>

<ol start="6">
<li><h4 id="闪光灯-Flash"><a href="#闪光灯-Flash" class="headerlink" title="闪光灯(Flash)"></a>闪光灯(Flash)</h4></li>
</ol>
<p style="text-indent:2em">针对某些特殊场景，比如暗光环境下拍摄需求，此时由于光线本身较少，无法完成充分的感光操作，但是为了获取正常的拍摄需求，往往需要通过外部补光来作为额外的光照补偿，基于此，闪光灯便应运而生，对于手机而言，其主要分为氙气灯与LED灯两种，由于LED闪光灯具有功耗较低、体积较小的优势，作为手机闪光灯的主流选择。另外，现在很多手机采用了双色闪光灯的策略，双色闪光灯可以根据环境的需要调节两灯发光的强度，可以更为逼近自然光的效果，相比单闪光灯强度有所提升，另外色温也较普通双闪光灯要更为准确，总体来讲效果较好。</p>

<ol start="7">
<li><h4 id="图像处理器-ISP"><a href="#图像处理器-ISP" class="headerlink" title="图像处理器(ISP)"></a>图像处理器(ISP)</h4></li>
</ol>
<p style="text-indent:2em">一旦当感光器件完成光电转换之后，便会将数据给到图像处理器，而ISP第一步需要做的便是去掉暗电流噪声，何为暗电流噪声呢？这要从感光器件说起，针对CCD/CMOS而言，通常并不是全部都用于感光，有一部分是被专门遮挡住，用于采集在并未感光情况的暗电流情况，通过这种方式消除掉暗电流带来的噪声。</p>

<p style="text-indent:2em">对于镜头的各处的折射率不同的属性，会随着视场角的慢慢增大，能够通过镜头的斜光束慢慢减少，从而产生了图像中心亮度较边缘部分要高，这个现象在光学系统中叫做渐晕，很显然这种差异性会带成像的不自然，所以ISP接下来需要对于这种偏差进行修正，而修正的算法便是镜头阴影矫正，具体原理便是以图像中间亮度均匀的区域为中心，计算出个点由于衰减带来的图像变暗速度，从而计算出RGB三通道的补偿因子，根据这些补偿因子来对图像进行修正。</p>

<p style="text-indent:2em">随后，由于感光器件针对光线都是采用红、绿、蓝三基色进行分别采集而成的，所以数据一般会呈现出类似马赛克的排布效果，此时便需要完成去马赛克处理，基本原理便是通过一定的插值算法，通过附近的颜色分量猜测该像素所缺失的颜色分量，力争还原每一个像素的真实颜色效果，从而形成一个颜色真实的图像数据，而此时的数据格式便是RAW数据格式，即最原始的图像数据。</p>

<p style="text-indent:2em">当感光器进行光电转换的过程中，每一个环节都会产生一定的偏差，而这个偏差到最后便会以噪声的方式表现出来，所以接下来需要对于这个无关信息–噪声进行一定的降噪处理，当前主要采用了非线性去噪算法，比如双边滤波器，在采样时不仅考虑了像素在空间距离上的关系，同时还加入了像素间的相似程度考虑，从而保持了原始图像的大体分块，对于边缘信息保持良好。</p>

<p style="text-indent:2em">进一步降低了噪声之后，ISP需要对于图像白平衡进行处理，由于不同场景下的外界色温的不同，需要按照一定的比例调整RGB分量的值，从而使得在感光器中，白色依然是呈现白色的效果。白平衡可以采用手动白平衡，通过手动调整三个颜色分量的比例关系，达到白平衡的目的，而更一般地采用了自动白平衡的处理，这里ISP就承担着自动白平衡的使命，通过对当前图像进行分析，得到各颜色分量的比例关系，进而调整其成像效果。</p>

<p style="text-indent:2em">调整好图像白平衡后，需要进一步地调整颜色误差，这里的误差主要由于滤光片各颜色块之间存在颜色渗透所导致，一般在Tunning过程中会利用相机模组拍摄的图像与标准图像相比较得到的一个矫正矩阵，ISP利用这个矩阵来对拍摄的图像进行图像颜色矫正，从而达到还原拍摄场景中真实颜色的目的。</p>

<p style="text-indent:2em">以上简单罗列了下，图像处理器的几个基本功能，虽然每个厂商所生产的ISP都不尽相同，但是基本都包括了以上几个步骤，由此可见，图像处理器是用来提升整个相机系统的成像效果的。</p>

<h3 id="手机相机简介"><a href="#手机相机简介" class="headerlink" title="手机相机简介"></a>手机相机简介</h3><p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%8D%81-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%B1%82/camera.jpg" alt="img"></p>
<p style="text-indent:2em">对于手机上的相机系统，受到尺寸以及功耗的限制，无法像专业相机那样，为了保证成像效果，可以的很方便地更换更大的镜头，加入更大尺寸的CCD/CMOS感光器件，可以放入更加强大的图像处理模块，所以留给手机的发挥空间并不是很大，但是即便如此，各大手机厂商依旧在有限的空间和续航能力下，将相机系统做到了在某些领域媲美专业相机的地步，接下来我们来简单介绍下这套小体积但具有大能量的相机系统。</p>

<p style="text-indent:2em">如图所示，手机的相机系统可以分为两个部分，一个是相机模组，一个是图像处理器ISP，相机模组是用来进行进行光电转换的，而图像处理器正如之前所介绍那样是用于图像处理的，接下来我们分别来看下，两者在手机端是如何运行的。</p>

<ol>
<li><h4 id="相机模组"><a href="#相机模组" class="headerlink" title="相机模组"></a>相机模组</h4></li>
</ol>
<p style="text-indent:2em">由于受到体积的限制，手机相机模组往往做得十分精致小巧，里面主要包括了镜头、对焦马达、滤光片以及感光器(Sensor)。</p>

<p style="text-indent:2em">一般为了消除色差都会采用多个透镜的组合，手机中的镜头也不例外，其材质多是玻璃和塑料的组合，对于塑料镜头而言，成本较低，适合用于低端产品中的相机系统，而玻璃一般成像质量较高，但是成本也稍高于塑料镜头，所以往往用于一些追求成像质量的手机中，同时其中，镜头主要存在以下几个参数：</p>

<ul>
<li>视场角FOV，该参数表明了通过镜头可以成像多大范围的场景，一般FOV越大就越能看到大范围的景物，但是有可能会带来严重的畸变，通常使用后期的畸变矫正算法来修正大FOV所带来的畸变。</li>
<li>焦距F ，规定所有平行于透镜主轴的光线汇聚到的那点叫做焦点，而焦点到透镜中心的距离便是这里的焦距，一般焦距越大，镜头的FOV也就越小。而越短的焦距，往往FOV越大。</li>
<li>光圈值f，通过镜头焦距与实际光圈的直径比值来指定，该值越小，说明进光量也就越大，手机镜头一般采用f/2.0的固定光圈。</li>
</ul>
<p style="text-indent:2em">紧接着是对焦马达，这部分在手机中主要采用的是音圈马达(VCM)，而为了方便调整镜头，一般会将整个镜头集成在马达模组中，主板通过I2C总线传输指令，进而驱动马达的移动调整镜头达到对焦或者变焦的目的，这里我们简单介绍下音圈马达。**音圈马达**在电子学中被称为音圈电机，之所以被称为音圈，是因为其实现原理与扬声器类似，都是在一个永久磁场内部，通过改变马达内线圈的直流电流大小，来控制弹簧片的拉升位置，进而带动镜头上下运动，达到对焦或者变焦的目的，由于具有着高灵敏度与高精度的特点，使之成为手机的主流对焦组件。在手机端，对于音圈马达的使用一般分为两种模式，一种是变焦，一种是对焦，两者原理和目的都不一样。</p>

<ul>
<li>变焦: 通过马达调整镜头组中某一个透镜的移动，进而改变整个镜头的焦距，引起视场角的变化，从而实现对于景物的放大缩小的目的，这种方式便是我们常说的光学变焦，这种变焦手段的优点是在放大景物的过程中，不会损失图像细节，但是缺点也很明显，受到体积的限制，无法进行大范围的光学变焦，所以手机厂商一般采用光学与数字变焦的组合方式，达到高范围的变焦目的。</li>
<li>对焦: 通过音圈马达直接前后移动整个镜头，使物体的像平面与感光器的感光平面重合，进而得到一幅清晰的图像，这种方式正是对焦的过程。其目的是为了获得清晰的图像。</li>
</ul>
<p style="text-indent:2em">光线在经过了镜头之后，会首先进入到下一个组件–滤光片，该部分会针对光线做进一步处理，主要有两个目的：</p>

<ul>
<li>过滤红外线: 由于感光器会感受到部分不可见的红外线，进而干扰后面的图像处理效果，所以需要通过滤光片，将这部分红外线过滤掉，只让可见光透过。</li>
<li>修正光线: 光线通过透镜之后，并不都是平行垂直射向感光器的，还有很多并非直射的光线，很显然如果不对其进行拦截，会对感光器产生一定的干扰，所以滤光片利用石英的物理偏光特性，保留了直射的光线，反射掉斜射部份，避免影响旁边的感光点，进一步提升成像效果。</li>
</ul>
<p style="text-indent:2em">经过滤光片的过滤与修正，此时入射的光线具有一定的稳定性，此时就需要通过这个相机体系的核心感光器来进行光电转换了。</p>

<p style="text-indent:2em">手机端的感光器主要有CCD与CMOS，但是由于成本较高，体积较大，CCD在手机端已经用的不多了，CMOS成为了这个领域的主流感光器，手机端的CMOS依然采用了三层结构，微透镜/滤光片/感光层，具体定义如下：</p>

<ul>
<li>微透镜层主要用于扩展单个像素的受光面积。</li>
<li>滤光片采用的是Bayer模式，类似与RGB模式，都是采用RGB几个颜色分量来分别度量每一个像素的三通道的灰度值，但是基于人眼对于绿色更为敏感的基本规律，Bayer模式进一步强调了绿色分量，从而将绿色分量分别定义了Gr以及Gb，用于更好地表达图像的色彩和亮度。</li>
<li>感光层，用于将光子转换成电子信号，在经过放大电路以及模数转换电路，将其转换成数字信号。</li>
<li>其感光层的核心便是一个个感光二极管，每一个二极管边上都包含了一个放大器和一个数模转换电路。由于每一个感光元件都有一个放大器，虽然在一定程度上加快的速度的读取，但是却无法保证每一个放大器的放大效果一致，所以这种设计会带来可能的噪声。另外，由于CMOS在每一个二极管旁都加入了额外的硬件电路，势必会造成感光面积的缩小，所以这种设计会影响整体感光效果，这种设计被称为前照式，为了解决该问题，CMOS厂商推出了背照式设计，这种设计将感光像素与金属电极晶体管分别放置于感光片的两面，提高了像素占空比，增加了光线感应效率，增加了像素数量，改善了信噪比，极大的提升了成像效果。</li>
</ul>
<ol start="2">
<li><h4 id="图像处理器"><a href="#图像处理器" class="headerlink" title="图像处理器"></a>图像处理器</h4></li>
</ol>
<p style="text-indent:2em">手机端的图像处理器的实现流程基本和非手机端的相机系统中类似，对于高通平台的ISP，其中主要包括了诸如IFE/BPS/IPE/JPEG等硬件模块，他们分别担任了不通过图像处理任务，接下来我们一一简单介绍下：</p>

<ul>
<li>IFE(Image Front End)： Sensor输出的数据首先会到达IFE，该硬件模块会针对preview以及video去做一些颜色校正、下采样、去马赛克统计3A数据的处理。</li>
<li>BPS(Bayer Processing Segment): 该硬件模块主要用于拍照图像数据的坏点去除、相位对焦、 去马赛克，下采样、HDR处理以及Bayer的混合降噪处理。</li>
<li>IPE(Image Processing Engine): 该硬件主要由NPS、PPS两部分组成，承担诸如硬件降噪（MFNR、MFSR）、图像的裁剪、降噪、颜色处理、细节增强等图像处理工作。</li>
<li>JPEG: 拍照数据的存储通过该硬件模块进行jpeg编码工作。</li>
</ul>
<ol start="3">
<li><h4 id="多摄相机系统"><a href="#多摄相机系统" class="headerlink" title="多摄相机系统"></a>多摄相机系统</h4></li>
</ol>
<p style="text-indent:2em">相对于专业相机而言，手机相机的受众并不了解太多专业的摄影学知识，但是这类群体具有一个明显不同于专业相机受众的特点，那就是比较关注相机的便携性和可玩性，其中便携性不用多说，整体手机相机的都是以小巧著称，但是可玩性方面，各大手机厂商也是煞费苦心，采用了很多策略来扩展了相机的可玩性，其中多摄便是一个比较典型的例子。</p>

<p style="text-indent:2em">早期的手机相机，一般都是单独的后摄走遍天下，其功能比较单一，之后随着时代的发展以及年轻用户日益增多，对于自拍的需求愈发强烈，其中对于该领域的技术也有所突破。所以手机厂商便顺势推出了双摄模式，在手机前面额外加入一个相机模组来主要用于自拍，其中还在ISP中创新性地加入了美颜算法，进而大幅提升了自拍图像效果。紧接着，手机厂商将多个模组集成到手机上，进而满足了多个场景的拍照需求。现如今的手机相机，往往采用了多个摄像模组，有专门的用于拍摄微缩景观的微距模组，也有专门拍摄广角场景的广角模组，也有为了满足特定需求开发的双摄系统，由于双摄技术的飞速发展，而今已经产生了很多中成熟的方案。</p>

<p style="text-indent:2em">双摄技术顾名思义，是采用了两个摄像头模组分别成像，并通过特定的算法处理，融合成一张图像，达到特定成像需求的目的。普遍地，现在双摄方案主要用于实现背景虚化、提升暗光/夜景条件下成像质量、光学变焦，接下来依次进行简单的介绍：</p>

<h5 id="背景虚化-RGB-RGB"><a href="#背景虚化-RGB-RGB" class="headerlink" title="背景虚化(RGB + RGB)"></a><strong>背景虚化(RGB + RGB)</strong></h5><p style="text-indent:2em">为了实现该目的，主要采用了两个RGB的相机模组，同时对景物进行成像，利用三角测量原理，计算出每个点的景深数据，依靠该系列数据，进行前景以及背景的分离，再通过虚化算法针对背景虚化处理，最终营造出背景虚化的成像效果。值得注意的是，这里由于三角测量的原理的限制，需要对两个相机模组进行标定，使得两者成像平面位于同一平面，并且保持像素对齐。</p>

<h5 id="暗光提升-RGB-MONO"><a href="#暗光提升-RGB-MONO" class="headerlink" title="暗光提升(RGB + MONO)"></a><strong>暗光提升(RGB + MONO)</strong></h5><p style="text-indent:2em">在较暗的环境中，往往拍摄出来的效果不尽如人意，所以手机厂商便采用了一个RGB和一个黑白相机模组(MONO)来提升暗光成像效果，具体原理是，由于黑白相机模组没有Bayer滤光片，所以在暗光条件下，可以获得更多的进光量，进而保存了更多的图像细节，再加之RGB相机模组的颜色份量的补充，这样就可以更好的保证了暗光下的成像质量，同样的由于需要对两个相机模组的成像进行融合，所以依然需要进行标定操作，使两个相机模组能够保持像素对齐。</p>

<h5 id="光学变焦-广角-长焦"><a href="#光学变焦-广角-长焦" class="headerlink" title="光学变焦(广角 + 长焦)"></a><strong>光学变焦(广角 + 长焦)</strong></h5><p style="text-indent:2em">光学变焦，正如之前介绍的，完全可以在对焦马达中通过调整单个透镜进行焦距变换，从而实现变焦的目的，但是有受到体积的限制，往往无法从单个相机模组中得到更大的变焦范围，所以手机厂商就提出采用两个具有不同焦距(广角和长焦)的相机模组，共同实现光学变焦的目的，其原理是通过广角模组呈现大范围的场景，通过长焦模组看到更远的场景，在拍照是模组切换以及优秀的融合算法实现了相对平滑的变焦操作。</p><br>

<p style="text-indent:2em">通过上面的介绍，我们可以看到一个相机系统是通过镜头、光圈快门、感光器以及图像处理器组成，而为了提高其成像质量，在发展过程中逐步加入了滤光片、对焦马达以及闪光灯等组件，同时为了将相机系统嵌入手机中，无法避免地对硬件进行了一定的裁剪，比如光圈往往摒弃了可调形式，采用了固定光圈，另外，由于体积以及续航限制，手机上主流感光器主要采用了CMOS，而对焦马达也由于体积限制，对焦范围也有所缩小。但是即便硬件受到不小的限制，通过这这几年图像处理芯片不断发展，以及算法的不断优化，手机相机系统其实正在逐步缩小与专业相机的差距，我相信在不久的将来成像效果手机相机完全可以媲美专业相机。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B9%9D-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93%E9%AB%98%E9%80%9AKMD%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B9%9D-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93%E9%AB%98%E9%80%9AKMD%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/" class="post-title-link" itemprop="url">Android Camera 体系结构之九 相机驱动层–高通KMD框架详解</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:03:20 / 修改时间：15:05:06" itemprop="dateCreated datePublished" datetime="2021-06-11T15:03:20+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">利用了V4L2可扩展这一特性，高通在相机驱动部分实现了自有的一套KMD框架，该框架通过V4L2标准方法在系统中创建设备节点，将控制接口直接暴露给UMD CSL进行访问，而其内部主要定义了一系列核心模块，包括CRM(Camera Request Manager)，用于管理整个KMD的Session/Link的创建销毁以及Request的在子设备间的流转，该模块创建video0设备节点暴露关键接口给UMD，此外还包括了Sync模块，主要负责了UMD/KMD之间的数据同步与传输，创建video1设备节点暴露接口给UMD进行访问，除此之外，为了更精细化地控制一系列的硬件图像处理模块，包括ISP/IPE/Sensor等硬件模块，高通也分别为各自子模块创建了设备节点，进而暴露控制接口给UMD进行访问。</p>

<p style="text-indent:2em">其中主要目录如下：</p>

<ul>
<li><p>cam_core/： 关于KMD核心函数的实现都放在这，主要包括了subdev、node、context的一些诸如创建/注册/销毁等标准方法。</p>
</li>
<li><p>cam_req_mgr/: CRM的具体实现，用于创建v4l2_device，用于管理所有的子设备，同时生成video设备节点，暴露控制接口给UMD，主要包括了Session/Link的行为管理以及Request的同步与分发，此外，还创建了media_device，用于暴露枚举接口给UMD来轮询查找整个KMD的子设备。</p>
</li>
<li><p>cam_sync/: 该部分主要实现了用于保持与UMD的图像数据的同步相关业务逻辑，由于该模块的特殊性，高通直接为其创建了一个单独的video设备节点，暴露了用于同步的一些控制接口。</p>
</li>
<li><p>cam_utils/: 一些共有方法的实现，包括debug方法集等</p>
</li>
<li><p>cam_smmu/: 高通自己实现了一套smmu api，供KMD使用</p>
</li>
<li><p>cam_lrme/: 低分辨率运动估计模块的驱动实现</p>
</li>
<li><p>cam_fd/: 人脸识别的驱动程序</p>
</li>
<li><p>cam_isp/: isp的驱动程序</p>
</li>
<li><p>cam_jpeg/: 编码器，可以通过该驱动完成jpeg的编码工作</p>
</li>
<li><p>cam_cdm/: camera data mover，数据移动器的驱动实现，主要用于解析由CSL传入的命令信息，其中包括了寄存器的设置以及图像数据的处理等。</p>
</li>
<li><p>cam_cpas/: 该模块主要用于CSL获取camera 平台驱动信息，IPE/BPS电源控制等</p>
</li>
<li><p>cam_icp/: image control processor ，图像处理控制器驱动实现</p>
</li>
<li><p>cam_hyp_intf/: Hypervisor 模块接口驱动程序实现</p>
</li>
<li><p>cam_sensor_module/: 类传感器的系列硬件模块</p>
</li>
<li><ul>
<li>cam_actuator/: 对焦马达的驱动实现</li>
<li>cam_cci/: 实现了用于通讯的CCI接口，其中包括了I2C以及gpio的实现</li>
<li>cam_csiphy: 基于MIPI CSI接口的物理层驱动，用于传输图像数据</li>
<li>cam_sensor_io: 使用cam_cci，向上实现了控制sensor的IO接口</li>
<li>cam_sensor: sensor 的驱动实现</li>
<li>cam_sensor_util: sensor相关的公有方法的实现</li>
<li>cam_eeprom: eeprom设备的驱动实现</li>
<li>cam_ois: 光学防抖设备的驱动实现</li>
<li>cam_flash: 闪光灯设备的驱动实现</li>
</ul>
</li>
</ul>
<h3 id="核心模块解析"><a href="#核心模块解析" class="headerlink" title="核心模块解析"></a>核心模块解析</h3><p style="text-indent:2em">正如之前介绍的那样，整个框架主要由三个部分组成，CRM/Camera Sync以及子模块，接下来我们以下图为例简单讲解下各自的关系：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B9%9D-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93%E9%AB%98%E9%80%9AKMD%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3/sub.dev.jpg" alt="sub.dev"></p>
<p style="text-indent:2em">在系统初始化时，CRM内部会创建一个v4l2_device结构体，用于管理所有的子设备，与此同时每一个子设备在注册的时候都会创建各自的v4l2_subdev挂载到该v4l2_device上面。此外，CRM会创建一个video0设备节点提供关键接口给CSL来进行访问，而每个子设备也会在系统中生成各自的v4l2-sbudev设备节点，提供接口给CSL进行更为精细化的控制。而其中的Cam Sync在初始化的过程中，也创建了一个v4l2_device设备，并且生成了video1节点给CSL进行控制。这个框架主要就是围绕这三个部分进行的，CRM用于管理Session/Link的创建，控制Request在各个子设备中的流转，子设备受CSL控制进行配置以及图像处理工作，而一旦图像处理完成便会将结果发送至Cam Sync模块，进上传至CSL中。</p>

<h4 id="CRM-Camera-Request-Manager"><a href="#CRM-Camera-Request-Manager" class="headerlink" title="CRM(Camera Request Manager)"></a>CRM(Camera Request Manager)</h4><p style="text-indent:2em">该模块本质上是一个软件模块，主要做了以下几个事情：</p>

<ul>
<li>接收来自CSL的Session/Link/Request请求，并且维护其在内核的状态。</li>
<li>在不同pipeline delay的子模块间，同步每一个Request状态，并按照需要发送给每一个子设备。</li>
<li>如果出现错误，负责上传至CSL。</li>
<li>负责针对实时子模块的flush操作。</li>
</ul>
<p style="text-indent:2em">其中针对Session/Link/Request的请求便是通过之前创建的video设备节点将接口暴露给CSL，一旦接收到命令便开始进行处理，而命令主要有以下几个：</p>

<ul>
<li>CAM_REQ_MGR_CREATE_SESSION/CAM_REQ_MGR_DESTROY_SESSION： 分别表示了Session的创建和销毁，该Session保持着与CamX-CHI的一一对应关系。</li>
<li>CAM_REQ_MGR_LINK/CAM_REQ_MGR_UNLINK： 分别表示了Link的创建和销毁动作，每一个Session可以包含多条Link，而每一个Link都连接着此次图像采集过程中所需要的子设备，CRM也是通过该Link来管理Request同步与分发的操作。</li>
<li>CAM_REQ_MGR_SCHED_REQ：一旦CSL开始下发Request的时候，便可以通过该命令告知KMD，而在KMD中，CRM会将此次Request存入Link中的in_q数组中，当子设备告知准备好了此次Request的处理后，便通知子设备进行配置并处理Request。</li>
<li>CAM_REQ_MGR_ALLOC_BUF/CAM_REQ_MGR_RELEASE_BUF: 图像缓冲区的申请与释放，CRM中使用cam_mem_table结构体来管理着申请的缓冲区。</li>
</ul>
<p style="text-indent:2em">一旦CRM接收了来自CSL的请求，便会在内部进行处理，而其中的一系列业务处理便会通过接下来的几个结构体来完成：</p>

<p style="text-indent:2em">首先在初始化过程中，会去创建一个cam_req_mgr_device。该结构体有以下几个主要的成员：</p>

<ul>
<li>video: 存储着对应的video_device。</li>
<li>v4l2_dev: 保存着初始化过程中创建的v4l2_device。</li>
<li>subdev_nodes_created: 标志着从属于v4l2_device的子设备是否都成功创建了设备节点。</li>
<li>cam_eventq： v4l2文件描述结构体，其中维护着event事件队列。</li>
</ul>
<p style="text-indent:2em">之后会去创建一个cam_req_mgr_core_device，该结构体比较简单主要用于维护一个Session链表，在CSL下发创建Session的动作后，会将创建好的Session放入该量表中，同时通过crm_lock保持着业务处理中的同步。</p>

<p style="text-indent:2em">一个Session可以包含很多条Link，其中变量num_links存储了Link数量，数组links存储着所有link，entry变量作为当前session的实体可以嵌入cam_req_mgr_core_device中的session链表中进行统一管理。</p>

<p style="text-indent:2em">在CSL下发CAM_REQ_MGR_LINK命令的时候，会去创建cam_req_mgr_core_link。</p>

<p style="text-indent:2em">该结构体比较复杂，接下来我们主要介绍下几个主要的变量：</p>

<ul>
<li>link_hdl：作为该Link的句柄，区别于其它Link。</li>
<li>num_devs： 表示了该条Link上连接了多少个子设备。</li>
<li>max_delay： 表示了从属于该Link上的所有子设备具有的最大的Pipeline delay值。</li>
<li>l_dev： 存储着所有从属于该Link上的子设备，后续对于子设备的控制都是通过该数组来进行的。</li>
<li>req： 该成员主要用于管理下发的request。</li>
<li>state: 标志着该Link的状态，而Link状态主要包括了CAM_CRM_LINK_STATE_AVAILABLE/CAM_CRM_LINK_STATE_IDLE/CAM_CRM_LINK_STATE_READY/CAM_CRM_LINK_STATE_ERR几种状态。</li>
</ul>
<p style="text-indent:2em">创建完Link之后，会将其存入一个存储cam_req_mgr_core_link的全局变量g_links中进行统一管理。</p>

<p style="text-indent:2em">而当下发CAM_REQ_MGR_SCHED_REQ命令的时候，会在内部进行解析，并且将其存入cam_req_mgr_core_link中的cam_req_mgr_req_data中等待后续的流转。</p>

<p style="text-indent:2em">其中in_q变量主要用于存储request，而l_tbl用于记录pipeline delay的相关信息，而apply_data数组用于存储所有的等待处理的request信息。</p>

<h4 id="Cam-Sync"><a href="#Cam-Sync" class="headerlink" title="Cam Sync"></a>Cam Sync</h4><p style="text-indent:2em">该模块本质上是一个软件模块，用于保持与UMD的图像数据的同步，主要利用了V4L2框架的event机制，由CSL进行事件的等待，一旦数据处理完毕，该模块便可以向上层发送事件，进而，通知CSL取出数据进行下一步处理，其中包括了几个主要ioctl的命令：</p>

<ul>
<li>CAM_SYNC_CREATE: 一旦CSL部分需要创建一个用于同步的实体的时候便下发该命令，而在Cam Sync中，会将传入的信息存入内部的sync_table_row数组中进行管理，并且将生成的sync_obj传入上层。</li>
<li>CAM_SYNC_DESTROY： 销毁用于同步的sync实体。</li>
<li>CAM_SYNC_REGISTER_PAYLOAD： 通过该命令将一些同步的回调方法注册到Cam Sync中，这样一但当数据处理完成，Cam Sync便可以由之前创建的sync_obj来找到相应的回调方法，进而调用该回调方法进行后续处理。</li>
<li>CAM_SYNC_DEREGISTER_PAYLOAD：释放之前注册的相关同步实体的信息，包括其回调方法。</li>
<li>CAM_SYNC_SIGNAL：该命令主要用于CamX-CHI中软件Node处理完数据之后，通知Cam Sync进行后续处理的目的。</li>
</ul>
<p style="text-indent:2em">其中包括了几个比较重要的结构体，首先在初始化过程中会去创建sync_device结构体，其主要的几个变量如下：</p>

<ul>
<li>vdev: 创建的video_device。</li>
<li>v4l2_dev: 创建的v4l2_device设备。</li>
<li>sync_table: 用于存储sync_table_row的数组。</li>
<li>cam_sync_eventq: v4l2设备描述符结构体，其中维护着event事件队列。</li>
</ul>
<p style="text-indent:2em">其中最重要的时sync_table中存储的sync_table_row结构体，它代表了整个对应于CSL中的sync object，其中比较重要的变量含义如下：</p>

<ul>
<li>sync_id：该sync object的唯一标识，同时该标识于CSL保持同步。</li>
<li>state: 代表了当前sync object的状态。</li>
<li>user_payload_list： 存储着该sync object所对应的来自UMD的payload，该payload在KMD中并没有被使用，仅仅存储与KMD中，一旦当前sync object被触发，便直接将其再次传入UMD中。</li>
</ul>
<h3 id="模块初始化"><a href="#模块初始化" class="headerlink" title="模块初始化"></a>模块初始化</h3><p style="text-indent:2em">在系统启动初期，整个相机驱动中的各个模块都开始进行加载了，接下来我们依次介绍下：</p>

<p style="text-indent:2em">首先是CRM的初始化，按照linux驱动模块的标准方法，会走到module_init宏声明的驱动结构体中的probe方法，这里是cam_req_mgr_probe方法，在该方法中主要做了以下几个事情：</p>

<ul>
<li>调用cam_v4l2_device_setup方法，创建并向系统注册用于管理所有子设备的v4l2_device。</li>
<li>调用cam_media_device_setup方法，创建并向系统注册media_device，并且创建了media设备节点，用于CSL枚举KMD中所有设备。</li>
<li>调用cam_req_mgr_util_init方法，其中初始化了一个cam_req_mgr_util_hdl_tbl，该结构体中存在一个handle数组，而每一个handle主要用于存储Session、Link以及各个子设备的相关信息，后期在整个图像采集的过程中，都是通过该结构体来找对应的操作实体，进而采取相应的动作。</li>
<li>调用cam_req_mgr_core_device_init方法，该方法中，会去创建并初始化一个cam_req_mgr_core_device结构体，作为全局变量g_crm_core_dev存在于整个框架中，而该结构体中主要包含了用于存储创建的Session的session_head链表，以及用于保护Session临界资源的crm_lock。</li>
</ul>
<p style="text-indent:2em">其次，是Cam Sync的初始化，整个流程最终会走到驱动结构体中的probe方法中，这里是cam_sync_probe方法，在该方法中主要做了以下几个事情：</p>

<ul>
<li>创建sync_dev结构体，该结构中通过一个sync_table_row数组来维护着所有的sync objects。</li>
<li>调用cam_sync_media_controller_init方法，用于创建media_deivce设备，并且创建了media设备节点，提供给CSL枚举子设备的能力。</li>
<li>调用v4l2_device_register方法，创建并像系统注册一个v4l2_device结构体，其中用于ioctl的方法集是指向的g_cam_sync_ioctl_ops，一旦CSL有创建/注册sync objects需求的时候，便会最终走到该方法中，从而实现相应的功能。</li>
<li>调用video_register_device方法，生成video1设备节点，暴露控制接口给CSL。</li>
<li>调用cam_sync_init_entity方法，将video1中的meida_entity中function字段赋值CAM_SYNC_DEVICE_TYPE，这样在UMD就可以通过相应的media节点枚举出该模块。</li>
</ul>
<p style="text-indent:2em">以上两个模块都是具有独立的video设备节点的，但是对于子设备而言，由于代表着相应的硬件设备，同时需要嵌入到整个框架中才能正常运行，所以高通将其抽象成了v4l2_subdev来进行管理，这里主要还是介绍两个比较有代表性的子模块，ISP以及Sensor。</p>

<p style="text-indent:2em">首先来看下ISP的初始化阶段，在其相应的probe方法cam_isp_dev_probe中做了如下几个事情：</p>

<ul>
<li>调用cam_subdev_probe方法，在该方法中，会去注册一个v4l2_subdev，并且将其挂载到CRM中的v4l2_device上，同时还创建了一个node，并且存入了v4l2_subdev中的token中，方便以后进行读取，另外，将方法集赋值为cam_subdev_ops，最后，创建了该v4l2_subdev内部的media_entity，并且为其function字段赋值为CAM_IFE_DEVICE_TYPE，这样也方便在枚举子设备时分辨出当前节点代表着isp模块。</li>
<li>调用cam_isp_hw_mgr_init方法，该方法用于初始化isp中的硬件模块。</li>
<li>调用cam_isp_context_init方法，该方法中会初始化node，在node内部创建一定数量的context，用于后期的状态维护，并且为每一个context都配置了状态机，以及子状态机来用于管理整个isp模块。</li>
</ul>
<p style="text-indent:2em">其次来看下Sensor模块的初始化，在其相应的probe方法cam_sensor_driver_i2c_probe中主要做了以下几个事情：</p>

<ul>
<li>调用cam_sensor_parse_dt方法获取dts中定义的硬件信息。</li>
<li>调用cam_sensor_init_subdev_params方法，该方法中会创建v4l2_subdev，然后挂载到CRM中的v4l2_device中，并且将sensor的私有方法集cam_sensor_internal_ops赋值给v4l2_subdev结构体中的ops，这样一旦操作相应的子设备节点，便最终会走到该方法集中，关于Sensor的一些操作便可以放到这个里面进行处理。最终将创建的v4l2_subdev中的media_entity中functon赋值为CAM_SENSOR_DEVICE_TYPE，方便CSL进行枚举Sensor设备。</li>
</ul>
<p style="text-indent:2em">通过上面的两个子设备的初始化代码梳理，不难发现，并没有进行设备节点的创建，那关于节点的创建动作发生在哪一个阶段呢？ 为了解决这个疑问我们不得不先介绍下linux两个宏定义，一个是module_init，另一个便是late_initcall，两者都是为了声明初始化函数，但是执行时间有一个先后顺序，而late_initcall一般在所有module_init定义的方法都运行完成之后才会被运行，而针对所有子设备的节点的创建便是在这里完成的，在该方法中主要做了以下工作：</p>

<ul>
<li>调用cam_dev_mgr_create_subdev_nodes方法，而在该方法中会去调用v4l2标准方法v4l2_device_register_subdev_nodes来统一创建挂载在CRM中v4l2_device下的子设备节点。</li>
</ul>
<p style="text-indent:2em">至此，整个KMD框架便初始化完成，现在便静静等待CSL下发请求。</p>

<h3 id="处理UMD-CSL请求"><a href="#处理UMD-CSL请求" class="headerlink" title="处理UMD CSL请求"></a>处理UMD CSL请求</h3><p style="text-indent:2em">整个KMD的初始化动作在linux内核启动的时候完成的，要稍早于CamX-CHI整个框架的初始化，所以在CamX-CHI进行初始化的时候，KMD框架的各个资源节点都已准备妥当，接下来我们就以CamX-CHI的初始化开始详细描述下整个KMD处理来自CSL请求的流程。</p>

<ol>
<li><h4 id="获取模块资源"><a href="#获取模块资源" class="headerlink" title="获取模块资源"></a>获取模块资源</h4></li>
</ol>
<p style="text-indent:2em">在CamX-CHI初始化的时候，并不知道内核驱动部分是个什么状态，所以需要打开所有的media设备节点来枚举查询每一个驱动模块。</p>

<p style="text-indent:2em">首先，打开media0，根据CAM_VNODE_DEVICE_TYPE枚举并找到KMD框架中的CRM模块，并调用标准open方法来打开该设备，该动作最终会调用到cam_req_mgr_open方法，该方法主要做了以下几个工作：</p>

<ul>
<li>调用v4l2_fh_open方法，打开v4l2文件。</li>
<li>调用cam_mem_mgr_init方法，初始化了内存管理模块，为之后的缓冲区的申请与释放做好准备。</li>
<li>更新CRM状态为CAM_MEM_MGR_INITIALIZED。</li>
</ul>
<p style="text-indent:2em">在打开video0之后，会另起一个线程用于监听video的事件，这样就建立了与底层的双向通讯，而在此之前，需要通过ioctl方法将CSL需要监听的事件下发到驱动层，其中包括以下几个事件：</p>

<ul>
<li>V4L_EVENT_CAM_REQ_MGR_SOF/V4L_EVENT_CAM_REQ_MGR_SOF_BOOT_TS： 一旦底层产生的SOF事件，便会向CSL发送该事件。</li>
<li>V4L_EVENT_CAM_REQ_MGR_ERROR： 一旦底层产生了错误，会向上抛出该事件。</li>
</ul>
<p style="text-indent:2em">一旦CSL获取了CRM模块信息成功之后，便开始枚举查找各个子模块了，其中会先去打开Sensor子设备，获取硬件信息，并且存入CSL中，然后再依次获取其它诸如IFE/IPE等硬件子模块并获取各自的信息，并存入CSL中，为之后的数据流转做好准备。</p>

<p style="text-indent:2em">以上动作都完成之后，便开始查询Cam Sync模块了，基本流程与CRM大致相同：</p>

<p style="text-indent:2em">调用open方法打开video1，该方法最终会调用内核部分的cam_sync_open方法，而该方法中会调用v4l2_fh_open方法，从而打开v4l2文件。</p>

<p style="text-indent:2em">调用ioctl方法，订阅针对CAM_SYNC_V4L_EVENT_ID_CB_TRIG事件的监听 ，而对于该事件，一般是在子模块处理数据完成之后，会触发Cam Sync发送该事件至上层。</p>

<ol start="2">
<li><h4 id="打开Session"><a href="#打开Session" class="headerlink" title="打开Session"></a>打开Session</h4></li>
</ol>
<p style="text-indent:2em">好了，到这里，整个CamX初始化过程对于底层的请求都已经完成了，一旦用户打开相机应用之后，经过层层调用最终会去打开Session，进而调用video0的相应的ioctl方法传入CAM_REQ_MGR_CREATE_SESSION命令开始在驱动层打开Session的操作，而在驱动部分，会调用到CRM中的cam_req_mgr_create_session方法，在该方法中，会去创建一个用于代表session的handle，并将其存入全局静态变量hdl_tbl中。紧接着会去初始化该session中的link，其中该session管理着两个link数组，一个是用于初始化的links_init数组，一个是用于运行起来之后使用的links数组，这里的会首先初始化所有的links_init中的link，在使用的时候，会从该数组去取出一个空闲的link放入links中进行管理。</p>

<ol start="3">
<li><h4 id="打开设备"><a href="#打开设备" class="headerlink" title="打开设备"></a>打开设备</h4></li>
</ol>
<p style="text-indent:2em">在打开Session之后，随着Pipeline的创建，CamX会通过调用CSL中的相应Node的ioctl方法，下发CAM_ACQUIRE_DEV命令，来依次打开底层硬件设备，这里我们还是以ISP为例进行分析：</p>

<ul>
<li>一旦CSL调用了ISP设备节点的ioctl并且下发了CAM_ACQUIRE_DEV命令，并会通过层层调用一直调到__cam_node_handle_acquire_dev方法，在该方法中会首先去在ISP对应的node中的存储空闲context的队列中获取一个context。</li>
<li>紧接着，调用了cam_context_handle_acquire_dev方法，来通过调用之前获取的context的对应的状态机方法集中的acquire_dev方法来打开isp设备，而在该方法中，会调用cam_create_device_hdl方法，将当前session handle以及isp操作方法集存入存入hdl_tbl中，之后crm会通过该方法集操作isp模块。之后会将当前isp context状态更新为CAM_CTX_ACQUIRED，并且初始化了用于管理request的active_req_list/wati_req_list/pending_req_list/pending_req_list/free_req_list链表，并且将初始化好req_list都挂载到free链表中。</li>
</ul>
<p style="text-indent:2em">除了ISP，会根据不同的图像采集需求，打开不同的子设备，基本流程差不多，都是通过下发CAM_ACQUIRE_DEV命令来完成的，这里我们便不进行赘述了。</p>

<ol start="4">
<li><h4 id="创建Link"><a href="#创建Link" class="headerlink" title="创建Link"></a>创建Link</h4></li>
</ol>
<p style="text-indent:2em">在打开所有的子设备之后，紧接着需要将它们链接起来形成一个拓扑结构，方便各个子模块的管理。而这个动作还是通过调用CRM对应的ioctl下发CAM_REQ_MGR_LINK命令来完成的，该动作会经过层层调用，一直调用到CRM中的cam_req_mgr_link方法，接下来我们具体介绍下该方法的主要动作：</p>

<ul>
<li>调用__cam_req_mgr_reserve_link方法，在该方法中，首先会去从当前Session中的links_init数组中取出一个空闲的link，将其存入links数组，并且初始化其中的用于管理所有的request的in_q队列。</li>
<li>调用cam_create_device_hdl，创建link对应的handle，并且存入hdl_tbl中。</li>
<li>调用__cam_req_mgr_create_subdevs方法，初始化用于存储处于当前Link中的所有子设备。</li>
<li>调用__cam_req_mgr_setup_link_info方法，该方法首先会去调用该link中的所有子设备的get_dev_info方法来获取设备信息，然后会去依次调用hdl_tbl中的链接在此Link上的所有子设备的setup_link方法，来连接子设备，同时也将CRM的一些回调方法通过该方式注入到子设备中，使其具有通知CRM的能力。</li>
<li>更新该Link状态为CAM_CRM_LINK_STATE_READY，并且创建了一个工作队列用于操作的异步处理。</li>
</ul>
<ol start="5">
<li><h4 id="开启数据流"><a href="#开启数据流" class="headerlink" title="开启数据流"></a>开启数据流</h4></li>
</ol>
<p style="text-indent:2em">一旦整个Link创建完成之后，便可以开启数据流了，该动作通过CSL控制每一个子设备来完成，这里还是以ISP为例进行分析：</p>

<p style="text-indent:2em">由于在CamX初始化过程中已经存有打开的ISP文件句柄，所有通过调用其iotcl方法下发CAM_START_DEV命令来通知底层ISP模块开始进行数据流程传输，该命令首先会走到node,然后通过node下发到context，然后调用当前context的状态机对应的start_dev方法，而在该方法中，会首先更新当前context状态为CAM_CTX_ACTIVATED，然后通过操作底层硬件管理模块开始数据流的处理。</p>

<p style="text-indent:2em">除了ISP，还有Sensor/FLash等模块也是需要开启数据流，为之后的Request的下发做好准备。</p>

<ol start="6">
<li><h4 id="下发Request"><a href="#下发Request" class="headerlink" title="下发Request"></a>下发Request</h4></li>
</ol>
<p style="text-indent:2em">一旦开启了整个数据处理流程，便可以接收Request请求了，而该动作依然还是通过CRM来完成，调用其ioctl方法，传入CRM_WORKQ_TASK_SCHED_REQ命令，该动作最终会到达内核CRM中的cam_req_mgr_schedule_request方法，而方法会将此次任务封装成task交由工作队列进行异步处理，而在工作队列中最终会调用其回调方法cam_req_mgr_process_sched_req，该方法主要做了如下工作：</p>

<ul>
<li>取出该request从属的link，并且将其中的in_q取出，找到一个空闲的slot，并将该slot便作为此次request在内核中的实体。</li>
<li>更新该slot的状态为CRM_SLOT_STATUS_REQ_ADDED，并且将link中的open_req_cnt计数加1。</li>
</ul>
<p style="text-indent:2em">从上面的梳理不难看出，下发Request的操作并不复杂，其中并没有一个实际的Request下发到子设备的动作，所以很自然地会产生一个疑问，没有下发Request的动作，那CRM是如何来驱动整个Request的流转的呢? 所以接下来我们来进一步介绍下，整个Request的流转机制。</p>

<ol start="7">
<li><h4 id="子设备处理数据"><a href="#子设备处理数据" class="headerlink" title="子设备处理数据"></a>子设备处理数据</h4></li>
</ol>
<p style="text-indent:2em">当CSL下发Request到KMD之后，便会进入到DRQ中进行流转，通过之前对于CamX的学习，想必大家应该已经熟悉了整个DRQ的运行机制，DRQ的每一个Node都会有一定依赖关系，一旦某个Node满足依赖关系之后，便会调用其ProcessRequest开始进行此次的Request处理，而该动作会将图像数据以及配置信息打包，通过调用ioctl方法下发CAM_CONFIG_DEV到具体的子设备节点来将配置写入KMD子设备中，而一旦子设备收到此次请求之后，会调用当前context的状态机所对应的config_dev方法，接下来我们具体介绍下其中的所作的动作：</p>

<ul>
<li>将此次配置信息包括图像数据放入硬件管理模块中，但是此时并不进行处理，等待处理指示。</li>
<li>将此次Request信息封装一下，通过调用之前setup_link传入的回调方法集中的add_req方法通知CRM，而在CRM中，会首先通过一系列的判断，如果条件满足了便将此次request对应的slot状态更新为CRM_REQ_STATE_READY，并将该request存入pending队列中。</li>
</ul>
<p style="text-indent:2em">由上面的分析，发现该过程中并没有进行实际的硬件配置或者处理，此时便需要等待SOF的事件，来驱动接下来的操作，而SOF事件是ISP来通知CRM的，具体流程如下：</p>

<ul>
<li>EPOCH中断产生，触发回调方法__cam_isp_ctx_notify_sof_in_activated_state，在该方法中会封装事件，并且通过调用CRM中传入的回调方法notify_trigger将事件发送至CRM中。</li>
<li>一旦CRM收取到SOF事件，便会去找到对应的满足要求的request，并且调用__cam_req_mgr_process_req方法通知相应的子设备进行配置。</li>
<li>最后ISP会将此次SOF事件通过V4L2 event机制发送至UMD，通知到CSL中。</li>
</ul>
<ol start="8">
<li><h4 id="数据操作完成"><a href="#数据操作完成" class="headerlink" title="数据操作完成"></a>数据操作完成</h4></li>
</ol>
<p style="text-indent:2em">当CamX中的各自Node完成了下发Request的操作之后，便会等待数据的处理完成，一旦完成便会触发buf_done中断，进而告知context，最终会调用cam_sync_signal方法来通知Cam Sync，而在Cam Sync中会通过子设备调用cam_sync_signal时传入的sync_id在sync_table_row找到相应的sync object，最终通过event机制，将此次处理完成的事件传入UMD CSL中，进而进行后续处理。</p>

<p style="text-indent:2em">等到最后一个Node处理完成之后，此次Request的处理便宣告完成。</p>

<p style="text-indent:2em">之前QCamera & MM-Camera架构采用的相机驱动比较简单，主要就承担了硬件的上下电以及读写寄存器的任务，并且控制方向都是从上到下，并且控制逻辑由UMD负责。但是随着时代的发展，相机硬件模块越发复杂，所以用于直接控制硬件的驱动层也需要承担更为复杂的控制任务，通过上面的分析，我们可以看到，高通重新设计了一套优秀的KMD框架，在其中加入了更多复杂的控制逻辑，以达到精细化控制底层硬件模块的目的，其中比较重要的是CRM对于子设备的横向控制，这样的好处很明显，降低了UMD控制驱动的难度，UMD只需要将请求通过V4L2框架中的设备节点下发至KMD中，之后便由KMD中的CRM来统一管理，适时地将请求下发给各个子设备，进而控制着底层硬件模块。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">Android Camera 体系结构之八 相机驱动层–V4L2框架解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 15:00:52 / 修改时间：15:02:16" itemprop="dateCreated datePublished" datetime="2021-06-11T15:00:52+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">相机驱动层位于HAL Moudle与硬件层之间，借助linux内核驱动框架，以文件节点的方式暴露接口给用户空间，让HAL Module通过标准的文件访问接口，从而能够将请求顺利地下发到内核中，而在内核中，为了更好的支持视频流的操作，早先提出了v4l视频处理框架，但是由于操作复杂，并且代码无法进行较好的重构，难以维护等原因，之后便衍生出了v4l2框架。</p>

<p style="text-indent:2em">V4L2英文是Video for Linux 2，该框架是诞生于Linux系统，用于提供一个标准的视频控制框架，其中一般默认会嵌入media controller框架中进行统一管理，v4l2提供给用户空间操作节点，media controller拥有对于每一个设备的枚举控制能力，与此同时，由于v4l2包含了一定数量的子设备，而这一系列的子设备都是处于平级关系，但是在实际的图像采集过程中，子设备之间往往还存在着包含与被包含的关系，所以为了维护并管理这种关系，media controller针对多个子设备建立了的一个拓扑图，数据流也就按照这个拓扑图进行流转。按照v4l2标准，它将一个数据流设备抽象成一个videoX节点，从属的子设备都对应着各自的v4l2_subdev实现，并且通过media controller进行统一管理，整个流程复杂但高效，同时代码的扩展性也较高。</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/v4l2%E9%A9%B1%E5%8A%A8%E6%9E%B6%E6%9E%84.jpg" alt="img"></p>
<p style="text-indent:2em">而对高通平台而言，高通整个内核相机驱动是建立在v4l2框架上的，并且对其进行了相应的扩展，创建了一个整体相机控制者的CRM，它以节点video0暴露给用户空间，主要用于管理内核中的Session、Request以及与子设备，同时各个子模块都实现了各自的v4l2_subdev设备，并且以v4l2_subdev节点暴露给用户空间，与此同时，高通还创建了另一个video1设备Camera SYNC，该设备主要用于同步数据流，保证用户空间和内核空间的buffer能够高效得进行传递。</p>

<p style="text-indent:2em">再往下与相机驱动交互的便是整个相机框架的最底层Camera Hardware了，驱动部分控制着其上下电逻辑以及寄存器读取时序并按照I2C协议进行与硬件的通信，和根据MIPI CSI协议传递数据，从而达到控制各个硬件设备，并且获取图像数据的目的。</p>

<h3 id="流程简介"><a href="#流程简介" class="headerlink" title="流程简介"></a>流程简介</h3><p style="text-indent:2em">整个对于v4l2的操作主要包含了如下几个主要流程：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/use_v4l2.jpg" alt="img"></p>
<h4 id="打开video设备"><a href="#打开video设备" class="headerlink" title="打开video设备"></a>打开video设备</h4><p style="text-indent:2em">在需要进行视频数据流的操作之前，首先要通过标准的字符设备操作接口open方法来打开一个video设备，并且将返回的字符句柄存在本地，之后的一系列操作都是基于该句柄，而在打开的过程中，会去给每一个子设备的上电，并完成各自的一系列初始化操作。</p>

<h4 id="查看并设置设备"><a href="#查看并设置设备" class="headerlink" title="查看并设置设备"></a>查看并设置设备</h4><p style="text-indent:2em">在打开设备获取其文件句柄之后，就需要查询设备的属性，该动作主要通过ioctl传入VIDIOC_QUERYCAP参数来完成，其中该系列属性通过v4l2_capability结构体来表达，除此之外，还可以通过传入VIDIOC_ENUM_FMT来枚举支持的数据格式，通过传入VIDIOC_G_FMT/VIDIOC_S_FMT来分别获取和获取当前的数据格式，通过传入VIDIOC_G_PARM/VIDIOC_S_PARM来分别获取和设置参数。</p>

<h4 id="申请帧缓冲区"><a href="#申请帧缓冲区" class="headerlink" title="申请帧缓冲区"></a>申请帧缓冲区</h4><p style="text-indent:2em">完成设备的配置之后，便可以开始向设备申请多个用于盛装图像数据的帧缓冲区，该动作通过调用ioctl并且传入VIDIOC_REQBUFS命令来完成，最后将缓冲区通过mmap方式映射到用户空间。</p>

<h4 id="将帧缓冲区入队"><a href="#将帧缓冲区入队" class="headerlink" title="将帧缓冲区入队"></a>将帧缓冲区入队</h4><p style="text-indent:2em">申请好帧缓冲区之后，通过调用ioctl方法传入VIDIOC_QBUF命令来将帧缓冲区加入到v4l2 框架中的缓冲区队列中，静等硬件模块将图像数据填充到缓冲区中。</p>

<h4 id="开启数据流"><a href="#开启数据流" class="headerlink" title="开启数据流"></a>开启数据流</h4><p style="text-indent:2em">将所有的缓冲区都加入队列中之后便可以调用ioctl并且传入VIDIOC_STREAMON命令，来通知整个框架开始进行数据传输，其中大致包括了通知各个子设备开始进行工作，最终将数据填充到V4L2框架中的缓冲区队列中。</p>

<h4 id="将帧缓冲区出队"><a href="#将帧缓冲区出队" class="headerlink" title="将帧缓冲区出队"></a>将帧缓冲区出队</h4><p style="text-indent:2em">一旦数据流开始进行流转了，我们就可以通过调用ioctl下发VIDIOC_DQBUF命令来获取帧缓冲区，并且将缓冲区的图像数据取出，进行预览、拍照或者录像的处理，处理完成之后，需要将此次缓冲区再次放入V4L2框架中的队列中等待下次的图像数据的填充。</p><br>

<p style="text-indent:2em">整个采集图像数据的流程现在看来还是比较简单的，接口的控制逻辑很清晰，主要原因是为了提供给用户的接口简单而且抽象，这样方便用户进行集成开发，其中的大部分复杂的业务处理都被V4L2很好的封装了，接下来我们来详细了解下V4L2框架内部是如何表达以及如何运转的。</p>

<h3 id="关键结构体"><a href="#关键结构体" class="headerlink" title="关键结构体"></a>关键结构体</h3><p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AB-%E7%9B%B8%E6%9C%BA%E9%A9%B1%E5%8A%A8%E5%B1%82%E2%80%93V4L2%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%84%E4%BD%93.jpg" alt="img"></p>
<p style="text-indent:2em">从上图不难看出，v4l2_device作为顶层管理者，一方面通过嵌入到一个video_device中，暴露video设备节点给用户空间进行控制，另一方面，video_device内部会创建一个media_entity作为在media controller中的抽象体，被加入到media_device中的entitie链表中，此外，为了保持对所从属子设备的控制，内部还维护了一个挂载了所有子设备的subdevs链表。</p>

<p style="text-indent:2em">而对于其中每一个子设备而言，统一采用了v4l2_subdev结构体来进行描述，一方面通过嵌入到video_device，暴露v4l2_subdev子设备节点给用户空间进行控制，另一方面其内部也维护着在media controller中的对应的一个media_entity抽象体，而该抽象体也会链入到media_device中的entities链表中。</p>

<p style="text-indent:2em">通过加入entities链表的方式，media_device保持了对所有的设备信息的查询和控制的能力，而该能力会通过media controller框架在用户空间创建meida设备节点，将这种能力暴露给用户进行控制。</p>

<p style="text-indent:2em">由此可见，V4L2框架都是围绕着以上几个主要结构体来进行的，接下来我们依次简单介绍下：</p>

<details><summary>v4l2_device 源码如下：</summary>
<pre><code>struct v4l2_device &#123;
    struct device *dev;
#if defined(CONFIG_MEDIA_CONTROLLER)
    struct media_device *mdev;
#endif
    struct list_head subdevs;
    spinlock_t lock;
    char name[V4L2_DEVICE_NAME_SIZE];
    void (*notify)(struct v4l2_subdev *sd,
        unsigned int notification, void *arg);
    struct v4l2_ctrl_handler *ctrl_handler;
    struct v4l2_prio_state prio;
    struct kref ref;
    void (*release)(struct v4l2_device *v4l2_dev);
&#125;;</code></pre>
</details>


<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_device</span> *<span class="title">mdev</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">subdevs</span>;</span></span><br><span class="line">    <span class="keyword">spinlock_t</span> lock;</span><br><span class="line">    <span class="keyword">char</span> name[V4L2_DEVICE_NAME_SIZE];</span><br><span class="line">    <span class="keyword">void</span> (*notify)(struct v4l2_subdev *sd,</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> notification, <span class="keyword">void</span> *arg);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_prio_state</span> <span class="title">prio</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kref</span> <span class="title">ref</span>;</span></span><br><span class="line">    <span class="keyword">void</span> (*release)(struct v4l2_device *v4l2_dev);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了一个整个V4L2设备，作为整个V4L2的顶层管理者，内部通过一个链表管理着整个从属的所有的子设备，并且如果将整个框架放入media conntroller进行管理，便在初始化的时候需要将创建成功的media_device赋值给内部变量 mdev，这样便建立了于与media_device的联系，驱动通过调用v4l2_device_register方法和v4l2_device_unregister方法分别向系统注册和释放一个v4l2_device。</p>

<p>v4l2_subdev源码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev</span> &#123;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_entity</span> <span class="title">entity</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">module</span> *<span class="title">owner</span>;</span></span><br><span class="line">    <span class="keyword">bool</span> owner_v4l2_dev;</span><br><span class="line">    u32 flags;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> *<span class="title">v4l2_dev</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_ops</span> *<span class="title">ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_internal_ops</span> *<span class="title">internal_ops</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line">    <span class="keyword">char</span> name[V4L2_SUBDEV_NAME_SIZE];</span><br><span class="line">    u32 grp_id;</span><br><span class="line">    <span class="keyword">void</span> *dev_priv;</span><br><span class="line">    <span class="keyword">void</span> *host_priv;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">video_device</span> *<span class="title">devnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">fwnode_handle</span> *<span class="title">fwnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">async_list</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_async_subdev</span> *<span class="title">asd</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_async_notifier</span> *<span class="title">notifier</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_subdev_platform_data</span> *<span class="title">pdata</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了一个子设备，每一个子设备都需要在初始化的时候挂载到一个总的v4l2_device上，并且将该v4l2设备赋值给内部的v4l2_dev变量，之后将自身加入到v4l2_device中的子设备链表中进行统一管理，这种方式提高了遍历访问所有子设备的效率，同时为了表达不同硬件模块的特殊操作行为，v4l2_subdev定义了一个v4l2_subdev_ops 结构体来进行定义，其实现交由不同的硬件模块来具体完成。其中如果使能了CONFIG_MEDIA_CONTROLLER宏，便会在media_controller中生成一个对应的media_entity，来代表该子设备，而该entity便会存入子设备结构体中的entity变量中，最后，如果需要创建一个设备节点的话，通过video_device调用标准API接口进行实现，而相应的video_device便会存入其内部devnode变量中。</p>

<p style="text-indent:2em">video_device源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">video_device</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CONFIG_MEDIA_CONTROLLER)</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_entity</span> <span class="title">entity</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_intf_devnode</span> *<span class="title">intf_devnode</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_pipeline</span> <span class="title">pipe</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_file_operations</span> *<span class="title">fops</span>;</span></span><br><span class="line"> </span><br><span class="line">    u32 device_caps;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* sysfs */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> <span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">cdev</span> *<span class="title">cdev</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_device</span> *<span class="title">v4l2_dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev_parent</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ctrl_handler</span> *<span class="title">ctrl_handler</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span> *<span class="title">queue</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_prio_state</span> *<span class="title">prio</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* device info */</span></span><br><span class="line">    <span class="keyword">char</span> name[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">int</span> vfl_type;</span><br><span class="line">    <span class="keyword">int</span> vfl_dir;</span><br><span class="line">    <span class="keyword">int</span> minor;</span><br><span class="line">    u16 num;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> flags;</span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* V4L2 file handles */</span></span><br><span class="line">    <span class="keyword">spinlock_t</span>      fh_lock;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">fh_list</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span> dev_debug;</span><br><span class="line"> </span><br><span class="line">    v4l2_std_id tvnorms;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* callbacks */</span></span><br><span class="line">    <span class="keyword">void</span> (*release)(struct video_device *vdev);</span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">v4l2_ioctl_ops</span> *<span class="title">ioctl_ops</span>;</span></span><br><span class="line">    DECLARE_BITMAP(valid_ioctls, BASE_VIDIOC_PRIVATE);</span><br><span class="line"> </span><br><span class="line">    DECLARE_BITMAP(disable_locking, BASE_VIDIOC_PRIVATE);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span> *<span class="title">lock</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">如果需要给v4l2_device或者v4l2_subdev在系统中创建节点的话，便需要实现该结构体，并且通过video_register_device方法进行创建，而其中的fops便是video_device所对应的操作方法集，在v4l2框架内部，会将video_device嵌入到一个具有特定主设备号的字符设备中，而其方法集会在操作节点时被调用到。除了这些标准的操作集外，还定义了一系列的ioctl操作集，通过内部ioctl_ops来描述。</p>

<p style="text-indent:2em">media_device源码如下:</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">media_device</span> &#123;</span></span><br><span class="line">    <span class="comment">/* dev-&gt;driver_data points to this struct. */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span> *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_devnode</span> *<span class="title">devnode</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">char</span> model[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">char</span> driver_name[<span class="number">32</span>];</span><br><span class="line">    <span class="keyword">char</span> serial[<span class="number">40</span>];</span><br><span class="line">    <span class="keyword">char</span> bus_info[<span class="number">32</span>];</span><br><span class="line">    u32 hw_revision;</span><br><span class="line"> </span><br><span class="line">    u64 topology_version;</span><br><span class="line"> </span><br><span class="line">    u32 id;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ida</span> <span class="title">entity_internal_idx</span>;</span></span><br><span class="line">    <span class="keyword">int</span> entity_internal_idx_max;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">entities</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">interfaces</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">pads</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">links</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* notify callback list invoked when a new entity is registered */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">entity_notify</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* Serializes graph operations. */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span> <span class="title">graph_mutex</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">media_graph</span> <span class="title">pm_count_walk</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">void</span> *source_priv;</span><br><span class="line">    <span class="keyword">int</span> (*enable_source)(struct media_entity *entity,</span><br><span class="line">                 struct media_pipeline *pipe);</span><br><span class="line">    <span class="keyword">void</span> (*disable_source)(struct media_entity *entity);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">media_device_ops</span> *<span class="title">ops</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">如果使能了CONFIG_MEDIA_CONTROLLER宏，则当v4l2_device初始化的过程中便会去创建一个media_device，而这个media_device便是整个media controller的抽象管理者，每一个v4l2设备以及从属的子设备都会对应的各自的entity，并且将其存入media_device中进行统一管理，与其它抽象设备一样，media_device也具有自身的行为，比如用户可以通过访问media节点，枚举出所有的从属于同一个v4l2_device的子设备，另外，在开启数据流的时候，media_device通过将各个media_entity按照一定的顺序连接起来，实现了数据流向的整体控制。</p>

<p style="text-indent:2em">vb2_queue源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            type;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            io_modes;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span>           *<span class="title">dev</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span>           dma_attrs;</span><br><span class="line">    <span class="keyword">unsigned</span>            bidirectional:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            fileio_read_once:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            fileio_write_immediately:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>            allow_zero_bytesused:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span>           quirk_poll_must_check_waiting_for_buffers:<span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span>            *<span class="title">lock</span>;</span></span><br><span class="line">    <span class="keyword">void</span>                *owner;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_ops</span>        *<span class="title">ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_mem_ops</span>    *<span class="title">mem_ops</span>;</span></span><br><span class="line">    <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">vb2_buf_ops</span>    *<span class="title">buf_ops</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">void</span>                *drv_priv;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            buf_struct_size;</span><br><span class="line">    u32             timestamp_flags;</span><br><span class="line">    <span class="keyword">gfp_t</span>               gfp_flags;</span><br><span class="line">    u32             min_buffers_needed;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* private: internal use only */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mutex</span>            <span class="title">mmap_lock</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            memory;</span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">dma_data_direction</span>     <span class="title">dma_dir</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_buffer</span>       *<span class="title">bufs</span>[<span class="title">VB2_MAX_FRAME</span>];</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            num_buffers;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>        <span class="title">queued_list</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            queued_count;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">atomic_t</span>            owned_by_drv_count;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>        <span class="title">done_list</span>;</span></span><br><span class="line">    <span class="keyword">spinlock_t</span>          done_lock;</span><br><span class="line">    <span class="keyword">wait_queue_head_t</span>       done_wq;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">device</span>           *<span class="title">alloc_devs</span>[<span class="title">VB2_MAX_PLANES</span>];</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            streaming:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            start_streaming_called:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            error:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            waiting_for_buffers:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            is_multiplanar:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            is_output:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            copy_timestamp:<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>            last_buffer_dequeued:<span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_fileio_data</span>      *<span class="title">fileio</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_threadio_data</span>    *<span class="title">threadio</span>;</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_VIDEO_ADV_DEBUG</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Counters for how often these queue-related ops are</span></span><br><span class="line"><span class="comment">     * called. Used to check for unbalanced ops.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    u32             cnt_queue_setup;</span><br><span class="line">    u32             cnt_wait_prepare;</span><br><span class="line">    u32             cnt_wait_finish;</span><br><span class="line">    u32             cnt_start_streaming;</span><br><span class="line">    u32             cnt_stop_streaming;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">在整个V4L2框架运转过程中，最为核心的是图像数据缓冲区的管理，而这个管理工作便是由vb2_queue来完成的，vb2_queue通常在打开设备的时候被创建，其结构体中的vb2_ops可以由驱动自己进行实现，而vb2_mem_ops代表了内存分配的方法集，另外，还有一个用于将管理用户空间和内核空间的相互传递的方法集buf_ops，而该方法集一般都定义为v4l2_buf_ops这一标准方法集。除了这些方法集外，vb2_queue还通过一个vb2_buffer的数组来管理申请的所有数据缓冲区，并且通过queued_list来管理入队状态的所有buffer，通过done_list来管理被填充了数据等待消费的所有buffer。</p>

<p style="text-indent:2em">vb2_buffer源码如下：</p>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">vb2_buffer</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_queue</span>    *<span class="title">vb2_queue</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        index;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        type;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        memory;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span>        num_planes;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">vb2_plane</span>    <span class="title">planes</span>[<span class="title">VB2_MAX_PLANES</span>];</span></span><br><span class="line">    u64         timestamp;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* private: internal use only</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * state:       current buffer state; do not change</span></span><br><span class="line"><span class="comment">     * queued_entry:    entry on the queued buffers list, which holds</span></span><br><span class="line"><span class="comment">     *          all buffers queued from userspace</span></span><br><span class="line"><span class="comment">     * done_entry:      entry on the list that stores all buffers ready</span></span><br><span class="line"><span class="comment">     *          to be dequeued to userspace</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">vb2_buffer_state</span>   <span class="title">state</span>;</span></span><br><span class="line"> </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">queued_entry</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span>    <span class="title">done_entry</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p style="text-indent:2em">该结构体代表了V4L2框架中的图像缓冲区，当处于入队状态时内部queued_entry会被链接到vb2_queue中的queued_list中，当处于等待消费的状态时其内部done_entry会被链接到vb2_queue 中的done_list中，而其中的vb2_queue便是该缓冲区的管理者。</p>

<p style="text-indent:2em">以上便是V4L2框架的几个核心结构体，从上面的简单分析不难看出，v4l2_device作为一个相机内核体系的顶层管理者，内部使用一个链表控制着所有从属子设备v4l2_subdev，使用vb2_queue来申请并管理所有数据缓冲区，并且通过video_device向用户空间暴露设备节点以及控制接口，接收来自用户空间的控制指令，通过将自身嵌入media controller中来实现枚举、连接子设备同时控制数据流走向的目的。</p>

<h3 id="模块初始化"><a href="#模块初始化" class="headerlink" title="模块初始化"></a>模块初始化</h3><p style="text-indent:2em">整个v4l2框架是在linux内核中实现的，所以按照内核驱动的运行机制，会在系统启动的过程中，通过标准的module_init方式进行初始化操作，而其初始化主要包含两个方面，一个是v4l2_device的初始化，一个是子设备的初始化，首先我们来看下v4l2_device的初始化动作的基本流程。</p>

<p style="text-indent:2em">由于驱动的实现都交由各个平台厂商进行实现，所有内部逻辑都各不相同，这里我们抽离出主要方法来进行梳理：</p>

<p style="text-indent:2em">首先对于v4l2_device的初始化而言，在系统启动的过程中，linux内核会找到module_init声明的驱动，调用其probe方法进行探测相应设备，一旦探测成功，便表示初始化工作完成。</p>

<p style="text-indent:2em">而在probe方法内部，主要做了以下操作：</p>

<ul>
<li>获取dts硬件信息，初始化部分硬件设备。</li>
<li>创建v4l2_device结构体，填充信息，通过v4l2_device_register方法向系统注册并且创建video设备节点。</li>
<li>创建media_device结构体，填充信息，通过media_device_register向系统注册，并创建media设备节点，并将其赋值给v4l2_device中的mdev。</li>
<li>创建v4l2_device的media_entity,并将其添加到media controller进行管理。</li>
</ul>
<p style="text-indent:2em">类似于v4l2_device的初始化工作，子设备的流程如下：</p>

<ul>
<li>获取dts硬件信息，初始化子设备硬件模块</li>
<li>创建v4l2_subdev结构体，填充信息，通过v4l2_device_register_subdev向系统注册，并将其挂载到v4l2_device设备中</li>
<li>创建对应的media_entity，并通过media_device_register_entity方法其添加到media controller中进行统一管理。</li>
<li>最后调用v4l2_device_register_subdev_nodes方法，为所有的设置了V4L2_SUBDEV_FL_HAS_DEVNODE属性的子设备创建设备节点。</li>
</ul>
<h3 id="处理用户空间请求"><a href="#处理用户空间请求" class="headerlink" title="处理用户空间请求"></a>处理用户空间请求</h3><p style="text-indent:2em">系统启动之后，初始化工作便已经完成，现在一旦用户想要使用图像采集功能，便会触发整个视频采集流程，会通过操作相应的video节点来获取图像数据，一般来讲，标准的V4L2框架只需要通过操作video节点即可，但是由于现在的硬件功能越来越复杂，常规的v4l2_controller已经满足不了采集需求，所以现在的平台厂商通常会暴露子设备的设备节点，在用户空间直接通过标准的字符设备控制接口来控制各个设备，而现在我们的目的是梳理V4L2框架，所以暂时默认不创建子设备节点，简单介绍下整个流程。</p>

<p style="text-indent:2em">在操作之前，还有一个准备工作需要做，那就是需要找到哪些是我们所需要的设备，而它的设备节点是什么，此时便可以通过打开media设备节点，并且通过ioctl注入MEDIA_IOC_ENUM_ENTITIES参数来获取v4l2_device下的video设备节点，该操作会调用到内核中的media_device_ioctl方法，而之后根据传入的命令，进而调用到media_device_enum_entities方法来枚举所有的设备。</p>

<p style="text-indent:2em">整个采集流程，主要使用三个标准字符设备接口来完成，分别是用于打开设备的open方法、用于控制设备的ioctl方法以及关闭设备的close方法。</p>

<ol>
<li><h4 id="打开设备-open"><a href="#打开设备-open" class="headerlink" title="打开设备(open)"></a>打开设备(open)</h4></li>
</ol>
<p style="text-indent:2em">一旦确认了我们需要操作的video节点是哪一个，便可以通过调用字符设备标准接口open方法来打开设备，而这个方法会首先陷入内核空间，然后调用file_operations中的open方法，再到v4l2_file_operations中的open方法，而该方法由驱动自己进行实现，其中主要包括了给各个硬件模块上电，并且调用vb2_queue_init方法创建并初始化一个vb2_queue用于数据缓冲区的管理。</p>

<ol start="2">
<li><h4 id="控制设备-ioctl"><a href="#控制设备-ioctl" class="headerlink" title="控制设备(ioctl)"></a>控制设备(ioctl)</h4></li>
</ol>
<p style="text-indent:2em">在打开设备之后，接下来的大部分操作都是通过ioctl方法来完成的，而在该方法中，会首先陷入到内核空间，之后调用字符设备的v4l2_fops中的v4l2_ioctl方法，而在该方法中又会去调用video_device的video_ioctl2方法，video_ioctl2方法定义了一系列video标准的方法，通过不同的命令在v4l2_ioctls中找到相应的标准方法实现，同时为了满足用户自定义命令的实现，在video_ioctl2方法中会去调用到之前注册video_device时赋予的ioctl_ops中的vidioc_default方法，在该方法中加入用户自己的控制逻辑。</p>

<p style="text-indent:2em">在整个控制流程中，首先通过命令VIDIOC_QUERYCAP来获取设备所具有的属性，通过VIDIOC_G_PARM/VIDIOC_S_PARM来分别获取和设置设备参数，在这一系列操作配置完成之后，便需要向内核申请用于数据流转的缓冲区(Buffer)，该操作通过命令VIDIOC_REQBUFS来完成，在内核部分主要调用了标准方法vb2_reqbufs，进而调用__vb2_queue_alloc来向内核申请已知个数的Buffer，并且将其存入之前创建的vb2_queue中进行管理。</p>

<p style="text-indent:2em">申请好了Buffer之后，便可以通过传入VIDIOC_QBUF命令将申请的Buffer入队，具体操作最终会调用vb2_qbuf方法，而在该方法中会从vb2_queue的bufs数组中取出Buffer，将其加入queued_list链表中，并且更新Buffer状态，等待数据的填充或者来自用户空间的出队操作。</p>

<p style="text-indent:2em">在完成上面的操作后，整个数据流并没有开始流转起来，所以需要下发VIDIOC_STREAMON命令来通知整个框架开始出数据，在驱动中主要会去调用vb2_streamon方法，进而调用vb2_start_streaming方法，其中该方法会去将队列中的的Buffer放入到相应的驱动中，等待被填充，紧接着会去调用vb2_queue.ops.start_streaming方法来通知设备开始出图，而该方法一般由驱动自己实现，最后会调用v4l2_subdev_call(subdev, video, s_stream, mode)方法通知各个子设备开始出图。</p>

<p style="text-indent:2em">当有图像产生时，会填充到之前传入的buffer中，并且调用vb2_buffer_done方法通知vb2_queue将buffer加入到done_list链表中，并更新状态为VB2_BUF_STATE_DONE。</p>

<p style="text-indent:2em">在整个数据流开启之后，并不会自动的将图像传入用户空间，必须通过VIDIOC_DQBUF命令来从设备中读取一个帧图像数据，具体操作是通过层层调用会调用到vb2_dqbuf方法，而在该方法中会调用__vb2_get_done_vb方法去从done_list中获取Buffer，如果当前链表为空则会等待最终数据准备好，如果有准备好的buffer便直接从done_list取出，并且将其从queued_list中去掉，最后通过__vb2_dqbuf方法将Buffer返回用户空间。</p>

<p style="text-indent:2em">获取到图像数据之后，便可以进行后期的图像处理流程了，在处理完成之后，需要下发VIDIOC_QBUF将此次buffer重新加入queued_list中，等待下一次的数据的填充和出队操作。</p>

<p style="text-indent:2em">但不需要进行图像的采集时，可以通过下发VIDIOC_STREAMOFF命令来停止整个流程，具体流程首先会调用v4l2_subdev_call(subdev, video, s_stream, 0)通知所有子设备停止出图操作，其次调用vb2_buffer_done唤醒可能的等待Buffer的线程，同时更新Buffer状态为VB2_BUF_STATE_ERROR，然后调用vb2_streamoff取消所有的数据流并更新vb2_queue.streaming的为disable状态。</p>

<ol start="3">
<li><h4 id="关闭设备-close"><a href="#关闭设备-close" class="headerlink" title="关闭设备(close)"></a>关闭设备(close)</h4></li>
</ol>
<p style="text-indent:2em">当确认不使用当前设备进行图像采集操作之后，便可以调用标准方法close来关闭设备。其中主要包括了调用vb2_queue_release方法释放了vb2_queue以及设备下电操作和相关资源的释放。</p><br>

<p style="text-indent:2em">通过上面的介绍，我相信我们已经对整个V4L2框架有了一个比较深入的认识， 然而对于一个优秀的软件架构而言，仅仅是支持现有的功能是远远不够的，随着功能的不断完善，势必会出现需要进行扩展的地方，而v4l2在设计之初便很好的考虑到了这一点，所以提供了用于扩展的方法集，开发者可以通过加入自定的命令来扩充整个框架，高通在这一点上做的非常好，在v4l2框架基础上，设计出了一个独特的KMD框架，提供给UMD CSL进行访问的接口。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">Android Camera 体系结构之七 相机硬件抽象层实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:57:09 / 修改时间：14:57:50" itemprop="dateCreated datePublished" datetime="2021-06-11T14:57:09+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">回顾高通平台Camera HAL历史，之前高通采用的是QCamera & MM-Camera架构，但是为了更精细化控制底层硬件(Sensor/ISP等关键硬件)，同时方便手机厂商自定义一些功能，现在提出了CamX-CHI架构，由于在CamX-CHI中完全看不到之前老架构的影子，所以它完全是一个全新的架构，它将一些高度统一的功能性接口抽离出来放到CamX中，将可定制化的部分放在CHI中供不同厂商进行修改，实现各自独有的特色功能，这样设计的好处显而易见，那便是即便开发者对于CamX并不是很了解，但是依然可以很方便的加入自定义的功能，从而降低了开发者在高通平台的开发门槛。</p>

<p style="text-indent:2em">接下来我们以最直观的目录结构入手对该架构做一个简单的认识，以下便是CamX-CHI基本目录结构：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/camx-chi.jpg" alt="img"></p>
<p style="text-indent:2em">该部分代码主要位于 vendor/qcom/proprietary/ 目录下，其中camx代表了通用功能性接口的代码实现集合(CamX)，chi-cdk代表了可定制化需求的代码实现集合(CHI)，从图中可以看出CamX部分对上作为HAL3接口的实现，对下通过v4l2框架与Kernel保持通讯，中间通过互相dlopen so库并获取对方操作接口的方式保持着与CHI的交互。</p>

<h4 id="camx-中有如下几个主要目录："><a href="#camx-中有如下几个主要目录：" class="headerlink" title="camx/中有如下几个主要目录："></a>camx/中有如下几个主要目录：</h4><ul>
<li>core/ ：用于存放camx的核心实现模块，如Session、Manager、Pipeline等结构的实现。其中还包含了主要用于实现HAL3接口的hal/(halutils/)目录，以及负责与CHI进行交互的chi/目录</li>
<li>csl/：用于存放主要负责camx与camera driver的通讯模块，为camx提供了统一的Camera driver控制接口</li>
<li>hwl/：硬件流程和用于存放自身具有独立运算能力的硬件node的实现，包括bps、ipe、ife、jpeg等，该部分node受csl管理。</li>
<li>swl/：软件流程和用于存放自身并不具有独立运算能力必须依靠CPU才能实现的node的实现。包括stats、jpeg、sensor等。</li>
</ul>
<h4 id="chi-cdk-vendor-中有如下几个主要目录："><a href="#chi-cdk-vendor-中有如下几个主要目录：" class="headerlink" title="chi-cdk/vendor/中有如下几个主要目录："></a>chi-cdk/vendor/中有如下几个主要目录：</h4><ul>
<li>chioverride/: 用于存放CHI实现的核心模块，负责与camx进行交互并且实现了CHI的总体框架以及具体的业务处理逻辑。</li>
<li>bin/: 用于存放平台相关的配置项</li>
<li>topology/: 拓扑图xml，用于存放用户自定义的usecase.xml配置文件</li>
<li>node/: 各个node的实现，用于存放用户自定义功能的node</li>
<li>module/: 模组驱动配置，用于存放不同sensor的配置文件，该部分在初始化sensor的时候需要用到</li>
<li>tuning/: 效果调试参数，用于存放不同场景下的效果参数的配置文件</li>
<li>sensor/: sensor驱动配置，用于存放不同sensor的私有信息以及寄存器配置参数</li>
<li>actuator/: VCM驱动配置，用于存放不同对焦模块的配置信息</li>
<li>ois/：ois驱动配置，用于存放防抖模块的配置信息</li>
<li>flash/：闪光灯驱动配置，存放着闪光灯模块的配置信息</li>
<li>eeprom/: eeprom驱动配置，存放着eeprom外部存储模块的配置信息</li>
<li>fd/: 人脸参数配置，存放了人脸识别模块的配置信息</li>
</ul>
<h3 id="基本组件概念"><a href="#基本组件概念" class="headerlink" title="基本组件概念"></a>基本组件概念</h3><h4 id="Usecase"><a href="#Usecase" class="headerlink" title="Usecase"></a>Usecase</h4><p style="text-indent:2em">作为CamX-CHI中最大的抽象概念，其中包含了多条实现特定功能的Pipeline，具体实现是在CHI中通过Usecase类完成的，该类主要负责了其中的业务处理以及资源的管理。Usecase类，提供了一系列通用接口，作为现有的所有Usecase的基类。其中AdvancedCameraUsecase又继承于CameraUsecaseBase，相机中绝大部分场景会通过实例化AdvancedCameraUsecase来完成，它包括了几个主要接口：</p>

<ul>
<li>Create(): 该方法是静态方法，用于创建一个AdvancedCameraUsecase实例，在其初始化方法中会调用SelectUsecaseConfig方法去获取XML中的相应的Usecase配置信息。</li>
<li>ExecuteCaptureRequest(): 该方法用于下发一次Request请求。</li>
<li>ProcessResultCb(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session数据处理完成的时候便会调用该方法将结果发送到AdvancedCameraUsecase中。</li>
<li>ProcessDriverPartialCaptureResult(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session中产生了partial metadata的时候，便会调用该方法将其发送至AdvancedCameraUsecase中。</li>
<li>ProcessMessageCb(): 该方法会在创建Session的过程中，作为回调方法注册到其中，一旦Session产生任何事件，便会调用该方法通知到AdvancedCameraUsecase中。</li>
<li>ExecuteFlush(): 该方法用于刷新AdvancedCameraUsecase。</li>
<li>Destroy(): 该方法用于安全销毁AdvancedCameraUsecase。</li>
</ul>
<p style="text-indent:2em">Usecase的可定制化部分被抽象出来放在了(TARGET_PRODUCT)_usecase.xml中。这里简单介绍其中的几个主要的标签含义：</p>

<ul>
<li>UsecaseName: 代表了该Usecase的名字，后期根据这个名字找到这个Usecase的定义。</li>
<li>Targets: 用于表示用于输出的数据流的集合，其中包括了数据流的格式，输出Size的范围等。</li>
<li>Pipeline: 用于定义该Usecase可以使用的所有Pipeline，这里必须至少定义一条Pipeline。</li>
</ul>
<p style="text-indent:2em">根据chioverride/default/build/android/Android.mk文件规则，编译时会根据此xml的配置生成对应chioverride/default/g_pipelines.h。</p>

<h4 id="Feature"><a href="#Feature" class="headerlink" title="Feature"></a>Feature</h4><p style="text-indent:2em">代表了一个特定的功能，该功能需要多条Pipeline组合起来实现，受Usecase统一管理，在CHI中通过Feature类进行实现，在XML中没有对应的定义，具体的Feature选取工作是在Usecase中完成的，通过在创建Feature的时候，传入Usecase的实例的方式，来和Usecase进行相互访问各自的资源。以下是现有的Feature，其中Feature作为基类存在，定义了一系列通用方法。</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/feature.jpg" alt="img"></p>
<p style="text-indent:2em">几个常用的Feature:</p>

<ul>
<li>FeatureHDR: 用于实现HDR功能，它负责管理内部的一条或者几条pipeline的资源以及它们的流转，最终输出具有HDR效果的图像。</li>
<li>FeatureMFNR: 用于实现MFNR功能，内部分为几个大的流程，分别包括Prefiltering、Blending、Postfilter以及最终的OfflineNoiseReproces(这一个是可选择使能的)，每一个小功能中包含了各自的pipeline。</li>
<li>FeatureASD: 用于AI功能的实现，在预览的时候，接收每一帧数据，并且进行分析当前场景的AI识别输出结果，并其通过诸如到metadata方式给到上层，进行后续的处理。</li>
</ul>
<h4 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h4><p style="text-indent:2em">
用于管理pipeline的抽象控制单元，一个Session中至少拥有一个pipeine，并且控制着所有的硬件资源，管控着每一个内部pipeline的request的流转以及数据的输入输出，它没有可定制化的部分，所以在CHI中的XML文件中并没有将Session作为一个独立的单元进行定义。Session的实现主要通过CamX中的Session类，其主要接口如下：</p>


<ul>
<li>Initialize(): 根据传入的参数SessionCreateData进行Session的初始化工作。</li>
<li>NotifyResult(): 内部的Pipeline通过该接口将结果发送到Session中。</li>
<li>ProcessCaptureRequest(): 该方法用于用户决定发送一个Request到Session中的时候调用。</li>
<li>StreamOn(): 通过传入的Pipeline句柄，开始硬件的数据传输。</li>
<li>StreamOff(): 通过传入的Pipeline句柄，停止硬件的数据传输。</li>
</ul>
<h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p style="text-indent:2em">作为提供单一特定功能的所有资源的集合，维护着所有硬件资源以及数据的流转，每一个Pipeline包括了其中的Node/Link，在CamX中通过Pipeline类进行实现，负责整条Pipeline的软硬件资源的维护以及业务逻辑的处理，接下来我们简单看下该类的几个主要接口：</p>

<ul>
<li>Create(): 该方法是一个静态方法，根据传入的PipelineCreateInputData信息来实例化一个Pipeline对象。</li>
<li>StreamOn(): 通知Pipeline开始硬件的数据传输</li>
<li>StreamOff(): 通知Pipeline停止硬件的数据传输</li>
<li>FinalizePipeline(): 用于完成Pipeline的设置工作</li>
<li>OpenRequest(): open一个CSL用于流转的Request</li>
<li>ProcessRequest(): 开始下发Request</li>
<li>NotifyNodeMetadataDone(): 该方法是Pipeline提供给Node，当Node内部生成了metadata，便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessMetadataRequestIdDone通知Session。</li>
<li>NotifyNodePartialMetadataDone(): 该方法是Pipeline提供给Node，当Node内部生成了partial metadata，便会调用该方法来通知metadata已经完成，最后当所有Node都通知Pipeline metadata已经完成，Pipeline 便会调用ProcessPartialMetadataRequestIdDone通知Session。</li>
<li>SinkPortFenceSignaled(): 用来通知Session 某个sink port的fence处于被触发的状态。</li>
<li>NonSinkPortFenceSignaled(): 用来通知Session 某个non sink port的fence处于被触发的状态。</li>
</ul>
<p style="text-indent:2em">Pipeline中的Node以及连接方式都在XML中被定义，其主要包含了以下几个标签定义：</p>

<ul>
<li>PipelineName: 用来定义该条Pipeline的名称</li>
<li>NodeList: 该标签中定义了该条Pipeline的所有的Node</li>
<li>PortLinkages: 该标签定义了Node上不同端口之间的连接关系</li>
</ul>
<h4 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h4><p style="text-indent:2em">作为单个具有独立处理功能的抽象模块，可以是硬件单元也可以是软件单元，关于Node的具体实现是CamX中的Node类来完成的，其中CamX-CHI中主要分为两个大类，一个是高通自己实现的Node包括硬件Node，一个是CHI中提供给用户进行实现的Node，其主要方法如下：</p>

<ul>
<li>Create(): 该方法是静态方法，用于实例化一个Node对象。</li>
<li>ExecuteProcessRequest(): 该方法用于针对hwl node下发request的操作。</li>
<li>ProcessRequestIdDone(): 一旦该Node当前request已经处理完成，便会通过调用该方法通知Pipeline。</li>
<li>ProcessMetadataDone(): 一旦该Node的当前request的metadata已经生成，便会通过调用该方法通知到Pipeline。</li>
<li>ProcessPartialMetadataDone(): 一旦该Node的当前request的partial metadata已经生成，便会通过调用该方法通知到Pipeline。</li>
<li>CreateImageBufferManager(): 创建ImageBufferManager</li>
</ul>
<p style="text-indent:2em">其可定制化的部分作为标签在XML中进行定义：</p>

<ul>
<li>NodeName： 用来定义该Node的名称</li>
<li>NodeId: 用来指定该Node的ID，其中IPE NodeId为65538，IFE NodeId为65536，用户自定义的NodeId为255。</li>
<li>NodeInstance: 用于定义该Node的当前实例的名称。</li>
<li>NodeInstanceId: 用于指定该Node实例的Id。</li>
</ul>
<h4 id="Link"><a href="#Link" class="headerlink" title="Link"></a>Link</h4><p style="text-indent:2em">用于定义不同Port的连接，一个Port可以根据需要建立多条与其它从属于不同Node的Port的连接，它通过标签来进行定义，其中包括了作为输入端口，作为输出端口。一个Link中包含了一个SrcPort和一个DstPort，分别代表了输入端口和输出端口，然后BufferProperties用于表示两个端口之间的buffer配置。</p>

<h4 id="Port"><a href="#Port" class="headerlink" title="Port"></a>Port</h4><p style="text-indent:2em">作为Node的输入输出的端口，在XML文件中，标签用来定义一个输入端口，标签用来定义输出端口，每一个Node都可以根据需要使用一个或者多个输入输出端口，使用OutputPort以及InputPort结构体来进行在代码中定义。</p>

<ul>
<li>PortName: 该端口的名称</li>
<li>PortId: 该端口的Id</li>
<li>NodeName: 该端口从属的Node名称</li>
<li>NodeId: 该端口从属的Node的Id</li>
<li>NodeInstance: 该端口从属的Node的实例名称</li>
<li>NodeInstanceId: 该端口从属的Node的实例的Id</li>
</ul>
<h3 id="组件结构关系"><a href="#组件结构关系" class="headerlink" title="组件结构关系"></a>组件结构关系</h3><p style="text-indent:2em">通过之前的介绍，我们对于几个基本组件有了一个比较清晰地认识，但是任何一个框架体系并不是仅靠组件胡乱堆砌而成的，相反，它们都必须基于各自的定位，按照各自所独有的行为模式，同时按照约定俗成的一系列规则组合起来，共同完成整个框架某一特定的功能。所以这里不得不产生一个疑问，在该框架中它们到底是如何组织起来的呢？它们之间的关系又是如何的呢？ 接下来我们以下图入手开始进行分析：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/relationship_between_components.jpg" alt="img"></p>
<p style="text-indent:2em">由上图可以看到，几者是通过包含关系组合起来的，Usecase 包含Feature，而Feature包含了Session，Session又维护了内部的Pipeline的流转，而每一条pipeline中又通过Link将所有Node都连接了起来，接下我们就这几种关系详细讲解下：</p>

<p style="text-indent:2em">首先，一个Usecase代表了某个特定的图像采集场景，比如人像场景，后置拍照场景等等，在初始化的时候通过根据上层传入的一些具体信息来进行创建，这个过程中，一方面实例化了特定的Usecase，这个实例是用来管理整个场景的所有资源，同时也负责其中的业务处理逻辑，另一方面，获取了定义在XML中的特定Usecase，获取了用于实现某些特定功能的pipeline。</p>

<p style="text-indent:2em">其次，在Usecase中，Feature是一个可选项，如果当前用户选择了HDR模式或者需要在Zoom下进行拍照等特殊功能的话，在Usecase创建过程中，便会根据需要创建一个或者多个Feature，一般一个Feature对应着一个特定的功能，如果场景中并不需要任何特定的功能，则也完全可以不使用也不创建任何Feature。</p>

<p style="text-indent:2em">然后，每一个Usecase或者Feature都可以包含一个或者多个Session，每一个Session都是直接管理并负责了内部的Pipeline的数据流转，其中每一次的Request都是Usecase或者Feature通过Session下发到内部的Pipeline进行处理，数据处理完成之后也是通过Session的方法将结果给到CHI中，之后是直接给到上层还是将数据封装下再次下发到另一个Session中进行后处理，这都交由CHI来决定。其中，Session和Pipeline是一对多的关系，通常一个Session只包含了一条Pipeline，用于某个特定图像处理功能的实现，但是也不绝对，比如FeatureMFNR中包含的Session就包括了三条pipeline，又比如后置人像预览，也是用一个Session包含了两条分别用于主副双摄预览的Pipeline，主要是要看当前功能需要的pipeline数量以及它们之间是否存在一定关联。</p>

<p style="text-indent:2em">同时，根据上面关于Pipeline的定义，它内部包含了一定数量的Node，并且实现的功能越复杂，所包含的Node也就越多，同时Node之间的连接也就越错综复杂，比如后置人像预览虚化效果的实现就是将拿到的主副双摄的图像通过RTBOfflinePreview这一条Pipeline将两帧图像合成一帧具有虚化效果的图像，从而完成了虚化功能。</p>

<p style="text-indent:2em">最后Pipeline中的Node的连接方式是通过XML文件中的Link来进行描述的，每一个Link定义了一个输入端和输出端分别对应着不同Node上面的输入输出端口，通过这种方式就将其中的一个Node的输出端与另外一个Node的输入端，一个一个串联起来，等到图像数据从Pipeline的起始端开始输入的时候，便可以按照这种定义好的轨迹在一个一个Node之间进行流转，而在流转的过程中每经过一个Node都会在内部对数据进行处理，这样等到数据从起始端一直流转到最后一个Node的输出端的时候，数据就经过了很多次处理，这些处理效果最后叠加在一起便是该Pipeline所要实现的功能，比如降噪、虚化等等。</p>

<h3 id="关键流程详解"><a href="#关键流程详解" class="headerlink" title="关键流程详解"></a>关键流程详解</h3><h4 id="Camera-Provider-启动初始化"><a href="#Camera-Provider-启动初始化" class="headerlink" title="Camera Provider 启动初始化"></a>Camera Provider 启动初始化</h4><p style="text-indent:2em">当系统启动的时候，Camera Provider主程序会被运行，在整个程序初始化的过程中会通过获取到的camera_module_t调用其get_number_of_camera接口获取底层支持的camera数量，由于是第一次获取，所以在CamX-CHI中会伴随着很多初始化动作，具体操作见下图：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/camera_provider_%E5%90%AF%E5%8A%A8%E5%88%9D%E5%A7%8B%E5%8C%96.jpg" alt="img"></p>
<p style="text-indent:2em">主要流程如下：</p>

<ol>
<li>通过HAL3Module::GetInstance()静态方法实例化了HAL3Module对象，在其构造方法里面通过HwEnvironment::GetInstance()静态方法又实例化了HwEnvironment对象，在其构造方法中，实例化了SettingsManager对象，然后又在它构造方法中通过OverrideSettingsFile对象获取了位于/vendor/etc/camera/camxoverridesettings.txt文件中的平台相关的配置信息（通过这种Override机制方便平台厂商加入自定义配置），该配置文件中，可以加入平台特定的配置项，比如可以通过设置multiCameraEnable的值来表示当前平台是否支持多摄，或者通过设置overrideLogLevels设置项来配置CamX-CHI部分的Log输出等级等等。</li>
<li>同时在HwEnvironment构造方法中会调用其Initialize方法，在该方法中实例化了CSLModeManager对象，并通过CSLModeManager提供的接口，获取了所有底层支持的硬件设备信息，其中包括了Camera Request Manager、CAPS模块(该驱动模块主要用于CSL获取Camera平台驱动信息，以及IPE/BPS模块的电源控制)以及Sensor/IPE/Flash等硬件模块，并且通过调用CSLHwInternalProbeSensorHW方法获取了当前设备安装的Sensor模组信息，并且将获取的信息暂存起来，等待后续阶段使用，总得来说在HwEnvironment初始化的过程中,通过探测方法获取了所有底层的硬件驱动模块，并将其信息存储下来供后续阶段使用。</li>
<li>之后通过调用HwEnvironment对象中的ProbeChiCompoents方法在/vendor/lib64/camera/components路径下找寻各个Node生成的So库，并获取Node提供的标准对外接口，这些Node不但包括CHI部分用户自定义的模块，还包括了CamX部分实现的硬件模块，并最后都将其都存入ExternalComponentInfo对象中，等待后续阶段使用。</li>
</ol>
<p style="text-indent:2em">另外在初始化阶段还有一个比较重要的操作就是CamX 与CHI是通过互相dlopen对方的So库，获取了对方的入口方法，最后通过彼此的入口方法获取了对方操作方法集合，之后再通过这些操作方法与对方进行通讯，其主要流程见下图：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E4%B8%83-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82%E5%AE%9E%E7%8E%B0/camx-chi-1620873829302.jpg" alt="img"></p>
<p style="text-indent:2em">从上图不难看出，在HAL3Module构造方法中会去通过dlopen方法加载com.qti.chi.override.so库，并通过dlsym映射出CHI部分的入口方法chi_hal_override_entry，并调用该方法将HAL3Module对像中的成员变量m_ChiAppCallbacks(CHIAppCallbacks)传入CHI中，其中包含了很多函数指针，这些函数指针分别对应着CHI部分的操作方法集中的方法，一旦进入到CHI中，就会将CHI本地的操作方法集合中的函数地址依次赋值给m_ChiAppCallbacks，这样CamX后续就可以通过这个成员变量调用到CHI中方法，从而保持了与CHI的通讯。</p>

<p style="text-indent:2em">同样地，CHI中的ExtensionModule在初始化的时候，其构造方法中也会通过调用dlopen方法加载camera.qcom.so库，并将其入口方法ChiEntry通过dlsym映射出来，之后调用该方法，将g_chiContextOps(ChiContextOps，该结构体中定义了很多指针函数)作为参数传入CamX中，一旦进入CamX中，便会将本地的操作方法地址依次赋值给g_chiContextOps中的每一个函数指针，这样CHI之后就可以通过g_chiContextOps访问到CamX方法。</p>

<h4 id="打开相机设备-初始化相机设备"><a href="#打开相机设备-初始化相机设备" class="headerlink" title="打开相机设备/初始化相机设备"></a>打开相机设备/初始化相机设备</h4><p style="text-indent:2em">一旦用户打开了相机应用，App中便会去调用CameraManager的openCamera方法，该方法之后会最终调用到Camera Service中的CameraService::connectDevice方法，然后通过ICameraDevice::open()这一个HIDL接口通知Provider，然后在Provider内部又通过调用之前获取的camera_module_t中common的methods的open方法来获取一个Camera 设备，对应于HAL中的camera3_device_t结构体，紧接着，在Provider中会继续调用获取到的camera3_device_t的initialize方法进行初始化动作。接下来我们便来详细分析下CamX-CHI对于open以及initialize的具体实现流程：</p>

<h5 id="open"><a href="#open" class="headerlink" title="open"></a>open</h5><p style="text-indent:2em">该方法是camera_module_t的标准方法，主要用来获取camera3_device_t设备结构体的，CamX-CHI对其进行了实现，open方法中完成的工作主要有以下几个：</p>

<ol>
<li>将当前camera id传入CHI中进行remap操作，当然这个remap操作逻辑完全是根据CHI中用户需求来的，用户可以根据自己的需要在CHI中加入自定义remap逻辑。</li>
<li>实例化HALDevice对象，其构造函数中调用Initialize方法，该方法会填充CamX中自定义的Camera3Device结构体。</li>
<li>将m_HALCallbacks.process_capture_result指向了本地方法ProcessCaptureResult以及m_HALCallbacks.notify_result指向了本地方法Notify(之后会在配置数据流的过程中，将m_HALCallbacks注册到CHI中， 一旦当CHI数据处理完成之后，便会通过这两个回调方法将数据或者事件回传给CamX)。</li>
<li>最后将HALDevice 中的Camera3Device成员变量作为返回值给到Provider中的CameraCaptureSession中。</li>
</ol>
<p style="text-indent:2em">Camera3Device 其实重定义了camera3_device_t，其中HwDevice对应于camera3_device_t中的hw_device_t，Camera3DeviceOps对应于camera3_device_ops_t，而在HALDevice的初始化过程中，会将CamX实现的HAL3接口的结构体g_camera3DeviceOps赋值给Camera3DeviceOps中。</p>

<h5 id="initialize"><a href="#initialize" class="headerlink" title="initialize"></a>initialize</h5><p style="text-indent:2em">该方法在调用open后紧接着被调用，主要用于将上层的回调接口传入HAL中，一旦有数据或者事件产生，CamX便会通过这些回调接口将数据或者事件上传至调用者，其内部的实现较为简单。</p>

<p style="text-indent:2em">initialize方法中有两个参数，分别是之前通过open方法获取的camera3_device_t结构体和实现了camera3_callback_ops_t的CameraDevice，很显然camera3_device_t结构体并不是重点，所以该方法的主要工作是将camera3_callback_ops_t与CamX关联上，一旦数据准备完成便通过这里camera3_callback_ops_t中回调方法将数据回传到Camera Provider中的CameraDevice中，基本流程可以总结为以下几点：</p>

<ol>
<li>实例化了一个Camera3CbOpsRedirect对象并将其加入了g_HAL3Entry.m_cbOpsList队列中，这样方便之后需要的时候能够顺利拿到该对象。</li>
<li>将本地的process_capture_result以及notify方法地址分别赋值给Camera3CbOpsRedirect.cbOps中的process_capture_result以及notify函数指针。</li>
<li>将上层传入的回调方法结构体指针pCamera3CbOpsAPI赋值给Camera3CbOpsRedirect.pCbOpsAPI，并将Camera3CbOpsRedirect.cbOps赋值给pCamera3CbOpsAPI，通过JumpTableHal3的initialize方法将pCamera3CbOpsAPI传给HALDevice中的m_pCamera3CbOps成员变量，这样HALDevice中的m_pCamera3CbOps就指向了CamX中本地方法process_capture_result以及notify。</li>
</ol>
<p style="text-indent:2em">经过这样的一番操作之后，一旦CHI有数据传入便会首先进入到本地方法ProcessCaptureResult，然后在该方法中获取到HALDevice的成员变量m_pCamera3CbOps，进而调用m_pCamera3CbOps中的process_capture_result方法，即camxhal3entry.cpp中定义的process_capture_result方法，然后这个方法中会去调用JumpTableHAL3.process_capture_result方法，该方法最终会去调用Camera3CbOpsRedirect.pCbOpsAPI中的process_capture_result方法，这样就调到从Provider传入的回调方法，将数据顺利给到了CameraCaptureSession中。</p>

<h4 id="配置相机设备数据流"><a href="#配置相机设备数据流" class="headerlink" title="配置相机设备数据流"></a>配置相机设备数据流</h4><p style="text-indent:2em">在打开相机应用过程中，App在获取并打开相机设备之后，会调用CameraDevice.createCaptureSession来获取CameraDeviceSession，并且通过Camera api v2标准接口，通知Camera Service，调用其CameraDeviceClient.endConfigure方法，在该方法内部又会去通过HIDL接口ICameraDeviceSession::configureStreams_3_4通知Provider开始处理此次配置需求，在Provider内部，会去通过在调用open流程中获取的camera3_device_t结构体的configure_streams方法来将数据流的配置传入CamX-CHI中，之后由CamX-CHI完成对数据流的配置工作，接下来我们来详细分析下CamX-CHI对于该标准HAL3接口 configure_streams的具体实现：</p>

<p style="text-indent:2em">配置数据流是整个CamX-CHI流程比较重要的一环，其中主要包括两个阶段：</p>

<ol>
<li>选择UsecaseId</li>
<li>根据选择的UsecaseId创建Usecase</li>
</ol>
<p style="text-indent:2em">接下来我们就这两个阶段分别进行详细介绍:</p>

<h5 id="①-选择UsecaseId"><a href="#①-选择UsecaseId" class="headerlink" title="① 选择UsecaseId"></a>① 选择UsecaseId</h5><p style="text-indent:2em">不同的UsecaseId分别对应的不同的应用场景，该阶段是通过调用UsecaseSelector::GetMatchingUsecase()方法来实现的，该函数中通过传入的operation_mode、num_streams配置数据流数量以及当前使用的Sensor个数来选择相应的UsecaseId，比如当numPhysicalCameras值大于1同时配置的数据流数量num_streams大于1时选择的就是UsecaseId::MultiCamera，表示当前采用的是双摄场景。</p>

<h5 id="②-创建Usecase"><a href="#②-创建Usecase" class="headerlink" title="② 创建Usecase"></a>② 创建Usecase</h5><p style="text-indent:2em">根据之前选择的UsecaseId，通过UsecaseFactory来创建相应的Usecase，其中Class Usecase是所有Usecase的基类，定义并实现了一些通用接口，CameraUsecaseBase继承于Usecase，并扩展了部分功能。AdvancedCameraUsecase又继承于CameraUsecaseBase，作为主要负责大部分场景的Usecase实现类，另外对于多摄场景，现提供了继承于AdvancedCameraUsecase的UsecaseMultiCamera来负责实现。除了双摄场景，其它大部分场景使用的都是AdvancedCameraUsecase类来管理各项资源的，接下来我们重点梳理下AdvancedCameraUsecase::Create()方法。在AdvancedCameraUsecase::Create方法中做了很多初始化操作，其中包括了以下几个阶段：</p>

<ol>
<li>获取XML文件中Usecase配置信息</li>
<li>创建Feature</li>
<li>保存数据流，重建Usecase的配置信息</li>
<li>调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作</li>
</ol>
<p style="text-indent:2em">接下来我们就这几个阶段逐一进行分析：</p>

<h6 id="获取XML文件中Usecase配置信息"><a href="#获取XML文件中Usecase配置信息" class="headerlink" title="获取XML文件中Usecase配置信息"></a>获取XML文件中Usecase配置信息</h6><p style="text-indent:2em">这一部分主要通过调用CameraUsecaseBase::GetXMLUsecaseByName方法进行实现。该方法的主要操作是从PerNumTargetUsecases数组中找到匹配到给定的usecaseName的Usecase，并作为返回值返回给调用者，其中这里我们以"UsecaseZSL“为例进行分析，PerNumTargetUsecases的定义是在g_pipeline.h中，该文件是在编译过程中通过usecaseconverter.pl脚本将定义在个平台目录下的common_usecase.xml中的内容转换生成g_pipeline.h。</p>

<h6 id="创建Feature"><a href="#创建Feature" class="headerlink" title="创建Feature"></a>创建Feature</h6><p>如果当前场景选取了Feature，则调用FeatureSetup来完成创建工作。</p>
<p>该方法主要是通过诸如operation_mode、camera数量以及UsecaseId等信息来决定需要选择哪些Feature,具体逻辑比较清晰，一旦决定需要使用哪一个Feature之后，便调用相应的Feature的Create()方法进行初始化操作。</p>
<h6 id="保存数据流，重建Usecase的配置信息"><a href="#保存数据流，重建Usecase的配置信息" class="headerlink" title="保存数据流，重建Usecase的配置信息"></a>保存数据流，重建Usecase的配置信息</h6><p>从Camera Service 传入的数据流，需要将其存储下来，供后续使用，同时高通针对Usecase也加入了Override机制，根据需要可以选择性地扩展Usecase，这两个步骤的实现主要是通过SelectUsecaseConfig方法来实现。</p>
<p>其中主要是调用以下两个方法来实现的：</p>
<p>ConfigureStream： 该方法将从上层配置的数据流指针存入AdvancedCameraUsecase中，其中包括了用于预览的m_pPreviewStream以及用于拍照的m_pSnapshotStream。</p>
<p>BuildUsecase： 这个方法用来重新在原有的Usecase上面加入了Feature中所需要的pipeline，并创建了一个新的Usecase，并将其存入AdvancedCameraUsecase中的m_pChiUsecase成员变量中，紧接着通过SetPipelineToSessionMapping方法将pipeline与Session进行关联。</p>
<h6 id="调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作"><a href="#调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作" class="headerlink" title="调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作"></a>调用父类CameraUsecaseBase的initialize方法，进行一些常规初始化工作</h6>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://luojianwei.top/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="罗建伟的个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="罗建伟的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/" class="post-title-link" itemprop="url">Android Camera 体系结构之六 相机硬件抽象层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-11 14:55:17 / 修改时间：14:56:37" itemprop="dateCreated datePublished" datetime="2021-06-11T14:55:17+08:00">2021-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Camera/" itemprop="url" rel="index"><span itemprop="name">Camera</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p style="text-indent:2em">始于谷歌的Treble开源项目，基于接口与实现分离的设计原则，谷歌加入了Camera Provider这一抽象层，该层作为一个独立进程存在于整个系统中，并且通过HIDL这一自定义语言成功地将Camera Hal Module从Camera Service中解耦出来，承担起了对Camera HAL的封装工作，纵观整个Android Camera系统，对于Camera Provider而言，对上是通过HIDL接口负责与Camera Service的跨进程通信，对下通过标准的HAL3接口下发针对Camera的实际操作，这俨然是一个中央枢纽般的调配中心的角色，而事实上正是如此，由此看来，对Camera Provider的梳理变得尤为重要，接下来就以我个人理解出发来简单介绍下Camera Provider。</p>

<p style="text-indent:2em">Camera Provider通过提供标准的HIDL接口给Camera Service进行调用，保持与Service的正常通信，其中谷歌将HIDL接口的定义直接暴露给平台厂商进行自定义实现，其中为了极大地减轻并降低开发者的工作量和开发难度，谷歌很好地封装了其跨进程实现细节，同样地，Camera Provider通过标准的HAL3接口，向下控制着具体的Camera HAL Module，而这个接口依然交由平台厂商负责去实现，而进程内部则通过简单的函数调用，将HIDL接口与HAL3接口完美的衔接起来，由此构成了Provider整体架构。</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/provider.jpg" alt="img"></p>
<p style="text-indent:2em">由图中可以看出Camera Provider进程由两部分组成，一是运行在系统中的主程序通过提供了标准的HIDL接口保持了与Camera Service的跨进程通讯，二是为了进一步扩展其功能，通过dlopen方式加载了一系列so库，而其中就包括了实现了Camera HAL3接口的so库，而HAL3接口主要定义了用于实现图像控制的功能，其实现主要交由平台厂商或者开发者来完成，所以Camera HAL3 so库的实现各式各样，这里在高通平台上的实现就是我们本文重点需要分析的CamX-CHI框架。在开始梳理CamX-CHI之前，不防先从上到下，以接口为主线简单梳理下Camera Provider的各个部分:</p>

<h3 id="Camera-HIDL-接口"><a href="#Camera-HIDL-接口" class="headerlink" title="Camera HIDL 接口"></a>Camera HIDL 接口</h3><p style="text-indent:2em">首先需要明确一个概念，就是HIDL是一种自定义语言，其核心是接口的定义，而谷歌为了使开发者将注意力落在接口的定义上而不是机制的实现上，主动封装了HIDL机制的实现细节，开发者只需要通过*.hal文件定义接口，填充接口内部实际的实现即可，接下来来看下具体定义的几个主要接口：</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/hidl.jpg" alt="img"></p>
<p style="text-indent:2em">因为HIDL机制本身是跨进程通讯的，所以Camera Service本身通过HIDL接口获取的对象都会有Bn端和Bp端，分别代表了Binder两端，接下来为了方便理解，我们都省略掉Bn/Bp说法,直接用具体接口类代表，忽略跨进程两端的区别。</p>

<p style="text-indent:2em">ICameraProvider.hal文件中定义了ICameraProvider接口类，由CameraProvider继承并实现，在Camera Provider启动的时候被实例化，主要接口如下：</p>

<ul>
<li>getCameraDeviceInterface_V3_x: 该方法主要用于Camera Service获取ICameraDevice，通过该对象可以控制Camera 设备的诸如配置数据流、下发request等具体行为。</li>
<li>setCallback： 将CameraService 实现的ICameraProviderCallback传入CameraProvider，一旦Provider有事件产生时便可以通过该对象通知Camera Service。</li>
</ul>
<p style="text-indent:2em">ICameraProviderCallback.hal文件中定义了ICameraProviderCallback回调接口类，该接口由Camera Service中的CameraProviderManager::ProviderInfo继承并实现，在Camera Service启动的时候被实例化，通过调用ICameraProvider::setCallback接口注册到Camera Provider中，其主要接口如下：</p>

<ul>
<li>cameraDeviceStatusChange： 将Camera 设备状态上传至Camera Service，状态由CameraDeviceStatus定义</li>
</ul>
<p style="text-indent:2em">ICameraDevice.hal文件中定义了ICameraDevice接口类，由CameraDevice::TrampolineDeviceInterface_3_2实现，其主要接口如下:</p>

<ul>
<li>open： 用于创建一个Camera设备，并且将Camera Service中继承ICameraDeviceCallback并实现了相应接口的Camera3Device作为参数传入Provider中，供Provider上传事件或者图像数据。</li>
<li>getCameraCharacteristics：用于获取Camera设备的属性。</li>
</ul>
<p style="text-indent:2em">ICameraDeviceCallback.hal文件中定义了ICameraDeviceCallback接口类，由Camera Service中的Camera3Device继承并实现，通过调用ICameraDevice::open方法注册到Provider中，其主要接口如下：</p>

<ul>
<li>processCaptureResult_3_4: 一旦有图像数据产生会通过调用该方法将数据以及metadata上传至Camera Service。</li>
<li>notify: 通过该方法上传事件至Camera Service中，比如shutter事件等。</li>
</ul>
<p style="text-indent:2em">ICameraDeviceSession.hal文件中定义了ICameraDeviceSession接口类，由CameraDeviceSession::TrampolineSessionInterface_3_2继承并实现，其主要接口如下：</p>

<ul>
<li>constructDefaultRequestSettings：用于创建默认的Request配置项。</li>
<li>configureStreams_3_5：用于配置数据流，其中包括了output buffer/Surface/图像格式大小等属性。</li>
<li>processCaptureRequest_3_4：下发request到Provider中，一个request对应着一次图像需求。</li>
<li>close: 关闭当前会话</li>
</ul>
<h3 id="Camera-Provider-主程序"><a href="#Camera-Provider-主程序" class="headerlink" title="Camera Provider 主程序"></a>Camera Provider 主程序</h3><p style="text-indent:2em">接下来进入到Provider内部去看看，整个进程是如何运转的，以下图为例进行分析:</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/provider-process-flow.jpg" alt="img"></p>
<p style="text-indent:2em">在系统初始化的时候，系统会去运行android.hardware.camera.provider@2.4-service_64程序启动Provider进程，并加入HW Service Manager中接受统一管理，在该过程中实例化了一个LegacyCameraProviderImpl_2_4对象，并在其构造函数中通过hw_get_module标准方法获取HAL的camera_module_t结构体,并将其存入CameraModule对象中，之后通过调用该camera_modult_t结构体的init方法初始化HAL Module，紧接着调用其get_number_of_camera方法获取当前HAL支持的Camera数量，最后通过调用其set_callbacks方法将LegcyCameraProviderImpl_2_4(LegcyCameraProviderImpl_2_4继承了camera_modult_callback_t)作为参数传入CamX-CHI中，接受来自CamX-CHI中的数据以及事件，当这一系列动作完成了之后，Camera Provider进程便一直便存在于系统中，监听着来自Camera Service的调用。</p>

<p><img src="/2021/06/11/Android-Camera-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E4%B9%8B%E5%85%AD-%E7%9B%B8%E6%9C%BA%E7%A1%AC%E4%BB%B6%E6%8A%BD%E8%B1%A1%E5%B1%82/provider-process-flow1.jpg" alt="img"></p>
<p style="text-indent:2em">接下来以上图为例简单介绍下Provider中几个重要流程：</p>

<ul>
<li><p>Camera Service通过调用ICameraProvider的getCameraDeviceInterface_v3_x接口获取ICameraDevice，在此过程中，Provider会去实例化一个CameraDevice对象，并且将之前存有camera_modult_t结构体的CameraModule对象传入CameraDevice中，这样就可以在CameraDevice内部通过CameraModule访问到camera_module_t的相关资源，然后将CameraDevice内部类TrampolineDeviceInterface_3_2(该类继承并实现了ICameraDevice接口)返回给Camera Service。</p>
</li>
<li><p>Camera Service通过之前获取的ICameraDevice，调用其open方法来打开Camera设备，接着在Provider中会去调用CameraDevice对象的open方法，在该方法内部会去调用camera_module_t结构体的open方法，从而获取到HAL部分的camera3_device_t结构体，紧接着Provider会实例化一个CameraDeviceSession对象，并且将刚才获取到的camera3_device_t结构体以参数的方式传入CameraDeviceSession中，在CameraDeviceSession的构造方法中又会调用CameraDeviceSession的initialize方法，在该方法内部又会去调用camera3_device_t结构体的ops内的initialize方法开始HAL部分的初始化工作，最后CameraDeviceSession对象被作为camera3_callback_ops的实现传入HAL，接收来自HAL的数据或者具体事件，当一切动作都完成后，Provider会将CameraDeviceSession::TrampolineSessionInterface_3_2(该类继承并实现了ICameraDeviceSession接口)对象通过HIDL回调的方法返回给Camera Service中。</p>
</li>
<li><p>Camera Service通过调用ICameraDevcieSession的configureStreams_3_5接口进行数据流的配置，在Provider中，最终会通过调用之前获取的camera3_device_t结构体内ops的configure_streams方法下发到HAL中进行处理。</p>
</li>
<li><p>Camera Service通过调用ICameraDevcieSession的processCaptureRequest_3_4接口下发request请求到Provider中，在Provider中，最终依然会通过调用获取的camera3_device_t结构体内ops中的process_capture_request方法将此次请求下发到HAL中进行处理。</p>
</li>
</ul>
<p style="text-indent:2em">从整个流程不难看出，这几个接口最终对应的是HAL3的接口，并且Provider并没有经过太多复杂的额外的处理。</p>

<h3 id="Camera-HAL3-接口"><a href="#Camera-HAL3-接口" class="headerlink" title="Camera HAL3 接口"></a>Camera HAL3 接口</h3><p style="text-indent:2em">HAL(Hardware Abstraction Layer,硬件抽象层)，是谷歌开发的用于屏蔽底层硬件抽象出来的一个软件层， 每一个平台厂商可以将不开源的代码封装在这一层，仅仅提供二进制文件。该层定义了自己的一套通用标准接口，平台厂商务必按照以下规则定义自己的Module:</p>

<ul>
<li>每一个硬件模块都通过hw_module_t来描述，具有固定的名字HMI</li>
<li>每一个硬件模块都必须实现hw_module_t里面的open方法，用于打开硬件设备，并返回对应的操作接口集合</li>
<li>硬件的操作接口集合使用hw_device_t 来描述，并可以通过自定义一个更大的包含hw_device_t的结构体来拓展硬件操作集合</li>
</ul>
<p style="text-indent:2em">其中代表硬件模块的是hw_module_t，对应的设备是通过hw_device_t来描述，从这两者的定义可以看出，主要是通过hw_module_t 代表了模块，通过其open方法用来打开一个设备，而该设备是用hw_device_t来表示，其中除了用来关闭设备的close方法外，并无其它方法，由此可见谷歌定义的HAL接口，并不能满足绝大部分HAL模块的需要，所以谷歌想出了一个比较好的解决方式，那便是将这两个基本结构嵌入到更大的结构体内部，同时在更大的结构内部定义了各自模块特有的方法，用于实现模块的功能，这样，一来对上保持了HAL的统一规范，二来也扩展了模块的功能。</p>

<p style="text-indent:2em">基于上面的方式，谷歌便针对Camera 提出了HAL3接口，其中主要包括了用于代表一系列操作主体的结构体以及具体操作函数，接下来我们分别进行详细介绍：</p>

<h4 id="核心结构体解析"><a href="#核心结构体解析" class="headerlink" title="核心结构体解析"></a>核心结构体解析</h4><p style="text-indent:2em">HAL3中主要定义了
camera_module_t/camera3_device_t/camera3_stream_configuration/camera3_stream以及camera3_stream_buffer几个主要结构体。</p>


<p style="text-indent:2em">由其中camera_module_t以及camera3_device_t代码定义不难发现，camera_module_t包含了hw_module_t，主要用于表示Camera模块，其中定义了诸如get_number_of_cameras以及set_callbacks等扩展方法，而camera3_device_t包含了hw_device_t，主要用来表示Camera设备，其中定义了camera3_device_ops操作方法集合，用来实现正常获取图像数据以及控制Camera的功能。</p>

<p style="text-indent:2em">结构体camera3_stream_configuration主要用来代表配置的数据流列表，内部装有上层需要进行配置的数据流的指针，内部的定义简单介绍下：</p>

<ul>
<li>num_streams: 代表了来自上层的数据流的数量，其中包括了output以及input stream。</li>
<li>streams: 是streams的指针数组，包括了至少一条output stream以及至多一条input stream。</li>
<li>operation_mode: 当前数据流的操作模式，该模式在camera3_stream_configuration_mode_t中被定义，HAL通过这个参数可以针对streams做不同的设置。</li>
<li>session_parameters: 该参数可以作为缺省参数，直接设置为NULL即可，CAMERA_DEVICE_API_VERSION_3_5以上的版本才支持。</li>
</ul>
<p style="text-indent:2em">camera3_stream_t结构体主要用来代表具体的数据流实体，在整个的配置过程中，需要在上层进行填充，当下发到HAL中后，HAL会针对其中的各项属性进行配置，这里便简单介绍下其内部的各个元素的意义：</p>

<ul>
<li>stream_type: 表示数据流的类型，类型在camera3_stream_type_t中被定义。</li>
<li>width： 表示当前数据流中的buffer的宽度。</li>
<li>height: 表示当前数据流中buffer的高度。</li>
<li>format: 表示当前数据流中buffer的格式，该格式是在system/graphics.h中被定义。</li>
<li>usage： 表示当前数据流的gralloc用法，其用法定义在gralloc.h中。</li>
<li>max_buffers： 指定了当前数据流中可能支持的最大数据buffer数量。</li>
<li>data_space: 指定了当前数据流buffer中存储的图像数据的颜色空间。</li>
<li>rotation：指定了当前数据流的输出buffer的旋转角度，其角度的定义在camera3_stream_rotation_t中，该参数由Camera Service进行设置，必须在HAL中进行设置，该参数对于input stream并没有效果。</li>
<li>physical_camera_id： 指定了当前数据流从属的物理camera Id。</li>
</ul>
<p style="text-indent:2em">结构体camera3_stream_buffer_t主要用来代表具体的buffer对象，其中重要元素如下：</p>

<ul>
<li>stream: 代表了从属的数据流</li>
<li>buffer：buffer句柄</li>
</ul>
<h4 id="核心接口函数解析"><a href="#核心接口函数解析" class="headerlink" title="核心接口函数解析"></a>核心接口函数解析</h4><p style="text-indent:2em">HAL3的核心接口都是在camera3_device_ops中被定义,该结构体定义了一系列的函数指针，用来指向平台厂商实际的实现方法，接下来就其中几个方法简单介绍下：</p>

<h5 id="a-initialize"><a href="#a-initialize" class="headerlink" title="a) initialize"></a>a) initialize</h5><p style="text-indent:2em">该方法必须在camera_module_t中的open方法之后，其它camera3_device_ops中方法之前被调用，主要用来将上层实现的回调方法注册到HAL中，并且根据需要在该方法中加入自定义的一些初始化操作，另外，谷歌针对该方法在性能方面也有严格的限制，该方法需要在5ms内返回，最长不能超过10ms。


</p><h5 id="b-configure-streams"><a href="#b-configure-streams" class="headerlink" title="b) configure_streams"></a>b) configure_streams</h5><p style="text-indent:2em">该方法在完成initialize方法之后，在调用process_capture_request方法之前被调用，主要用于重设当前正在运行的Pipeline以及设置新的输入输出流，其中它会将stream_list中的新的数据流替换之前配置的数据流。在调用该方法之前必须确保没有新的request下发并且当前request的动作已经完成，否则会引起无法预测的错误。一旦HAL调用了该方法，则必须在内部配置好满足当前数据流配置的帧率，确保这个流程的运行的顺畅性。其中包含了两个参数，分别是camera3_device以及stream_list(camera3_stream_configuration_t ),其中第二个参数是上层传入的数据流配置列表，该列表中必须包含至少一个output stream，同时至多包含一个input stream。另外，谷歌针对该方法有着严格的性能要求，平台厂商在实现该方法的时候，需要在500ms内返回，最长不能超过1000ms。</p>

<h5 id="c-construct-default-request-settings"><a href="#c-construct-default-request-settings" class="headerlink" title="c) construct_default_request_settings"></a>c) construct_default_request_settings</h5><p style="text-indent:2em">该方法主要用于构建一系列默认的Camera Usecase的capture设置项，通过camera_metadata_t来进行描述，其中返回值是一个camera_metadata_t指针，其指向的内存地址是由HAL来进行维护的，同样地，该方法需要在1ms内返回，最长不能超过5ms。</p>

<h5 id="d-process-capture-request"><a href="#d-process-capture-request" class="headerlink" title="d) process_capture_request"></a>d) process_capture_request</h5><p style="text-indent:2em">该方法用于下发单次新的capture request到HAL中， 上层必须保证该方法的调用都是在一个线程中完成，而且该方法是异步的，同时其结果并不是通过返回值给到上层，而是通过HAL调用另一个接口process_capture_result()来将结果返回给上层的，在使用的过程中，通过in-flight机制，保证短时间内下发足够多的request，从而满足帧率要求。</p>

<p style="text-indent:2em">该方法的性能依然受到谷歌的严格要求，规定其需要在一帧图像处理完的时长内返回，最长不超过4帧图像处理完成的时长，比如当前预览帧率是30帧，则该方法的操作耗时最长不能超过120ms，否则便会引起明显的帧抖动，从而影响用户体验。</p>

<h5 id="e-dump"><a href="#e-dump" class="headerlink" title="e) dump"></a>e) dump</h5><p style="text-indent:2em">该方法用于打印当前Camera设备的状态，一般是由上层通过dumpsys工具输出debug dump信息或者主动抓取bugreport的时候被调用，该方法必须是非阻塞实现，同时需要保证在1ms内返回，最长不能超过10ms。</p>

<h5 id="f-flush"><a href="#f-flush" class="headerlink" title="f) flush"></a>f) flush</h5><p style="text-indent:2em">当上层需要执行新的configure_streams的时候，需要调用该方法去尽可能快地清除掉当前已经在处理中的或者即将处理的任务，为配置数据流提供一个相对稳定的环境，其具体工作如下：</p>

<ul>
<li>所有的还在流转的request会尽可能快的返回</li>
<li>并未开始进行流转的request会直接返回，并携带错误信息</li>
<li>任何可以打断的硬件操作会立即被停止</li>
<li>任何无法进行打断的硬件操作会在当前状态下进行休眠</li>
</ul>
<p style="text-indent:2em">flush会在所有的buffer都得以释放，所有request都成功返回后才真正返回，该方法需要在100ms内返回，最长不能超过1000ms。</p>

<p style="text-indent:2em">上面的一系列方法是上层直接对下控制Camera Hal，而一旦Camera Hal产生了数据或者事件的时候，可以通过camera3_callback_ops中定义的回调方法将数据或者事件返回至上层，该结构体中常用的回调方法主要有两个：用于返回数据的process_capture_result以及用于返回事件的notify，接下来分别介绍下：</p>

<ul>
<li>process_capture_result</li>
</ul>
<p style="text-indent:2em">该方法用于返回HAL部分产生的metadata和image buffers，它与request是多对一的关系，同一个request，可能会对应到多个result，比如可以通过调用一次该方法用于返回metadata以及低分辨率的图像数据，再调用一次该方法用于返回jpeg格式的拍照数据，而这两次调用时对应于同一个process_capture_request动作。同一个Request的Metadata以及Image Buffers的先后顺序无关紧要，但是同一个数据流的不同Request之间的Result必须严格按照Request的下发先后顺序进行依次返回的，如若不然，会导致图像数据显示出现顺序错乱的情况。该方法是非阻塞的，而且并且必须要在5ms内返回。</p>

<ul>
<li>notify</li>
</ul>
<p style="text-indent:2em">该方法用于异步返回HAL事件到上层，必须非阻塞实现，而且要在5ms内返回。</p>



<p style="text-indent:2em">谷歌为了将系统框架和平台厂商的自定义部分相分离，在Android上推出了Treble项目，该项目直接将平台厂商的实现部分放入vendor分区中进行管理，进而与system分区保持隔离，这样便可以在相互独立的空间中进行各自的迭代升级，而互不干扰，而在相机框架体系中，便将Camera HAL Module从Camera Service中解耦出来，放入独立进程Camera Provider中进行管理，而为了更好的进行跨进程访问，谷歌针对Provider提出了HIDL机制用于Camera Service对于Camera Provier的访问，而HIDL接口的实现是在Camera Provider中实现，针对Camera HAL Module的控制又是通过谷歌制定的Camera HAL3接口来完成，所以由此看来，Provider的职责也比较简单，通过HIDL机制保持与Camera Service的通信，通过HAL3接口控制着Camera HAL Module。</p>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/home/page/2/">2</a><a class="extend next" rel="next" href="/home/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">罗建伟的个人博客</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
